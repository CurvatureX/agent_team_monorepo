#!/usr/bin/env python3
"""
æµ‹è¯•WorkflowéªŒè¯åŠŸèƒ½ - åˆ›å»ºåŒ…å«æ‰€æœ‰nodeå­ç±»å‹çš„workflow

è¿™ä¸ªè„šæœ¬ç”¨äºéªŒè¯æˆ‘ä»¬åˆšåˆšæ”¹é€ çš„èŠ‚ç‚¹è§„èŒƒç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
å®ƒå°†åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰æ”¯æŒçš„nodeå­ç±»å‹çš„workflowï¼Œå¹¶æµ‹è¯•éªŒè¯åŠŸèƒ½ã€‚
"""

import json
import sys
from pathlib import Path

# Add the backend directory to Python path
backend_dir = Path(__file__).parent / "apps" / "backend"
sys.path.insert(0, str(backend_dir))

try:
    from shared.models import CreateWorkflowRequest, NodeData, ConnectionsMap
    from workflow_engine.utils.workflow_validator import WorkflowValidator
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def create_comprehensive_test_workflow():
    """åˆ›å»ºåŒ…å«æ‰€æœ‰nodeå­ç±»å‹çš„æµ‹è¯•workflow"""
    
    nodes = []
    node_id_counter = 1
    
    # 1. TRIGGER_NODE å­ç±»å‹
    trigger_subtypes = [
        "TRIGGER_MANUAL",
        "TRIGGER_WEBHOOK", 
        "TRIGGER_CRON",
        "TRIGGER_CHAT",
        "TRIGGER_EMAIL",
        "TRIGGER_FORM",
        "TRIGGER_CALENDAR"
    ]
    
    for subtype in trigger_subtypes:
        node_id = f"trigger_{node_id_counter}"
        node_id_counter += 1
        
        if subtype == "TRIGGER_MANUAL":
            parameters = {
                "trigger_name": "Manual Test",
                "description": "Manual trigger for testing",
                "require_confirmation": True
            }
        elif subtype == "TRIGGER_WEBHOOK":
            parameters = {
                "webhook_path": "/test-webhook",
                "http_method": "POST",
                "authentication": "none"
            }
        elif subtype == "TRIGGER_CRON":
            parameters = {
                "cron_expression": "0 9 * * MON",
                "timezone": "UTC"
            }
        elif subtype == "TRIGGER_CHAT":
            parameters = {
                "chat_platform": "slack",
                "message_filter": "hello"
            }
        elif subtype == "TRIGGER_EMAIL":
            parameters = {
                "email_filter": "subject:test",
                "email_provider": "gmail"
            }
        elif subtype == "TRIGGER_FORM":
            parameters = {
                "form_id": "test-form",
                "form_fields": ["name", "email"]
            }
        elif subtype == "TRIGGER_CALENDAR":
            parameters = {
                "calendar_id": "primary",
                "event_filter": "meeting"
            }
        
        nodes.append(NodeData(
            id=node_id,
            name=f"Test {subtype}",
            type="TRIGGER_NODE",
            subtype=subtype,
            parameters=parameters,
            position={"x": 100, "y": 100 + len(nodes) * 100}
        ))
    
    # 2. AI_AGENT_NODE å­ç±»å‹
    ai_subtypes = [
        "GEMINI_NODE",
        "OPENAI_NODE", 
        "CLAUDE_NODE"
    ]
    
    for subtype in ai_subtypes:
        node_id = f"ai_{node_id_counter}"
        node_id_counter += 1
        
        base_params = {
            "system_prompt": f"You are a helpful {subtype.lower()} assistant",
            "temperature": 0.7,
            "max_tokens": 1000
        }
        
        if subtype == "GEMINI_NODE":
            parameters = {
                **base_params,
                "model_version": "gemini-pro",
                "safety_settings": {}
            }
        elif subtype == "OPENAI_NODE":
            parameters = {
                **base_params,
                "model_version": "gpt-4",
                "presence_penalty": 0.0,
                "frequency_penalty": 0.0
            }
        elif subtype == "CLAUDE_NODE":
            parameters = {
                **base_params,
                "model_version": "claude-3-sonnet",
                "stop_sequences": []
            }
        
        nodes.append(NodeData(
            id=node_id,
            name=f"Test {subtype}",
            type="AI_AGENT_NODE",
            subtype=subtype,
            parameters=parameters,
            position={"x": 300, "y": 100 + len(nodes) * 100}
        ))
    
    # 3. ACTION_NODE å­ç±»å‹
    action_subtypes = [
        "RUN_CODE",
        "HTTP_REQUEST",
        "DATA_TRANSFORMATION",
        "FILE_OPERATION"
    ]
    
    for subtype in action_subtypes:
        node_id = f"action_{node_id_counter}"
        node_id_counter += 1
        
        if subtype == "RUN_CODE":
            parameters = {
                "code": "print('Hello World')",
                "language": "python",
                "timeout": 30,
                "environment": {},
                "capture_output": True
            }
        elif subtype == "HTTP_REQUEST":
            parameters = {
                "method": "GET",
                "url": "https://api.example.com/test",
                "headers": {},
                "data": {},
                "timeout": 30,
                "authentication": "none",
                "retry_attempts": 3
            }
        elif subtype == "DATA_TRANSFORMATION":
            parameters = {
                "transformation_type": "filter",
                "transformation_rule": "filter condition"
            }
        elif subtype == "FILE_OPERATION":
            parameters = {
                "operation": "read",
                "file_path": "/tmp/test.txt"
            }
        
        nodes.append(NodeData(
            id=node_id,
            name=f"Test {subtype}",
            type="ACTION_NODE", 
            subtype=subtype,
            parameters=parameters,
            position={"x": 500, "y": 100 + len(nodes) * 100}
        ))
    
    # 4. FLOW_NODE å­ç±»å‹
    flow_subtypes = [
        "IF",
        "FILTER", 
        "LOOP",
        "MERGE",
        "SWITCH",
        "WAIT"
    ]
    
    for subtype in flow_subtypes:
        node_id = f"flow_{node_id_counter}"
        node_id_counter += 1
        
        if subtype == "IF":
            parameters = {
                "condition": "input.value > 10"
            }
        elif subtype == "FILTER":
            parameters = {
                "filter_condition": {"status": "active"}
            }
        elif subtype == "LOOP":
            parameters = {
                "loop_type": "for_each",
                "max_iterations": 100
            }
        elif subtype == "MERGE":
            parameters = {
                "merge_strategy": "combine"
            }
        elif subtype == "SWITCH":
            parameters = {
                "switch_cases": [
                    {"value": "case1", "route": "branch1"},
                    {"value": "case2", "route": "branch2"}
                ]
            }
        elif subtype == "WAIT":
            parameters = {
                "wait_type": "time",
                "duration": 5
            }
        
        nodes.append(NodeData(
            id=node_id,
            name=f"Test {subtype}",
            type="FLOW_NODE",
            subtype=subtype, 
            parameters=parameters,
            position={"x": 700, "y": 100 + len(nodes) * 100}
        ))
    
    # 5. å…¶ä»–èŠ‚ç‚¹ç±»å‹...
    # ä¸ºäº†ç®€åŒ–æµ‹è¯•ï¼Œæˆ‘ä»¬å…ˆæµ‹è¯•ä»¥ä¸Šè¿™äº›ä¸»è¦ç±»å‹
    
    # åˆ›å»ºworkflowè¯·æ±‚
    workflow_request = CreateWorkflowRequest(
        name="Comprehensive Node Types Test Workflow",
        description="æµ‹è¯•æ‰€æœ‰nodeå­ç±»å‹çš„éªŒè¯åŠŸèƒ½",
        nodes=nodes,
        connections=None,  # ç®€åŒ–æµ‹è¯•ï¼Œä¸æ·»åŠ è¿æ¥
        settings={},
        static_data={},
        tags=["test", "validation"],
        user_id="test-user",
        session_id="test-session"
    )
    
    return workflow_request

def test_workflow_validation():
    """æµ‹è¯•workflowéªŒè¯åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•workflowéªŒè¯åŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•workflow
    print("ğŸ“ åˆ›å»ºåŒ…å«æ‰€æœ‰nodeå­ç±»å‹çš„æµ‹è¯•workflow...")
    workflow_request = create_comprehensive_test_workflow()
    
    print(f"âœ… åˆ›å»ºäº†åŒ…å« {len(workflow_request.nodes)} ä¸ªèŠ‚ç‚¹çš„workflow")
    
    # æ‰“å°èŠ‚ç‚¹ä¿¡æ¯
    print("\nğŸ“‹ èŠ‚ç‚¹åˆ—è¡¨:")
    for node in workflow_request.nodes:
        print(f"  - {node.id}: {node.type}.{node.subtype} ({node.name})")
    
    # ä½¿ç”¨WorkflowValidatorè¿›è¡ŒéªŒè¯
    print("\nğŸ” å¼€å§‹éªŒè¯workflow...")
    validator = WorkflowValidator()
    
    # è½¬æ¢ä¸ºdictæ ¼å¼
    workflow_dict = {
        "name": workflow_request.name,
        "nodes": [node.dict() for node in workflow_request.nodes],
        "connections": workflow_request.connections.dict() if workflow_request.connections else {},
        "settings": workflow_request.settings
    }
    
    # æ‰§è¡ŒéªŒè¯
    result = validator.validate_workflow_structure(workflow_dict, validate_node_parameters=True)
    
    # è¾“å‡ºéªŒè¯ç»“æœ
    print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
    print(f"  âœ… æ˜¯å¦æœ‰æ•ˆ: {result['valid']}")
    
    if result['errors']:
        print(f"  âŒ é”™è¯¯ ({len(result['errors'])}):")
        for error in result['errors']:
            print(f"    - {error}")
    else:
        print("  âœ… æ²¡æœ‰å‘ç°é”™è¯¯")
    
    if result['warnings']:
        print(f"  âš ï¸  è­¦å‘Š ({len(result['warnings'])}):")
        for warning in result['warnings']:
            print(f"    - {warning}")
    else:
        print("  âœ… æ²¡æœ‰è­¦å‘Š")
    
    return result

def test_invalid_workflow():
    """æµ‹è¯•æ— æ•ˆworkflowçš„éªŒè¯"""
    print("\n\nğŸ§ª æµ‹è¯•æ— æ•ˆworkflowçš„éªŒè¯...")
    
    # åˆ›å»ºä¸€ä¸ªæœ‰é”™è¯¯çš„node
    invalid_node = NodeData(
        id="invalid_node",
        name="Invalid Node",
        type="AI_AGENT_NODE",
        subtype="OPENAI_NODE",
        parameters={
            # ç¼ºå°‘å¿…éœ€çš„system_promptå‚æ•°
            "temperature": "invalid_type",  # é”™è¯¯çš„ç±»å‹
            "max_tokens": -100  # æ— æ•ˆå€¼
        },
        position={"x": 100, "y": 100}
    )
    
    workflow_request = CreateWorkflowRequest(
        name="Invalid Test Workflow",
        description="æµ‹è¯•æ— æ•ˆèŠ‚ç‚¹çš„éªŒè¯",
        nodes=[invalid_node],
        connections=None,
        settings={},
        static_data={},
        tags=["test", "invalid"],
        user_id="test-user", 
        session_id="test-session"
    )
    
    validator = WorkflowValidator()
    workflow_dict = {
        "name": workflow_request.name,
        "nodes": [node.dict() for node in workflow_request.nodes],
        "connections": {},
        "settings": workflow_request.settings
    }
    
    result = validator.validate_workflow_structure(workflow_dict, validate_node_parameters=True)
    
    print(f"ğŸ“Š æ— æ•ˆworkflowéªŒè¯ç»“æœ:")
    print(f"  âŒ æ˜¯å¦æœ‰æ•ˆ: {result['valid']} (åº”è¯¥ä¸ºFalse)")
    print(f"  âŒ é”™è¯¯æ•°é‡: {len(result['errors'])}")
    
    if result['errors']:
        print("  é”™è¯¯è¯¦æƒ…:")
        for error in result['errors']:
            print(f"    - {error}")
    
    return result

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•WorkflowèŠ‚ç‚¹è§„èŒƒç³»ç»Ÿ...")
    print("=" * 60)
    
    try:
        # æµ‹è¯•æœ‰æ•ˆworkflow
        valid_result = test_workflow_validation()
        
        # æµ‹è¯•æ— æ•ˆworkflow
        invalid_result = test_invalid_workflow()
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æµ‹è¯•æ€»ç»“:")
        print(f"  âœ… æœ‰æ•ˆworkflowéªŒè¯: {'é€šè¿‡' if valid_result['valid'] else 'å¤±è´¥'}")
        print(f"  âŒ æ— æ•ˆworkflowéªŒè¯: {'é€šè¿‡' if not invalid_result['valid'] else 'å¤±è´¥'}")
        
        if valid_result['valid'] and not invalid_result['valid']:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼èŠ‚ç‚¹è§„èŒƒç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
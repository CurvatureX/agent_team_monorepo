name: Deploy to AWS ECS

on:
  push:
    branches: [main, develop]
    paths:
      - "apps/backend/**"
      - ".github/workflows/deploy.yml"
      - "infra/**"
  pull_request:
    branches: [main, develop]
    paths:
      - "apps/backend/**"
      - ".github/workflows/deploy.yml"
      - "infra/**"
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY_API_GATEWAY: agent-team/api-gateway
  ECR_REPOSITORY_WORKFLOW_AGENT: agent-team/workflow-agent
  ECR_REPOSITORY_WORKFLOW_ENGINE: agent-team/workflow-engine
  ECR_REPOSITORY_WORKFLOW_SCHEDULER: agent-team/workflow-scheduler

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies and test API Gateway
        working-directory: apps/backend
        run: |
          pip install uv
          uv sync
          uv pip install -e api-gateway/
          cd api-gateway
          rm -rf .pytest_cache __pycache__ **/__pycache__ **/*.pyc
          uv run -m pytest tests/ -v --cov=app --cov-report=xml

      - name: Install dependencies and test Workflow Agent
        working-directory: apps/backend
        run: |
          uv run -m pytest workflow_agent/tests/ -v --rootdir=. || echo "Tests not found, skipping"

      - name: Install dependencies and test Workflow Engine
        working-directory: apps/backend
        run: |
          uv run -m pytest workflow_engine/tests/ -v --rootdir=. || echo "Tests not found, skipping"

      - name: Install dependencies and test Workflow Scheduler
        working-directory: apps/backend
        run: |
          uv run -m pytest workflow_scheduler/tests/ -v --rootdir=. || echo "Tests not found, skipping"

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: apps/backend/coverage.xml
          flags: api-gateway
          name: api-gateway-coverage

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || github.event_name == 'pull_request'

    strategy:
      matrix:
        service:
          - name: api-gateway
            context: apps/backend
            dockerfile: apps/backend/api-gateway/Dockerfile
            repository: agent-team/api-gateway
          - name: workflow-agent
            context: apps/backend
            dockerfile: apps/backend/workflow_agent/Dockerfile
            repository: agent-team/workflow-agent
          - name: workflow-engine
            context: apps/backend
            dockerfile: apps/backend/workflow_engine/Dockerfile
            repository: agent-team/workflow-engine
          - name: workflow-scheduler
            context: apps/backend
            dockerfile: apps/backend/workflow_scheduler/Dockerfile
            repository: agent-team/workflow-scheduler

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repository if it doesn't exist
        run: |
          aws ecr describe-repositories --repository-names ${{ matrix.service.repository }} --region ${{ env.AWS_REGION }} || \
          aws ecr create-repository --repository-name ${{ matrix.service.repository }} --region ${{ env.AWS_REGION }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build, tag, and push image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Build and push Docker image
          docker buildx build \
            --platform linux/amd64 \
            --target production \
            --file ${{ matrix.service.dockerfile }} \
            --tag $ECR_REGISTRY/${{ matrix.service.repository }}:$IMAGE_TAG \
            --tag $ECR_REGISTRY/${{ matrix.service.repository }}:latest \
            --push \
            ${{ matrix.service.context }}

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Terraform Init
        working-directory: infra
        run: terraform init

      - name: Terraform Plan
        working-directory: infra
        env:
          TF_VAR_image_tag: ${{ github.sha }}
          TF_VAR_supabase_url: ${{ secrets.SUPABASE_URL }}
          TF_VAR_supabase_secret_key: ${{ secrets.SUPABASE_SECRET_KEY }}
          TF_VAR_supabase_anon_key: ${{ secrets.SUPABASE_ANON_KEY }}
          TF_VAR_openai_api_key: ${{ secrets.OPENAI_API_KEY }}
          TF_VAR_anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          TF_VAR_database_url: ${{ secrets.DATABASE_URL }}
          TF_VAR_grafana_cloud_api_key: ${{ secrets.GRAFANA_CLOUD_API_KEY }}
          TF_VAR_grafana_cloud_tenant_id: ${{ secrets.GRAFANA_CLOUD_TENANT_ID }}
          TF_VAR_github_app_id: ${{ secrets.GITAPP_APP_ID }}
          TF_VAR_github_app_private_key: ${{ secrets.GITAPP_PRIVATE_KEY }}
          TF_VAR_github_webhook_secret: ${{ secrets.GITAPP_WEBHOOK_SECRET }}
          TF_VAR_smtp_username: ${{ secrets.SMTP_USERNAME }}
          TF_VAR_smtp_password: ${{ secrets.SMTP_PASSWORD }}
        run: terraform plan -out=tfplan

      - name: Handle Service Discovery cleanup if needed
        run: |
          # Check if terraform plan shows service discovery services being recreated
          if grep -q "aws_service_discovery_service.*must be replaced" tfplan.txt 2>/dev/null || grep -q "Destroying.*service_discovery_service" infra/tfplan 2>/dev/null; then
            echo "Service Discovery services need cleanup - handling gracefully"

            # Get all service discovery instances that need cleanup
            SERVICES=$(aws servicediscovery list-services --query "Services[?Name=='api-gateway' || Name=='workflow-agent'].Id" --output text 2>/dev/null || echo "")

            for service_id in $SERVICES; do
              if [ ! -z "$service_id" ]; then
                echo "Checking instances for service: $service_id"
                aws servicediscovery list-instances --service-id "$service_id" --query "Instances[].Id" --output text | xargs -r -n1 -I {} aws servicediscovery deregister-instance --service-id "$service_id" --instance-id {} || true
                # Wait a moment for deregistration
                sleep 5
              fi
            done
          fi
        working-directory: infra

      - name: Terraform Apply
        working-directory: infra
        env:
          TF_VAR_image_tag: ${{ github.sha }}
          TF_VAR_supabase_url: ${{ secrets.SUPABASE_URL }}
          TF_VAR_supabase_secret_key: ${{ secrets.SUPABASE_SECRET_KEY }}
          TF_VAR_supabase_anon_key: ${{ secrets.SUPABASE_ANON_KEY }}
          TF_VAR_openai_api_key: ${{ secrets.OPENAI_API_KEY }}
          TF_VAR_anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          TF_VAR_database_url: ${{ secrets.DATABASE_URL }}
          TF_VAR_grafana_cloud_api_key: ${{ secrets.GRAFANA_CLOUD_API_KEY }}
          TF_VAR_grafana_cloud_tenant_id: ${{ secrets.GRAFANA_CLOUD_TENANT_ID }}
          TF_VAR_github_app_id: ${{ secrets.GITAPP_APP_ID }}
          TF_VAR_github_app_private_key: ${{ secrets.GITAPP_PRIVATE_KEY }}
          TF_VAR_github_webhook_secret: ${{ secrets.GITAPP_WEBHOOK_SECRET }}
          TF_VAR_smtp_username: ${{ secrets.SMTP_USERNAME }}
          TF_VAR_smtp_password: ${{ secrets.SMTP_PASSWORD }}
        run: terraform apply -auto-approve tfplan

      - name: Update ECS Service - API Gateway
        run: |
          aws ecs update-service \
            --cluster agent-prod-cluster \
            --service api-gateway-service \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}

      - name: Update ECS Service - Workflow Agent
        run: |
          aws ecs update-service \
            --cluster agent-prod-cluster \
            --service workflow-agent-service \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}

      - name: Update ECS Service - Workflow Engine
        run: |
          aws ecs update-service \
            --cluster agent-prod-cluster \
            --service workflow-engine-service \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}

      - name: Update ECS Service - Workflow Scheduler
        run: |
          aws ecs update-service \
            --cluster agent-prod-cluster \
            --service workflow-scheduler-service \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}

      - name: Update ECS Service - OTEL Collector
        run: |
          aws ecs update-service \
            --cluster agent-prod-cluster \
            --service agent-prod-otel-collector \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }} || echo "OTEL Collector service not found, skipping"

      - name: Wait for deployment to complete
        run: |
          # Base services that should always exist
          BASE_SERVICES="api-gateway-service workflow-agent-service workflow-engine-service workflow-scheduler-service"
          
          # Check which services are actually ACTIVE
          ACTIVE_SERVICES=""
          for service in $BASE_SERVICES; do
            STATUS=$(aws ecs describe-services \
              --cluster agent-prod-cluster \
              --services $service \
              --region ${{ env.AWS_REGION }} \
              --query "services[0].status" \
              --output text 2>/dev/null || echo "")
            
            if [ "$STATUS" = "ACTIVE" ]; then
              ACTIVE_SERVICES="$ACTIVE_SERVICES $service"
              echo "✓ Service $service is ACTIVE"
            else
              echo "⚠ Service $service is not ACTIVE (status: $STATUS), skipping"
            fi
          done
          
          # Check if OTEL collector exists and is ACTIVE
          OTEL_STATUS=$(aws ecs describe-services \
            --cluster agent-prod-cluster \
            --services agent-prod-otel-collector \
            --region ${{ env.AWS_REGION }} \
            --query "services[0].status" \
            --output text 2>/dev/null || echo "")
          
          if [ "$OTEL_STATUS" = "ACTIVE" ]; then
            ACTIVE_SERVICES="$ACTIVE_SERVICES agent-prod-otel-collector"
            echo "✓ OTEL Collector service is ACTIVE"
          else
            echo "ℹ OTEL Collector service is not ACTIVE (status: $OTEL_STATUS), skipping"
          fi
          
          # Only wait for ACTIVE services
          if [ -n "$ACTIVE_SERVICES" ]; then
            echo "Waiting for services to stabilize: $ACTIVE_SERVICES"
            aws ecs wait services-stable \
              --cluster agent-prod-cluster \
              --services $ACTIVE_SERVICES \
              --region ${{ env.AWS_REGION }} \
              --cli-read-timeout 1200
            echo "✅ All active services are stable"
          else
            echo "⚠ No active services found to wait for"
            exit 1
          fi

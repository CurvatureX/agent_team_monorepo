#!/usr/bin/env python3
"""
ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åŒæ—¶è®°å½•æŠ€æœ¯è°ƒè¯•æ—¥å¿—å’Œç”¨æˆ·å‹å¥½ä¸šåŠ¡æ—¥å¿—
"""

import asyncio
import sys
import time
from datetime import datetime
from pathlib import Path

# è®¾ç½®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from workflow_engine.services.unified_log_service import (
    create_legacy_compatible_logger,
    get_unified_log_service,
)


async def demo_unified_logging():
    """ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿæ¼”ç¤º"""

    print("=" * 80)
    print("ğŸ”„ ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿæ¼”ç¤º - åŒæ—¶æ”¯æŒæŠ€æœ¯å’Œä¸šåŠ¡æ—¥å¿—")
    print("=" * 80)
    print()

    execution_id = f"demo-unified-{int(time.time())}"
    log_service = get_unified_log_service()

    print(f"ğŸ“‹ æ‰§è¡ŒID: {execution_id}")
    print()

    # 1. ä¸šåŠ¡æ—¥å¿—è®°å½• - ç”¨æˆ·å‹å¥½ä¿¡æ¯
    print("ğŸ“ ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸šåŠ¡æ—¥å¿—è®°å½• (ç”¨æˆ·å‹å¥½)")
    print("-" * 50)

    # å·¥ä½œæµå¼€å§‹ - é‡Œç¨‹ç¢‘äº‹ä»¶
    await log_service.add_business_log(
        execution_id=execution_id,
        event_type="workflow_started",
        technical_message="Starting customer service workflow with 4 nodes",
        user_friendly_message="ğŸš€ å¼€å§‹æ‰§è¡Œå®¢æˆ·æœåŠ¡å·¥ä½œæµ (å…±4ä¸ªæ­¥éª¤)",
        display_priority=10,  # æœ€é«˜ä¼˜å…ˆçº§
        is_milestone=True,
        total_steps=4,
    )

    print("âœ… å·²è®°å½•: å·¥ä½œæµå¼€å§‹é‡Œç¨‹ç¢‘äº‹ä»¶")

    # æ­¥éª¤1 - AIåˆ†æ
    await log_service.add_business_log(
        execution_id=execution_id,
        event_type="step_started",
        technical_message="AI analysis step initiated",
        user_friendly_message="ğŸ“ æ­¥éª¤ [1/4] AIæ™ºèƒ½åˆ†æ - åˆ†æå®¢æˆ·è¯·æ±‚å†…å®¹",
        display_priority=7,  # é«˜ä¼˜å…ˆçº§
        step_number=1,
        total_steps=4,
        progress_percentage=25.0,
        node_name="AIåˆ†æ",
        node_type="AI_AGENT",
    )

    print("âœ… å·²è®°å½•: æ­¥éª¤1å¼€å§‹ - AIæ™ºèƒ½åˆ†æ")

    # æ­¥éª¤1å®Œæˆ
    await log_service.add_business_log(
        execution_id=execution_id,
        event_type="step_completed",
        technical_message="AI analysis completed successfully",
        user_friendly_message="âœ… AIæ™ºèƒ½åˆ†æå®Œæˆ - è¯†åˆ«ä¸ºè®¢å•æŸ¥è¯¢è¯·æ±‚",
        display_priority=7,
        step_number=1,
        total_steps=4,
        progress_percentage=25.0,
        duration_seconds=2,
        node_name="AIåˆ†æ",
    )

    print("âœ… å·²è®°å½•: æ­¥éª¤1å®Œæˆ - AIæ™ºèƒ½åˆ†æ")

    await asyncio.sleep(0.5)

    # 2. æŠ€æœ¯æ—¥å¿—è®°å½• - è¯¦ç»†è°ƒè¯•ä¿¡æ¯
    print("\nğŸ“ ç¬¬äºŒéƒ¨åˆ†ï¼šæŠ€æœ¯æ—¥å¿—è®°å½• (è¯¦ç»†è°ƒè¯•)")
    print("-" * 50)

    # OpenAI APIè°ƒç”¨è¯¦æƒ…
    await log_service.add_technical_log(
        execution_id=execution_id,
        level="DEBUG",
        message="OpenAI API call initiated",
        event_type="step_input",
        node_id="ai_analysis_node_001",
        node_name="AIåˆ†æ",
        node_type="AI_AGENT",
        technical_details={
            "api_endpoint": "https://api.openai.com/v1/chat/completions",
            "model": "gpt-4",
            "temperature": 0.2,
            "max_tokens": 1000,
            "request_id": "req_abc123def456",
        },
        performance_metrics={
            "request_start_time": datetime.now().isoformat(),
            "request_timeout": 30,
        },
    )

    print("âœ… å·²è®°å½•: OpenAI APIè°ƒç”¨å¼€å§‹è¯¦æƒ…")

    # APIå“åº”è¯¦æƒ…
    await log_service.add_technical_log(
        execution_id=execution_id,
        level="INFO",
        message="OpenAI API response received successfully",
        event_type="step_output",
        node_id="ai_analysis_node_001",
        duration_seconds=2,
        technical_details={
            "response_status": 200,
            "token_usage": {"prompt_tokens": 156, "completion_tokens": 89, "total_tokens": 245},
            "model_used": "gpt-4",
            "finish_reason": "stop",
        },
        performance_metrics={
            "response_time_ms": 1850,
            "tokens_per_second": 48.1,
            "latency_p95": 1923,
        },
    )

    print("âœ… å·²è®°å½•: OpenAI APIå“åº”è¯¦æƒ…å’Œæ€§èƒ½æŒ‡æ ‡")

    # é”™è¯¯åœºæ™¯ - æŠ€æœ¯é”™è¯¯
    await log_service.add_technical_log(
        execution_id=execution_id,
        level="ERROR",
        message="Slack API rate limit exceeded",
        event_type="step_error",
        node_id="slack_notification_node",
        node_name="Slacké€šçŸ¥",
        technical_details={
            "status_code": 429,
            "error_code": "rate_limited",
            "retry_after": 60,
            "api_endpoint": "/api/chat.postMessage",
            "request_headers": {
                "authorization": "Bearer xoxb-***",
                "content-type": "application/json",
            },
        },
        stack_trace="Traceback (most recent call last):\\n  File 'slack_node.py', line 45, in send_message\\n    response = requests.post(...)\\nSlackAPIError: rate_limited",
    )

    print("âœ… å·²è®°å½•: Slack APIé”™è¯¯å’ŒæŠ€æœ¯å †æ ˆä¿¡æ¯")

    # å¯¹åº”çš„ä¸šåŠ¡é”™è¯¯æ—¥å¿—
    await log_service.add_business_log(
        execution_id=execution_id,
        event_type="step_error",
        technical_message="Slack notification failed due to rate limiting",
        user_friendly_message="ğŸ’¥ Slacké€šçŸ¥å‘é€å¤±è´¥ - APIé€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•",
        level="ERROR",
        display_priority=9,  # é”™è¯¯äº‹ä»¶é«˜ä¼˜å…ˆçº§
        node_name="Slacké€šçŸ¥",
        step_number=4,
        total_steps=4,
    )

    print("âœ… å·²è®°å½•: å¯¹åº”çš„ç”¨æˆ·å‹å¥½é”™è¯¯ä¿¡æ¯")

    await asyncio.sleep(0.5)

    # 3. æŸ¥è¯¢ä¸åŒç±»å‹çš„æ—¥å¿—
    print("\nğŸ“ ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ†ç±»æ—¥å¿—æŸ¥è¯¢æ¼”ç¤º")
    print("-" * 50)

    # æŸ¥è¯¢ä¸šåŠ¡æ—¥å¿— - å‰ç«¯ç”¨æˆ·ç•Œé¢
    print("ğŸ” æŸ¥è¯¢ä¸šåŠ¡æ—¥å¿— (ç”¨æˆ·ç•Œé¢):")
    business_logs = await log_service.get_business_logs(
        execution_id=execution_id, min_priority=5, limit=10
    )

    for i, log in enumerate(business_logs, 1):
        priority_icon = "ğŸ”¥" if log.get("display_priority", 5) >= 8 else "ğŸ“‹"
        milestone_icon = "â­" if log.get("is_milestone", False) else ""
        message = log.get("user_friendly_message") or log.get("message")
        print(f"  {i}. {priority_icon}{milestone_icon} {message}")

    print(f"   å…±æ‰¾åˆ° {len(business_logs)} æ¡ä¸šåŠ¡æ—¥å¿—")

    # æŸ¥è¯¢æŠ€æœ¯æ—¥å¿— - å¼€å‘è°ƒè¯•
    print("\nğŸ” æŸ¥è¯¢æŠ€æœ¯æ—¥å¿— (å¼€å‘è°ƒè¯•):")
    technical_logs = await log_service.get_technical_logs(execution_id=execution_id, limit=5)

    for i, log in enumerate(technical_logs, 1):
        level = log.get("level", "INFO")
        level_icon = "âŒ" if level == "ERROR" else "ğŸ”§" if level == "DEBUG" else "â„¹ï¸"
        message = log.get("message", "")
        print(f"  {i}. {level_icon} [{level}] {message}")

        # æ˜¾ç¤ºæŠ€æœ¯ç»†èŠ‚
        tech_details = log.get("technical_details", {})
        if tech_details:
            key_details = []
            if "status_code" in tech_details:
                key_details.append(f"çŠ¶æ€ç : {tech_details['status_code']}")
            if "response_time_ms" in tech_details:
                key_details.append(f"å“åº”æ—¶é—´: {tech_details['response_time_ms']}ms")
            if "model" in tech_details:
                key_details.append(f"æ¨¡å‹: {tech_details['model']}")
            if key_details:
                print(f"      ğŸ’¡ {' | '.join(key_details)}")

    print(f"   å…±æ‰¾åˆ° {len(technical_logs)} æ¡æŠ€æœ¯æ—¥å¿—")

    # æŸ¥è¯¢é‡Œç¨‹ç¢‘äº‹ä»¶ - æ‰§è¡Œæ¦‚è§ˆï¼ˆé€šè¿‡ä¸šåŠ¡æ—¥å¿—è·å–ï¼‰
    print("\nğŸ” æŸ¥è¯¢é‡Œç¨‹ç¢‘äº‹ä»¶ (æ‰§è¡Œæ¦‚è§ˆ):")
    milestone_result = await log_service.get_business_logs(
        execution_id=execution_id, min_priority=7, milestones_only=True, limit=50, page=1  # é«˜ä¼˜å…ˆçº§
    )

    for i, log in enumerate(milestone_result.data, 1):
        message = log.get("user_friendly_message") or log.get("message")
        timestamp = log.get("timestamp", "")[:19].replace("T", " ")
        print(f"  {i}. â­ {message} ({timestamp})")

    print(f"   å…±æ‰¾åˆ° {len(milestone_result.data)} ä¸ªé‡Œç¨‹ç¢‘äº‹ä»¶")

    # 4. å…¼å®¹æ€§æ¼”ç¤º
    print("\nğŸ“ ç¬¬å››éƒ¨åˆ†ï¼šä¸ç°æœ‰BusinessLoggerå…¼å®¹æ€§")
    print("-" * 50)

    # ä½¿ç”¨å…¼å®¹æ€§æ¥å£
    legacy_logger = create_legacy_compatible_logger(execution_id, "å…¼å®¹æ€§æµ‹è¯•å·¥ä½œæµ")

    await legacy_logger.workflow_started(3, "APIè§¦å‘")
    print("âœ… ä½¿ç”¨å…¼å®¹æ¥å£è®°å½•å·¥ä½œæµå¼€å§‹")

    await legacy_logger.step_completed("æ•°æ®å¤„ç†", 1.5, "SUCCESS")
    print("âœ… ä½¿ç”¨å…¼å®¹æ¥å£è®°å½•æ­¥éª¤å®Œæˆ")

    # éªŒè¯å…¼å®¹æ€§æ—¥å¿—
    compat_logs = await log_service.get_business_logs(execution_id, min_priority=5)
    compat_count = len(
        [log for log in compat_logs if "å…¼å®¹æ€§" in log.get("user_friendly_message", "")]
    )
    print(f"âœ… å…¼å®¹æ€§æ—¥å¿—å·²æ­£ç¡®è®°å½•: {compat_count} æ¡")

    print()
    print("=" * 80)
    print("ğŸ‰ ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    print()
    print("ğŸ“Š æ€»ç»“ç»Ÿè®¡:")

    # æœ€ç»ˆç»Ÿè®¡
    all_business = await log_service.get_business_logs(
        execution_id, min_priority=1, limit=1000, page=1
    )
    all_technical = await log_service.get_technical_logs(execution_id, limit=1000, page=1)
    all_milestones = await log_service.get_business_logs(
        execution_id, min_priority=7, milestones_only=True, limit=1000, page=1
    )

    print(f"   ğŸ“‹ ä¸šåŠ¡æ—¥å¿—: {len(all_business.data)} æ¡")
    print(f"   ğŸ”§ æŠ€æœ¯æ—¥å¿—: {len(all_technical.data)} æ¡")
    print(f"   â­ é‡Œç¨‹ç¢‘äº‹ä»¶: {len(all_milestones.data)} ä¸ª")
    print(f"   ğŸ“ æ€»è®¡: {len(all_business.data) + len(all_technical.data)} æ¡æ—¥å¿—")
    print()
    print("ğŸ¯ ä½¿ç”¨åœºæ™¯éªŒè¯:")
    print("   âœ… å‰ç«¯ç”¨æˆ·ç•Œé¢ â†’ æŸ¥è¯¢ä¸šåŠ¡æ—¥å¿— (ä¸­æ–‡å‹å¥½)")
    print("   âœ… å¼€å‘è°ƒè¯•ç•Œé¢ â†’ æŸ¥è¯¢æŠ€æœ¯æ—¥å¿— (è¯¦ç»†ä¿¡æ¯)")
    print("   âœ… AI Agentåˆ†æ â†’ è·å–ç»“æ„åŒ–æŠ€æœ¯æ•°æ®")
    print("   âœ… æ‰§è¡Œæ¦‚è§ˆç•Œé¢ â†’ æ˜¾ç¤ºé‡Œç¨‹ç¢‘äº‹ä»¶")
    print("   âœ… ç°æœ‰ä»£ç å…¼å®¹ â†’ æ— ç¼è¿ç§»æ”¯æŒ")


async def demo_api_usage():
    """æ¼”ç¤ºå¦‚ä½•é€šè¿‡APIæŸ¥è¯¢åˆ†ç±»æ—¥å¿—"""

    print("\n" + "=" * 60)
    print("ğŸŒ APIæŸ¥è¯¢ç¤ºä¾‹")
    print("=" * 60)
    print()

    execution_id = "demo-api-example"

    print("ğŸ“‹ å‰ç«¯ä¸šåŠ¡æ—¥å¿—æŸ¥è¯¢:")
    print("   GET /v1/workflows/executions/{}/logs/business?min_priority=5".format(execution_id))
    print("   â†’ è¿”å›ç”¨æˆ·å‹å¥½çš„ä¸­æ–‡æ—¥å¿—ï¼Œé€‚åˆå‰ç«¯å±•ç¤º")
    print()

    print("ğŸ”§ æŠ€æœ¯è°ƒè¯•æ—¥å¿—æŸ¥è¯¢:")
    print(
        "   GET /v1/workflows/executions/{}/logs/technical?include_stack_trace=true".format(
            execution_id
        )
    )
    print("   â†’ è¿”å›è¯¦ç»†æŠ€æœ¯ä¿¡æ¯ï¼Œé€‚åˆå¼€å‘è°ƒè¯•")
    print()

    print("â­ é‡Œç¨‹ç¢‘äº‹ä»¶æŸ¥è¯¢:")
    print(
        "   GET /v1/workflows/executions/{}/logs/business?milestones_only=true&min_priority=7".format(
            execution_id
        )
    )
    print("   â†’ è¿”å›å…³é”®æ‰§è¡ŒèŠ‚ç‚¹ï¼Œé€‚åˆè¿›åº¦æ¦‚è§ˆï¼ˆé€šè¿‡ä¸šåŠ¡æ—¥å¿—è¿‡æ»¤è·å–ï¼‰")
    print()

    print("ğŸ”„ æ•°æ®è¿ç§»:")
    print("   POST /v1/workflows/executions/{}/logs/migrate".format(execution_id))
    print("   â†’ å°†ç°æœ‰ExecutionLogè¿ç§»åˆ°ç»Ÿä¸€æ ¼å¼")


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(demo_unified_logging())
    demo_api_usage()

    print("\nğŸš€ ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼")
    print("   æ‚¨ç°åœ¨å¯ä»¥:")
    print('   1. è¿è¡Œæ•°æ®åº“è¿ç§»: python -c "from migrations.add_unified_log_fields import *"')
    print("   2. å¯åŠ¨æœåŠ¡: python -m workflow_engine.main")
    print("   3. æµ‹è¯•API: curl http://localhost:8002/docs")
    print("   4. é›†æˆç°æœ‰ä»£ç : ä½¿ç”¨ create_legacy_compatible_logger()")

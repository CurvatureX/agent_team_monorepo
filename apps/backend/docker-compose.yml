
services:
  # ======================
  # Infrastructure Services
  # ======================

  # Redis - Shared cache for API Gateway rate limiting, JWT caching, and Workflow Agent state
  redis:
    image: redis:7-alpine
    container_name: agent-team-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - agent-team-network

  # Note: Using Supabase as primary database - no local PostgreSQL needed
  # All services connect directly to Supabase for data persistence and user management

  # Redis Commander - Redis management UI (development only)
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: agent-team-redis-ui
    profiles: ["dev", "development"]
    ports:
      - "8081:8081"
    environment:
      REDIS_HOSTS: "production:redis:6379"
      HTTP_USER: "admin"
      HTTP_PASSWORD: "${REDIS_UI_PASSWORD:-admin123}"
      HTTP_AUTH: "true"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - agent-team-network

  # ======================
  # Backend Services (gRPC)
  # ======================

  # Workflow Agent - AI workflow consultant (gRPC service on port 50051)
  workflow-agent:
    build:
      context: .
      dockerfile: ./workflow_agent/Dockerfile
      target: production
      args:
        - PYTHON_VERSION=3.11
    container_name: agent-team-workflow-agent
    environment:
      # Core service configuration
      DEBUG: "${DEBUG:-false}"
      GRPC_HOST: "${GRPC_HOST:-[::]}"
      GRPC_PORT: "${GRPC_PORT:-50051}"

      # Database configuration (Supabase)
      SUPABASE_URL: "${SUPABASE_URL}"
      SUPABASE_SECRET_KEY: "${SUPABASE_SECRET_KEY}"

      # Redis configuration for LangGraph checkpoints
      REDIS_URL: "redis://redis:6379/0"
      LANGGRAPH_CHECKPOINT_BACKEND: "redis"

      # AI API keys
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
      ANTHROPIC_API_KEY: "${ANTHROPIC_API_KEY}"

      # AI model configuration
      DEFAULT_MODEL_PROVIDER: "${DEFAULT_MODEL_PROVIDER:-openai}"
      DEFAULT_MODEL_NAME: "${DEFAULT_MODEL_NAME:-gpt-4}"

      # RAG configuration
      EMBEDDING_MODEL: "${EMBEDDING_MODEL:-text-embedding-ada-002}"
      RAG_SIMILARITY_THRESHOLD: "${RAG_SIMILARITY_THRESHOLD:-0.3}"

      # Service discovery (matches AWS ECS configuration)
      SERVICE_NAME: "workflow-agent"
      ENVIRONMENT: "${ENVIRONMENT:-development}"
    ports:
      - "50051:50051"
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./shared/proto:/app/shared/proto:ro
      - workflow_agent_logs:/app/logs
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "50051"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 240s # Matches production configuration
    restart: unless-stopped
    networks:
      - agent-team-network

  # Workflow Engine - Workflow execution engine (gRPC service on port 50050)
  workflow-engine:
    build:
      context: .
      dockerfile: ./workflow_engine/Dockerfile
      target: production
    container_name: agent-team-workflow-engine
    env_file:
      - ./.env
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "50050"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s

    networks:
      - agent-team-network

  # ======================
  # Frontend Gateway (HTTP)
  # ======================

  # API Gateway - Three-layer FastAPI service (HTTP on port 8000)
  api-gateway:
    build:
      context: .
      dockerfile: ./api-gateway/Dockerfile
    container_name: api_gateway_service
    ports:
      - "8000:8000"
    env_file:
      - ./.env
    environment:
      - WORKFLOW_SERVICE_HOST=workflow-engine
      - WORKFLOW_SERVICE_PORT=50050
    depends_on:
      redis:
        condition: service_healthy
      workflow-agent:
        condition: service_healthy
      workflow-engine:
        condition: service_healthy
    volumes:
      - ./shared/proto:/app/shared/proto:ro
      - api_gateway_logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/public/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s # Matches production configuration
    restart: unless-stopped
    networks:
      - agent-team-network

# ======================
# Volumes
# ======================
volumes:
  redis_data:
    driver: local
  workflow_agent_logs:
    driver: local
  workflow_engine_logs:
    driver: local
  api_gateway_logs:
    driver: local

# ======================
# Networks
# ======================
networks:
  app-network:
    driver: bridge

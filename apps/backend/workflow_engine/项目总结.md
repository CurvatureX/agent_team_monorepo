# Workflow Engine 项目总结

## 项目概述

Workflow Engine 是一个基于 FastAPI 构建的工作流执行引擎，负责工作流的创建、管理、执行和监控。该项目是 AI Teams 平台的核心组件之一，提供了灵活的工作流编排和执行能力。

## 技术架构

### 核心技术栈
- **Web 框架**: FastAPI + Uvicorn
- **数据库**: PostgreSQL (通过 Supabase) + SQLAlchemy ORM
- **缓存**: Redis
- **消息队列**: Celery
- **AI 集成**: OpenAI, Anthropic, LangChain
- **监控**: Prometheus, OpenTelemetry, Sentry
- **容器化**: Docker (支持 AWS ECS 部署)

### 服务配置
- **端口**: 8002 (可通过环境变量配置)
- **协议**: HTTP/REST API (已从 gRPC 迁移)
- **健康检查**: `/health` 端点
- **API 文档**: `/docs` (Swagger UI) 和 `/redoc`

## 项目结构

```
workflow_engine/
├── workflow_engine/          # 主应用目录
│   ├── main.py             # FastAPI 应用入口
│   ├── api/                # API 路由定义
│   │   ├── v1/            # v1 版本 API
│   │   └── app.py         # 节点规范 API
│   ├── core/              # 核心配置和工具
│   │   ├── config.py      # Pydantic 配置管理
│   │   └── database.py    # 数据库连接管理
│   ├── services/          # 业务服务层
│   │   ├── workflow_service.py      # 工作流 CRUD 服务
│   │   ├── execution_service.py     # 执行管理服务
│   │   └── validation_service.py    # 验证服务
│   ├── nodes/             # 节点实现
│   │   ├── factory.py     # 节点工厂模式
│   │   └── [各种节点类型实现]
│   ├── models/            # 数据模型
│   └── execution_engine.py # 执行引擎核心
├── database/              # 数据库相关
│   └── schema.sql        # 数据库架构定义
├── doc/                  # 文档目录
├── tests/               # 测试文件
├── Dockerfile           # Docker 配置
└── requirements.txt     # Python 依赖
```

## 核心功能模块

### 1. 工作流管理 (Workflow Service)
- **创建工作流**: 支持复杂的节点和连接配置
- **更新工作流**: 动态修改工作流配置
- **删除工作流**: 安全删除工作流及相关数据
- **查询工作流**: 支持多维度过滤和分页
- **节点模板管理**: 预定义的可重用节点配置

### 2. 执行引擎 (Execution Engine)
- **工作流执行**: 异步执行工作流实例
- **状态追踪**: 实时监控执行状态
- **错误处理**: 优雅的错误处理和重试机制
- **性能监控**: 详细的执行性能分析
- **执行历史**: 完整的执行记录保存

### 3. 节点系统 (Node System)
系统实现了 8 种核心节点类型：

1. **TriggerNode (触发节点)**: 时间触发、事件触发等
2. **AIAgentNode (AI 代理节点)**: 集成 AI 模型交互
3. **ActionNode (动作节点)**: 基础动作执行
4. **ExternalActionNode (外部动作节点)**: 第三方服务集成
5. **FlowNode (流程控制节点)**: 条件判断、循环等
6. **HumanLoopNode (人机协作节点)**: 人工介入点
7. **ToolNode (工具节点)**: 工具集成和 MCP 支持
8. **MemoryNode (记忆节点)**: 状态和数据管理

### 4. API 端点

#### 工作流相关 (`/v1/workflows`)
- `POST /workflows` - 创建新工作流
- `GET /workflows/{workflow_id}` - 获取工作流详情
- `PUT /workflows/{workflow_id}` - 更新工作流
- `DELETE /workflows/{workflow_id}` - 删除工作流
- `GET /workflows` - 列出工作流
- `GET /node-templates` - 获取节点模板

#### 执行相关 (`/v1/executions`)
- `POST /workflows/{workflow_id}/execute` - 执行工作流
- `GET /executions/{execution_id}` - 获取执行状态
- `POST /executions/{execution_id}/cancel` - 取消执行
- `GET /workflows/{workflow_id}/executions` - 获取执行历史

## 数据库设计

### 核心数据表
1. **workflows**: 工作流定义，使用 JSONB 存储灵活配置
2. **nodes**: 工作流中的节点配置
3. **node_connections**: 节点间的连接关系
4. **node_templates**: 可重用的节点模板
5. **workflow_executions**: 执行记录和状态
6. **users**: 用户管理（集成 Supabase）
7. **integrations**: 外部服务集成配置

### 数据库特性
- UUID 主键，支持分布式场景
- JSONB 字段支持灵活的配置存储
- 完善的索引优化查询性能
- 自动时间戳触发器记录审计信息

## 部署和运维

### Docker 配置
- 基础镜像: Python 3.11-slim
- 多阶段构建优化镜像大小
- 非 root 用户运行提升安全性
- 健康检查确保服务稳定性
- 支持 AWS ECS 部署 (linux/amd64)

### 环境变量配置
```bash
# 必需配置
DATABASE_URL=postgresql://user:pass@host/dbname
PORT=8002

# AI 服务集成
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# 其他服务
REDIS_URL=redis://localhost:6379
```

### 监控和日志
- **Prometheus**: 指标收集
- **OpenTelemetry**: 分布式追踪
- **Sentry**: 错误追踪
- **结构化日志**: 便于分析和调试

## 关键特性

1. **模块化设计**: 清晰的分层架构，易于维护和扩展
2. **高性能**: Redis 缓存、数据库连接池优化
3. **可扩展性**: 工厂模式支持自定义节点类型
4. **AI 原生**: 深度集成多个 AI 提供商
5. **可观测性**: 完善的监控和日志体系
6. **安全性**: Supabase 认证集成，安全的容器部署
7. **开发友好**: 自动生成 API 文档，完善的错误提示

## 未来展望

- 支持更多节点类型和集成
- 增强的工作流版本管理
- 分布式执行能力
- 更强大的监控和分析功能
- 工作流模板市场

## 相关文档

- [架构设计文档](doc/WORKFLOW_ENGINE_ARCHITECTURE.md)
- [节点实现指南](doc/NODE_IMPLEMENTATION_SUMMARY.md)
- [本地开发指南](doc/LOCAL_SETUP_GUIDE.md)
- [调试指南](doc/DEBUG_GUIDE.md)
- [执行引擎详解](doc/ENHANCED_EXECUTION_IMPLEMENTATION.md)

---

*该项目是 AI Teams 平台的核心组件，为构建智能化、自动化的工作流提供了强大的基础设施支持。*
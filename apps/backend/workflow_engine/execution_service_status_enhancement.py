#!/usr/bin/env python3
"""
ExecutionServiceçŠ¶æ€ç®¡ç†å¢å¼ºè¡¥ä¸
å¯¹ç°æœ‰ExecutionServiceè¿›è¡Œæœ€å°ä¾µå…¥æ€§çš„çŠ¶æ€ç®¡ç†å¢å¼º
"""

import asyncio
import logging
from datetime import datetime
from typing import Optional

logger = logging.getLogger(__name__)


def enhance_execution_service_status_management(execution_service):
    """
    å¢å¼ºExecutionServiceçš„çŠ¶æ€ç®¡ç†åŠŸèƒ½

    Args:
        execution_service: ç°æœ‰çš„ExecutionServiceå®ä¾‹
    """

    # ä¿å­˜åŸå§‹æ–¹æ³•
    original_update_status = execution_service._update_execution_status

    async def enhanced_update_execution_status(
        execution_id: str, status: str, error_message: str = None, max_retries: int = 3
    ):
        """å¢å¼ºçš„çŠ¶æ€æ›´æ–°æ–¹æ³• - å¸¦é‡è¯•å’Œé€šçŸ¥"""

        for attempt in range(max_retries):
            try:
                # è·å–æ—§çŠ¶æ€ç”¨äºé€šçŸ¥
                from shared.models.db_models import ExecutionModel

                db_execution = (
                    execution_service.db.query(ExecutionModel)
                    .filter(ExecutionModel.execution_id == execution_id)
                    .first()
                )

                old_status = db_execution.status if db_execution else "UNKNOWN"

                # è°ƒç”¨åŸå§‹æ›´æ–°æ–¹æ³•
                original_update_status(execution_id, status, error_message)

                # æ·»åŠ çŠ¶æ€å˜æ›´æ—¥å¿—
                logger.info(f"âœ… Enhanced status update: {execution_id} [{old_status} â†’ {status}]")

                # å¼‚æ­¥è®°å½•ä¸šåŠ¡æ—¥å¿—ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
                asyncio.create_task(
                    log_status_change_to_business_log(
                        execution_id, old_status, status, error_message
                    )
                )

                return True

            except Exception as e:
                logger.warning(
                    f"Status update attempt {attempt + 1} failed for {execution_id}: {e}"
                )
                execution_service.db.rollback()

                if attempt < max_retries - 1:
                    await asyncio.sleep(2**attempt)  # æŒ‡æ•°é€€é¿
                else:
                    logger.error(
                        f"âŒ Failed to update status after {max_retries} attempts: {execution_id}"
                    )
                    raise

    # æ›¿æ¢åŸå§‹æ–¹æ³•
    execution_service._update_execution_status_enhanced = enhanced_update_execution_status

    # æ·»åŠ è¶…æ—¶æ£€æµ‹æ–¹æ³•
    async def detect_stalled_executions(timeout_hours: int = 2):
        """æ£€æµ‹å¹¶å¤„ç†è¶…æ—¶æ‰§è¡Œ"""
        try:
            from sqlalchemy import func

            from shared.models.db_models import ExecutionModel, ExecutionStatus

            timeout_threshold = timeout_hours * 3600
            current_time = int(datetime.now().timestamp())

            stalled_executions = (
                execution_service.db.query(ExecutionModel)
                .filter(
                    ExecutionModel.status == ExecutionStatus.RUNNING.value,
                    ExecutionModel.start_time < current_time - timeout_threshold,
                )
                .all()
            )

            for execution in stalled_executions:
                runtime_hours = (current_time - execution.start_time) / 3600
                logger.warning(
                    f"â° Stalled execution detected: {execution.execution_id} "
                    f"(running {runtime_hours:.1f}h)"
                )

                # ä½¿ç”¨å¢å¼ºçš„çŠ¶æ€æ›´æ–°
                await enhanced_update_execution_status(
                    execution.execution_id,
                    ExecutionStatus.ERROR.value,
                    f"Execution timeout after {runtime_hours:.1f} hours",
                )

            return len(stalled_executions)

        except Exception as e:
            logger.error(f"Failed to detect stalled executions: {e}")
            return 0

    execution_service.detect_stalled_executions = detect_stalled_executions

    # æ·»åŠ çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥
    async def check_status_consistency():
        """æ£€æŸ¥çŠ¶æ€ä¸€è‡´æ€§"""
        try:
            from sqlalchemy import text

            # æŸ¥æ‰¾ä¸ä¸€è‡´çš„è®°å½•
            inconsistent_query = text(
                """
                SELECT execution_id, status, start_time, end_time
                FROM workflow_executions
                WHERE (status = 'RUNNING' AND end_time IS NOT NULL)
                   OR (status IN ('SUCCESS', 'ERROR', 'CANCELED') AND end_time IS NULL)
                LIMIT 50
            """
            )

            inconsistent_records = execution_service.db.execute(inconsistent_query).fetchall()

            fixed_count = 0
            for record in inconsistent_records:
                logger.warning(f"Status inconsistency found: {record.execution_id}")

                # ç®€å•ä¿®å¤ï¼šä¸ºå·²å®Œæˆçš„æ‰§è¡Œæ·»åŠ ç»“æŸæ—¶é—´
                if record.status in ["SUCCESS", "ERROR", "CANCELED"] and not record.end_time:
                    from shared.models.db_models import ExecutionModel

                    db_execution = (
                        execution_service.db.query(ExecutionModel)
                        .filter(ExecutionModel.execution_id == record.execution_id)
                        .first()
                    )

                    if db_execution:
                        db_execution.end_time = int(datetime.now().timestamp())
                        execution_service.db.commit()
                        fixed_count += 1
                        logger.info(f"âœ… Fixed missing end_time for {record.execution_id}")

            return {"inconsistent_found": len(inconsistent_records), "fixed": fixed_count}

        except Exception as e:
            logger.error(f"Status consistency check failed: {e}")
            return {"inconsistent_found": 0, "fixed": 0}

    execution_service.check_status_consistency = check_status_consistency

    logger.info("âœ… ExecutionService status management enhanced")
    return execution_service


async def log_status_change_to_business_log(
    execution_id: str, old_status: str, new_status: str, error_message: Optional[str] = None
):
    """è®°å½•çŠ¶æ€å˜æ›´åˆ°ä¸šåŠ¡æ—¥å¿—"""
    try:
        from workflow_engine.services.unified_log_service import get_unified_log_service

        status_emoji = {
            "NEW": "ğŸ†•",
            "RUNNING": "ğŸš€",
            "SUCCESS": "âœ…",
            "ERROR": "âŒ",
            "PAUSED": "â¸ï¸",
            "CANCELED": "ğŸš«",
        }

        emoji = status_emoji.get(new_status, "ğŸ“Š")
        user_message = f"{emoji} æ‰§è¡ŒçŠ¶æ€: {old_status} â†’ {new_status}"

        if error_message and new_status == "ERROR":
            user_message += f" | {error_message}"

        log_service = get_unified_log_service()
        await log_service.add_business_log(
            execution_id=execution_id,
            event_type="status_change",
            technical_message=f"Status: {old_status} â†’ {new_status}",
            user_friendly_message=user_message,
            display_priority=7,
            is_milestone=new_status in ["RUNNING", "SUCCESS", "ERROR"],
            data={
                "old_status": old_status,
                "new_status": new_status,
                "error_message": error_message,
                "timestamp": datetime.now().isoformat(),
            },
        )

    except Exception as e:
        logger.error(f"Failed to log status change: {e}")


class ExecutionStatusMonitor:
    """æ‰§è¡ŒçŠ¶æ€ç›‘æ§å™¨ - åå°ä»»åŠ¡"""

    def __init__(self, execution_service):
        self.execution_service = execution_service
        self.running = False
        self.check_interval = 300  # 5åˆ†é’Ÿ

    async def start_monitoring(self):
        """å¯åŠ¨çŠ¶æ€ç›‘æ§"""
        if self.running:
            return

        self.running = True
        logger.info("ğŸ” Starting execution status monitoring")

        while self.running:
            try:
                # æ£€æµ‹è¶…æ—¶æ‰§è¡Œ
                stalled_count = await self.execution_service.detect_stalled_executions()
                if stalled_count > 0:
                    logger.info(f"Detected and handled {stalled_count} stalled executions")

                # æ£€æŸ¥çŠ¶æ€ä¸€è‡´æ€§
                consistency_result = await self.execution_service.check_status_consistency()
                if consistency_result["fixed"] > 0:
                    logger.info(f"Fixed {consistency_result['fixed']} status inconsistencies")

                await asyncio.sleep(self.check_interval)

            except Exception as e:
                logger.error(f"Status monitoring error: {e}")
                await asyncio.sleep(60)  # å‡ºé”™åçŸ­æš‚ç­‰å¾…

    async def stop_monitoring(self):
        """åœæ­¢çŠ¶æ€ç›‘æ§"""
        self.running = False
        logger.info("â¹ï¸ Stopped execution status monitoring")


# ä½¿ç”¨ç¤ºä¾‹å’Œé›†æˆæŒ‡å—
def integrate_enhanced_status_management():
    """é›†æˆå¢å¼ºçŠ¶æ€ç®¡ç†çš„ç¤ºä¾‹"""

    print("ğŸ”§ ExecutionServiceçŠ¶æ€ç®¡ç†å¢å¼ºé›†æˆæŒ‡å—")
    print("=" * 60)

    integration_code = """
# 1. åœ¨ExecutionServiceåˆå§‹åŒ–æ—¶å¢å¼º
from workflow_engine.services.execution_service import ExecutionService
from execution_service_status_enhancement import enhance_execution_service_status_management

def create_enhanced_execution_service(db):
    service = ExecutionService(db)
    enhanced_service = enhance_execution_service_status_management(service)
    return enhanced_service

# 2. å¯åŠ¨åå°çŠ¶æ€ç›‘æ§
async def start_status_monitoring(execution_service):
    monitor = ExecutionStatusMonitor(execution_service)
    monitoring_task = asyncio.create_task(monitor.start_monitoring())
    return monitoring_task

# 3. åœ¨ä¸»åº”ç”¨ä¸­é›†æˆ
async def main():
    db = get_database_session()
    execution_service = create_enhanced_execution_service(db)

    # å¯åŠ¨çŠ¶æ€ç›‘æ§
    monitoring_task = await start_status_monitoring(execution_service)

    # åº”ç”¨ä¸»é€»è¾‘...

    # å…³é—­æ—¶åœæ­¢ç›‘æ§
    await monitor.stop_monitoring()
    monitoring_task.cancel()

# 4. æ‰‹åŠ¨è°ƒç”¨å¢å¼ºåŠŸèƒ½
async def manual_status_check(execution_service):
    # æ£€æµ‹è¶…æ—¶æ‰§è¡Œ
    stalled_count = await execution_service.detect_stalled_executions()
    print(f"Found {stalled_count} stalled executions")

    # æ£€æŸ¥çŠ¶æ€ä¸€è‡´æ€§
    consistency = await execution_service.check_status_consistency()
    print(f"Consistency check: {consistency}")
    """

    print(integration_code)

    print("\nğŸ“‹ é›†æˆæ£€æŸ¥æ¸…å•:")
    checklist = [
        "âœ… å¯¼å…¥å¢å¼ºæ¨¡å—",
        "âœ… åœ¨æœåŠ¡åˆå§‹åŒ–æ—¶è°ƒç”¨enhance_execution_service_status_management()",
        "âœ… å¯åŠ¨ExecutionStatusMonitoråå°ä»»åŠ¡",
        "âœ… åœ¨åº”ç”¨å…³é—­æ—¶åœæ­¢ç›‘æ§",
        "âœ… é…ç½®æ—¥å¿—çº§åˆ«ä»¥æŸ¥çœ‹çŠ¶æ€æ›´æ–°",
        "ğŸ”§ å¯é€‰: æ·»åŠ çŠ¶æ€å˜æ›´WebSocketé€šçŸ¥",
        "ğŸ”§ å¯é€‰: é…ç½®ç›‘æ§æŠ¥è­¦æœºåˆ¶",
    ]

    for item in checklist:
        print(f"  {item}")

    print(f"\nâš¡ é¢„æœŸæ•ˆæœ:")
    effects = [
        "çŠ¶æ€æ›´æ–°å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•",
        "çŠ¶æ€å˜æ›´è‡ªåŠ¨è®°å½•åˆ°ä¸šåŠ¡æ—¥å¿—",
        "è‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†è¶…æ—¶æ‰§è¡Œ",
        "è‡ªåŠ¨ä¿®å¤çŠ¶æ€ä¸€è‡´æ€§é—®é¢˜",
        "è¯¦ç»†çš„çŠ¶æ€å˜æ›´æ—¥å¿—è®°å½•",
        "åå°æŒç»­ç›‘æ§å¼‚å¸¸çŠ¶æ€",
    ]

    for effect in effects:
        print(f"  âœ… {effect}")


if __name__ == "__main__":
    integrate_enhanced_status_management()

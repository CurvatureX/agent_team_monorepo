测试用例 1：简单需求 - 无能力缺口
输入：「每天检查我们的产品仓库有没有新的 bug 报告，有的话发钉钉群通知开发团队」
预期 AI 行为：

快速扫描识别：GitHub✅ + 钉钉 ✅ + 定时触发 ✅ = 无缺口
简单澄清：「每天几点检查？」「监控哪个仓库？」「发到哪个钉钉群？」
直接生成：TRIGGER_CRON → EXTERNAL_GITHUB → EXTERNAL_DINGTALK
测试重点：基础能力匹配和简单参数收集

测试用例 2：中等复杂 - AI 能力协同
输入：「监控竞争对手的 GitHub 开源项目更新，AI 分析技术趋势，每月生成报告保存到飞书文档」
预期 AI 行为：

扫描识别：GitHub✅ + AI 分析 ✅ + 飞书 ✅ = 无缺口，可 AI 协同
智能建议：「建议三层 AI 处理：筛选 → 分析 → 报告生成，确保质量」
配置引导：「分析重点是技术创新还是市场策略？」「报告详细程度？」
生成工作流：TRIGGER_CRON → EXTERNAL_GITHUB → AI_TASK_ANALYZER → AI_REPORT_GENERATOR → TOOL_FEISHU
测试重点：AI 能力组合建议和智能配置引导

测试用例 3：跨系统集成 - 需要协商边界
输入：「Jira 有新需求时，自动在 GitHub 创建对应任务，更新项目看板，如果是紧急需求还要给产品经理发邮件」
预期 AI 行为：

复杂度评估：跨系统数据映射 + 条件分支逻辑
智能映射建议：「Jira 优先级如何映射到 GitHub 标签？」「紧急程度如何判定？」
协同设计提醒：「涉及 4 个系统认证，建议配置重试机制」
生成工作流：TRIGGER_JIRA → TRANSFORM_DATA → EXTERNAL_GITHUB → EXTERNAL_NOTION → FLOW_IF → EXTERNAL_GMAIL
测试重点：跨系统映射能力和错误处理建议

测试用例 4：高复杂需求 - 需要替代方案
输入：「微信工作群里有人@我的时候，自动分析问题类型，简单问题 AI 回答，复杂问题转给相关同事」
预期 AI 行为：

快速扫描：微信集成 ❌ + AI 分析 ✅ + 人工转接 ✅ = 有关键缺口
替代方案协商：「微信个人号难以集成，建议：1.企业微信 API 2.飞书群智能助手 3.邮件智能问答」
边界协商：「如何判断问题复杂度？按关键词、情感还是 AI 信心度？」
重新设计：根据用户选择的替代方案生成相应工作流
测试重点：缺口识别、替代方案提供和边界协商能力

测试用例 5：模糊表达 - 智能补全和澄清
输入：「搞个那种...监控网上关于我们公司的评价，不好的评价要及时处理，好的要推广利用」
预期 AI 行为：

理解模糊表达：识别出「舆情监控 + 自动分类 + 差异化处理」需求
智能补全建议：「检测到舆情监控需求，建议配置：1.多平台监控 2.情感分析分类 3.负面预警机制 4.正面内容收集」
澄清关键参数：「监控哪些平台？」「负面评价如何定义？」「处理团队联系方式？」
能力边界说明：「部分社交平台需要 API 权限，可提供 webhook 集成方案」
生成智能工作流：包含多平台监控、AI 情感分析、条件分支和人工协作节点
测试重点：自然语言理解、需求补全、边界说明和智能建议能力

这 5 个测试用例覆盖了从简单到复杂、从明确到模糊的完整场景谱系，可以全面测试 AI Agent 的能力识别、方案设计、边界协商和用户引导能力。

自测 Notes:

1. 测试一下一个简单的 case:
   每天检查我们的 Github 仓库有没有新的 bug 报告，有的话发钉钉群通知开发团队

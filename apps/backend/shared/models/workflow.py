# å·¥ä½œæµç›¸å…³çš„ Pydantic æ¨¡å‹
from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field, field_validator

from .common import BaseResponse, EntityModel
from .node_enums import NodeType


class PositionData(BaseModel):
    """èŠ‚ç‚¹ä½ç½®æ•°æ®"""

    x: float
    y: float


class RetryPolicyData(BaseModel):
    """é‡è¯•ç­–ç•¥æ•°æ®"""

    max_tries: int = Field(default=3, ge=1, le=10)
    wait_between_tries: int = Field(default=5, ge=1, le=300)  # seconds


class NodeData(BaseModel):
    """
    å·¥ä½œæµèŠ‚ç‚¹æ•°æ®

    ğŸ¯ WORKFLOW GENERATION TIP:
    When using HUMAN_IN_THE_LOOP nodes, they have built-in AI response analysis capabilities.
    Use their confirmed/rejected/unrelated/timeout output ports instead of creating
    separate AI_AGENT or FLOW (IF) nodes for response classification.
    """

    id: Optional[str] = None  # å¯é€‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆ
    name: str
    type: str
    subtype: str
    type_version: int = Field(default=1)
    position: PositionData
    parameters: Dict[str, Any] = Field(default_factory=dict)
    credentials: Dict[str, str] = Field(default_factory=dict)
    disabled: bool = False
    on_error: str = Field(default="continue", pattern="^(continue|stop)$")
    retry_policy: Optional[RetryPolicyData] = None
    notes: Dict[str, str] = Field(default_factory=dict)
    webhooks: List[str] = Field(default_factory=list)


class ConnectionData(BaseModel):
    """è¿æ¥æ•°æ®"""

    node: str
    type: str
    index: int = Field(default=0)


class ConnectionArrayData(BaseModel):
    """è¿æ¥æ•°ç»„æ•°æ®"""

    connections: List[ConnectionData] = Field(default_factory=list)


class NodeConnectionsData(BaseModel):
    """èŠ‚ç‚¹è¿æ¥æ•°æ®"""

    connection_types: Dict[str, ConnectionArrayData] = Field(default_factory=dict)


class WorkflowSettingsData(BaseModel):
    """å·¥ä½œæµè®¾ç½®æ•°æ®"""

    timezone: Dict[str, str] = Field(default_factory=dict)
    save_execution_progress: bool = True
    save_manual_executions: bool = True
    timeout: int = Field(default=3600, ge=60, le=86400)  # 1 hour default, max 24 hours
    error_policy: str = Field(default="continue", pattern="^(continue|stop)$")
    caller_policy: str = Field(default="workflow", pattern="^(workflow|user)$")

    @field_validator("timezone", mode="before")
    @classmethod
    def validate_timezone(cls, v):
        if isinstance(v, str):
            return {"name": v}
        return v


class WorkflowData(BaseModel):
    """å·¥ä½œæµæ•°æ®"""

    id: Optional[str] = None
    name: str
    description: Optional[str] = None
    nodes: List[NodeData]
    connections: Dict[str, Any] = Field(
        default_factory=dict
    )  # Keep as Any for now to handle validation properly
    settings: WorkflowSettingsData
    static_data: Dict[str, str] = Field(default_factory=dict)
    pin_data: Dict[str, str] = Field(default_factory=dict)
    tags: List[str] = Field(default_factory=list)
    active: bool = True
    created_at: Optional[int] = None
    updated_at: Optional[int] = None
    version: str = Field(default="1.0")

    @field_validator("name")
    @classmethod
    def name_must_not_be_empty(cls, v):
        if not v.strip():
            raise ValueError("Workflow name cannot be empty")
        return v.strip()

    @field_validator("nodes")
    @classmethod
    def validate_nodes(cls, v):
        if not v:
            raise ValueError("Workflow must contain at least one node")
        node_ids = [node.id for node in v]
        if len(node_ids) != len(set(node_ids)):
            raise ValueError("Node IDs must be unique")
        return v

    @field_validator("connections", mode="before")
    @classmethod
    def validate_connections_format(cls, v):
        """Validate connections format and node references."""
        if not isinstance(v, dict):
            return v

        # Check each source node connection
        for source_node_id, node_connections in v.items():
            # Handle both dict and NodeConnectionsData objects
            if isinstance(node_connections, NodeConnectionsData):
                # Already a valid NodeConnectionsData object, skip validation
                continue
            elif not isinstance(node_connections, dict):
                raise ValueError(
                    f"Invalid connection format for node '{source_node_id}': must be an object"
                )

            # Detect old target-centric format and reject it
            if "main" in node_connections and isinstance(node_connections["main"], list):
                # This is the old format with nested arrays
                if len(node_connections["main"]) > 0 and isinstance(
                    node_connections["main"][0], list
                ):
                    raise ValueError(
                        f"Detected legacy connection format for node '{source_node_id}'. Use connection_types structure instead."
                    )

            # Validate new format structure
            if "connection_types" not in node_connections:
                raise ValueError(
                    f"Missing 'connection_types' in connections for node '{source_node_id}'. Required format: connection_types->main->connections"
                )

            connection_types = node_connections.get("connection_types", {})
            if not isinstance(connection_types, dict):
                raise ValueError(
                    f"'connection_types' must be an object for node '{source_node_id}'"
                )

            for conn_type, conn_array in connection_types.items():
                if not isinstance(conn_array, dict) or "connections" not in conn_array:
                    raise ValueError(
                        f"Invalid connection array format for '{source_node_id}.{conn_type}': must have 'connections' field"
                    )

                connections_list = conn_array.get("connections", [])
                if not isinstance(connections_list, list):
                    raise ValueError(
                        f"'connections' must be a list for '{source_node_id}.{conn_type}'"
                    )

                # Validate each connection has required fields
                for i, conn in enumerate(connections_list):
                    if not isinstance(conn, dict):
                        raise ValueError(
                            f"Connection {i} in '{source_node_id}.{conn_type}' must be an object"
                        )
                    if "node" not in conn:
                        raise ValueError(
                            f"Connection {i} in '{source_node_id}.{conn_type}' missing required 'node' field"
                        )

        return v


# Engine specific models
class CreateWorkflowRequest(BaseModel):
    """åˆ›å»ºå·¥ä½œæµè¯·æ±‚"""

    name: str = Field(..., min_length=1, max_length=255)
    description: Optional[str] = Field(None, max_length=1000)
    nodes: List[NodeData] = Field(..., min_items=1)
    connections: Dict[str, Any] = Field(default_factory=dict)
    settings: Optional[WorkflowSettingsData] = None
    static_data: Dict[str, str] = Field(default_factory=dict)
    tags: List[str] = Field(default_factory=list)
    user_id: str = Field(..., min_length=1)
    session_id: Optional[str] = None

    @field_validator("name")
    @classmethod
    def name_must_not_be_empty(cls, v):
        if not v.strip():
            raise ValueError("å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©ºæˆ–ä»…åŒ…å«ç©ºæ ¼")
        return v.strip()

    @field_validator("nodes")
    @classmethod
    def validate_node_connections(cls, v):
        if not v:
            raise ValueError("å·¥ä½œæµå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹")
        # åªæ£€æŸ¥éç©ºçš„èŠ‚ç‚¹ ID
        node_ids = [node.id for node in v if node.id is not None]
        if len(node_ids) != len(set(node_ids)):
            raise ValueError("èŠ‚ç‚¹IDå¿…é¡»å”¯ä¸€")
        return v

    @field_validator("connections", mode="before")
    @classmethod
    def validate_connections_format(cls, v):
        """Validate connections format and node references."""
        if not isinstance(v, dict):
            return v

        # Check each source node connection
        for source_node_id, node_connections in v.items():
            # Handle both dict and NodeConnectionsData objects
            if isinstance(node_connections, NodeConnectionsData):
                # Already a valid NodeConnectionsData object, skip validation
                continue
            elif not isinstance(node_connections, dict):
                raise ValueError(
                    f"Invalid connection format for node '{source_node_id}': must be an object"
                )

            # Detect old target-centric format and reject it
            if "main" in node_connections and isinstance(node_connections["main"], list):
                # This is the old format with nested arrays
                if len(node_connections["main"]) > 0 and isinstance(
                    node_connections["main"][0], list
                ):
                    raise ValueError(
                        f"Detected legacy connection format for node '{source_node_id}'. Use connection_types structure instead."
                    )

            # Validate new format structure
            if "connection_types" not in node_connections:
                raise ValueError(
                    f"Missing 'connection_types' in connections for node '{source_node_id}'. Required format: connection_types->main->connections"
                )

            connection_types = node_connections.get("connection_types", {})
            if not isinstance(connection_types, dict):
                raise ValueError(
                    f"'connection_types' must be an object for node '{source_node_id}'"
                )

            for conn_type, conn_array in connection_types.items():
                if not isinstance(conn_array, dict) or "connections" not in conn_array:
                    raise ValueError(
                        f"Invalid connection array format for '{source_node_id}.{conn_type}': must have 'connections' field"
                    )

                connections_list = conn_array.get("connections", [])
                if not isinstance(connections_list, list):
                    raise ValueError(
                        f"'connections' must be a list for '{source_node_id}.{conn_type}'"
                    )

                # Validate each connection has required fields
                for i, conn in enumerate(connections_list):
                    if not isinstance(conn, dict):
                        raise ValueError(
                            f"Connection {i} in '{source_node_id}.{conn_type}' must be an object"
                        )
                    if "node" not in conn:
                        raise ValueError(
                            f"Connection {i} in '{source_node_id}.{conn_type}' missing required 'node' field"
                        )

        return v


class CreateWorkflowResponse(BaseModel):
    workflow: WorkflowData
    success: bool = True
    message: str = "Workflow created successfully"


class GetWorkflowRequest(BaseModel):
    workflow_id: str = Field(..., min_length=1)
    user_id: str = Field(..., min_length=1)
    session_id: Optional[str] = None


class GetWorkflowResponse(BaseModel):
    """è·å–å·¥ä½œæµå“åº”"""

    workflow: Optional[WorkflowData] = None
    found: bool
    message: str = ""


class UpdateWorkflowRequest(BaseModel):
    """æ›´æ–°å·¥ä½œæµè¯·æ±‚"""

    workflow_id: str = Field(..., min_length=1)
    name: Optional[str] = Field(None, min_length=1, max_length=255)
    description: Optional[str] = Field(None, max_length=1000)
    nodes: Optional[List[NodeData]] = None
    connections: Optional[Dict[str, Any]] = None
    settings: Optional[WorkflowSettingsData] = None
    static_data: Optional[Dict[str, str]] = None
    tags: Optional[List[str]] = None
    active: Optional[bool] = None
    user_id: str = Field(..., min_length=1)
    session_id: Optional[str] = None

    @field_validator("connections", mode="before")
    @classmethod
    def validate_connections_format(cls, v):
        """Validate connections format when provided."""
        if v is None:
            return v
        if not isinstance(v, dict):
            return v

        # Check each source node connection
        for source_node_id, node_connections in v.items():
            # Handle both dict and NodeConnectionsData objects
            if isinstance(node_connections, NodeConnectionsData):
                # Already a valid NodeConnectionsData object, skip validation
                continue
            elif not isinstance(node_connections, dict):
                raise ValueError(
                    f"Invalid connection format for node '{source_node_id}': must be an object"
                )

            # Detect old target-centric format and reject it
            if "main" in node_connections and isinstance(node_connections["main"], list):
                # This is the old format with nested arrays
                if len(node_connections["main"]) > 0 and isinstance(
                    node_connections["main"][0], list
                ):
                    raise ValueError(
                        f"Detected legacy connection format for node '{source_node_id}'. Use connection_types structure instead."
                    )

            # Validate new format structure
            if "connection_types" not in node_connections:
                raise ValueError(
                    f"Missing 'connection_types' in connections for node '{source_node_id}'. Required format: connection_types->main->connections"
                )

            connection_types = node_connections.get("connection_types", {})
            if not isinstance(connection_types, dict):
                raise ValueError(
                    f"'connection_types' must be an object for node '{source_node_id}'"
                )

            for conn_type, conn_array in connection_types.items():
                if not isinstance(conn_array, dict) or "connections" not in conn_array:
                    raise ValueError(
                        f"Invalid connection array format for '{source_node_id}.{conn_type}': must have 'connections' field"
                    )

                connections_list = conn_array.get("connections", [])
                if not isinstance(connections_list, list):
                    raise ValueError(
                        f"'connections' must be a list for '{source_node_id}.{conn_type}'"
                    )

                # Validate each connection has required fields
                for i, conn in enumerate(connections_list):
                    if not isinstance(conn, dict):
                        raise ValueError(
                            f"Connection {i} in '{source_node_id}.{conn_type}' must be an object"
                        )
                    if "node" not in conn:
                        raise ValueError(
                            f"Connection {i} in '{source_node_id}.{conn_type}' missing required 'node' field"
                        )

        return v


class UpdateWorkflowResponse(BaseModel):
    workflow: WorkflowData
    success: bool = True
    message: str = "Workflow updated successfully"


class DeleteWorkflowRequest(BaseModel):
    workflow_id: str = Field(..., min_length=1)
    user_id: str = Field(..., min_length=1)


class DeleteWorkflowResponse(BaseModel):
    success: bool = True
    message: str = "Workflow deleted successfully"


class ListWorkflowsRequest(BaseModel):
    user_id: str = Field(..., min_length=1)
    active_only: bool = True
    tags: List[str] = Field(default_factory=list)
    limit: int = Field(default=50, ge=1, le=500)
    offset: int = Field(default=0, ge=0)


class ListWorkflowsResponse(BaseModel):
    """åˆ—è¡¨å·¥ä½œæµå“åº”"""

    workflows: List[WorkflowData]
    total_count: int
    has_more: bool


class ExecuteWorkflowRequest(BaseModel):
    """æ‰§è¡Œå·¥ä½œæµè¯·æ±‚"""

    workflow_id: str = Field(..., min_length=1)
    trigger_data: Dict[str, str] = Field(default_factory=dict)
    user_id: str = Field(..., min_length=1)
    session_id: Optional[str] = None
    
    # æ–°å¢å‚æ•°ï¼šæ”¯æŒä»æŒ‡å®šèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
    start_from_node: Optional[str] = Field(
        default=None, 
        description="æŒ‡å®šä»å“ªä¸ªèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œï¼Œä¸ºç©ºæ—¶ä»è§¦å‘å™¨èŠ‚ç‚¹å¼€å§‹",
        example="ai_message_classification"
    )
    skip_trigger_validation: bool = Field(
        default=False,
        description="æ˜¯å¦è·³è¿‡è§¦å‘å™¨éªŒè¯ï¼Œç”¨äºä»ä¸­é—´èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œæ—¶ä½¿ç”¨"
    )
    
    # æ–°å¢ï¼šå½“ä½¿ç”¨start_from_nodeæ—¶ï¼Œå¯ä»¥æä¾›è‡ªå®šä¹‰è¾“å…¥æ•°æ®
    inputs: Optional[Dict[str, Any]] = Field(
        default=None,
        description="å½“ä½¿ç”¨start_from_nodeæ—¶çš„è‡ªå®šä¹‰è¾“å…¥æ•°æ®ï¼Œå°†ä¼ é€’ç»™èµ·å§‹èŠ‚ç‚¹"
    )


class ExecuteWorkflowResponse(BaseModel):
    execution_id: str
    status: str = "running"
    success: bool = True
    message: str = "Workflow execution started"


# API Gatewayç‰¹æœ‰çš„å·¥ä½œæµæ¨¡å‹
class WorkflowStatus(str, Enum):
    """å·¥ä½œæµçŠ¶æ€æšä¸¾"""

    DRAFT = "draft"
    ACTIVE = "active"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    ARCHIVED = "archived"


class WorkflowType(str, Enum):
    """å·¥ä½œæµç±»å‹æšä¸¾"""

    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    CONDITIONAL = "conditional"
    LOOP = "loop"
    HYBRID = "hybrid"


# Legacy NodeType removed - now using authoritative enums from shared.models.node_enums
# All services should import NodeType from shared.models directly


class WorkflowEdge(BaseModel):
    """
    å·¥ä½œæµè¿æ¥è¾¹æ¨¡å‹
    """

    id: str = Field(description="è¾¹çš„å”¯ä¸€æ ‡è¯†ç¬¦")
    source: str = Field(description="æºèŠ‚ç‚¹ID")
    target: str = Field(description="ç›®æ ‡èŠ‚ç‚¹ID")
    condition: Optional[str] = Field(default=None, description="è¾¹çš„æ¡ä»¶è¡¨è¾¾å¼")
    label: Optional[str] = Field(default=None, description="è¾¹çš„æ ‡ç­¾")


# Duplicate definitions removed - use the workflow-engine specific models above
# API Gateway should use CreateWorkflowRequest and UpdateWorkflowRequest defined earlier


class WorkflowExecutionRecord(EntityModel):
    """
    å·¥ä½œæµæ‰§è¡Œè®°å½•æ¨¡å‹
    """

    workflow_id: str = Field(description="å·¥ä½œæµID")
    session_id: Optional[str] = Field(default=None, description="å…³è”çš„ä¼šè¯ID")
    user_id: str = Field(description="æ‰§è¡Œç”¨æˆ·ID")
    status: str = Field(
        default="running", description="æ‰§è¡ŒçŠ¶æ€ (running, completed, failed, cancelled)"
    )
    input_data: Dict[str, Any] = Field(default_factory=dict, description="è¾“å…¥æ•°æ®")
    output_data: Optional[Dict[str, Any]] = Field(default=None, description="è¾“å‡ºæ•°æ®")
    error_message: Optional[str] = Field(default=None, description="é”™è¯¯æ¶ˆæ¯")
    start_time: Optional[str] = Field(default=None, description="å¼€å§‹æ—¶é—´")
    end_time: Optional[str] = Field(default=None, description="ç»“æŸæ—¶é—´")
    duration_ms: Optional[int] = Field(default=None, description="æ‰§è¡ŒæŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰")
    node_executions: List[Dict[str, Any]] = Field(default_factory=list, description="èŠ‚ç‚¹æ‰§è¡Œè®°å½•")


class WorkflowResponse(BaseModel):
    """
    å·¥ä½œæµå“åº”æ¨¡å‹
    """

    workflow: WorkflowData = Field(description="å·¥ä½œæµä¿¡æ¯")
    message: Optional[str] = Field(default=None, description="å“åº”æ¶ˆæ¯")


class WorkflowListResponse(BaseModel):
    """
    å·¥ä½œæµåˆ—è¡¨å“åº”æ¨¡å‹
    """

    workflows: List[WorkflowData] = Field(default_factory=list, description="å·¥ä½œæµåˆ—è¡¨")
    total_count: int = Field(default=0, description="æ€»æ•°é‡")
    page: int = Field(default=1, description="å½“å‰é¡µç ")
    page_size: int = Field(default=20, description="æ¯é¡µå¤§å°")


class WorkflowExecutionRequest(BaseModel):
    """
    å·¥ä½œæµæ‰§è¡Œè¯·æ±‚æ¨¡å‹
    """

    inputs: Dict[str, Any] = Field(default_factory=dict, description="æ‰§è¡Œæ—¶çš„è¾“å…¥å‚æ•°")
    settings: Optional[Dict[str, Any]] = Field(default=None, description="æ‰§è¡Œæ—¶çš„ç‰¹æ®Šè®¾ç½®")
    metadata: Optional[Dict[str, Any]] = Field(default=None, description="æ‰§è¡Œå…ƒæ•°æ®")
    
    # æ–°å¢å‚æ•°ï¼šæ”¯æŒä»æŒ‡å®šèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
    start_from_node: Optional[str] = Field(
        default=None, 
        description="æŒ‡å®šä»å“ªä¸ªèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œï¼Œä¸ºç©ºæ—¶ä»è§¦å‘å™¨èŠ‚ç‚¹å¼€å§‹",
        example="ai_message_classification"
    )
    skip_trigger_validation: bool = Field(
        default=False,
        description="æ˜¯å¦è·³è¿‡è§¦å‘å™¨éªŒè¯ï¼Œç”¨äºä»ä¸­é—´èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œæ—¶ä½¿ç”¨"
    )


class WorkflowExecutionResponse(BaseModel):
    """
    å·¥ä½œæµæ‰§è¡Œå“åº”æ¨¡å‹
    """

    execution_id: str = Field(description="æ‰§è¡ŒID")
    workflow_id: str = Field(description="å·¥ä½œæµID")
    status: str = Field(description="æ‰§è¡ŒçŠ¶æ€")
    message: Optional[str] = Field(default=None, description="å“åº”æ¶ˆæ¯")
    started_at: Optional[str] = Field(default=None, description="å¼€å§‹æ‰§è¡Œæ—¶é—´")


class NodeTemplate(BaseModel):
    """
    Node Template Model
    """

    id: str
    name: str
    description: Optional[str] = None
    category: Optional[str] = None
    node_type: str
    node_subtype: str
    version: Optional[str] = "1.0.0"
    is_system_template: bool = False
    default_parameters: Optional[Dict[str, Any]] = None
    required_parameters: Optional[List[str]] = None
    parameter_schema: Optional[Dict[str, Any]] = None


class NodeTemplateListResponse(BaseModel):
    """
    Response model for a list of node templates.
    """

    node_templates: List[NodeTemplate] = Field(default_factory=list)


# Single Node Execution Models
class ExecuteSingleNodeRequest(BaseModel):
    """
    è¯·æ±‚æ‰§è¡Œå·¥ä½œæµä¸­çš„å•ä¸ªèŠ‚ç‚¹
    """

    user_id: str = Field(..., description="ç”¨æˆ·ID", min_length=1)
    input_data: Dict[str, Any] = Field(default_factory=dict, description="èŠ‚ç‚¹æ‰§è¡Œçš„è¾“å…¥æ•°æ®")
    execution_context: Dict[str, Any] = Field(
        default_factory=dict,
        description="æ‰§è¡Œä¸Šä¸‹æ–‡é…ç½®",
        example={
            "use_previous_results": False,
            "previous_execution_id": None,
            "override_parameters": {},
            "credentials": {},
        },
    )

    class Config:
        json_schema_extra = {
            "example": {
                "user_id": "00000000-0000-0000-0000-000000000123",
                "input_data": {"url": "https://api.example.com", "method": "GET"},
                "execution_context": {
                    "use_previous_results": False,
                    "override_parameters": {"timeout": "30"},
                },
            }
        }


class SingleNodeExecutionResponse(BaseModel):
    """
    å•èŠ‚ç‚¹æ‰§è¡Œå“åº”
    """

    execution_id: str = Field(..., description="æ‰§è¡ŒID")
    node_id: str = Field(..., description="èŠ‚ç‚¹ID")
    workflow_id: str = Field(..., description="å·¥ä½œæµID")
    status: str = Field(..., description="æ‰§è¡ŒçŠ¶æ€")
    output_data: Dict[str, Any] = Field(default_factory=dict, description="èŠ‚ç‚¹è¾“å‡ºæ•°æ®")
    execution_time: float = Field(..., description="æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰")
    logs: List[str] = Field(default_factory=list, description="æ‰§è¡Œæ—¥å¿—")
    error_message: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")

    class Config:
        json_schema_extra = {
            "example": {
                "execution_id": "single-node-exec-123",
                "node_id": "http_request_node",
                "workflow_id": "workflow-456",
                "status": "COMPLETED",
                "output_data": {"response_code": 200, "response_body": {"data": "example"}},
                "execution_time": 1.23,
                "logs": ["Starting HTTP request...", "Request completed"],
                "error_message": None,
            }
        }

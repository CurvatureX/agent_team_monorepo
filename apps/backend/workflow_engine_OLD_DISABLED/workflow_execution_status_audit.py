#!/usr/bin/env python3
"""
Workflow Execution Status Audit & Enhancement
ç¡®ä¿workflow_executionsè¡¨çš„statuså­—æ®µåŠæ—¶å’Œå‡†ç¡®æ›´æ–°çš„å®¡è®¡å’Œå¢å¼ºè„šæœ¬
"""

import asyncio
import logging
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class StatusUpdatePoint:
    """çŠ¶æ€æ›´æ–°ç‚¹"""

    location: str
    trigger: str
    old_status: str
    new_status: str
    critical: bool
    has_error_handling: bool
    description: str


class ExecutionStatusAudit:
    """æ‰§è¡ŒçŠ¶æ€å®¡è®¡å™¨"""

    def __init__(self):
        self.status_points = self._identify_status_update_points()
        self.critical_gaps = []
        self.enhancement_recommendations = []

    def _identify_status_update_points(self) -> List[StatusUpdatePoint]:
        """è¯†åˆ«æ‰€æœ‰çŠ¶æ€æ›´æ–°ç‚¹"""
        return [
            # 1. å·¥ä½œæµåˆ›å»º
            StatusUpdatePoint(
                location="ExecutionService.execute_workflow() - Line 72",
                trigger="Workflow execution request received",
                old_status="None",
                new_status="NEW",
                critical=True,
                has_error_handling=True,
                description="åˆå§‹åˆ›å»ºæ‰§è¡Œè®°å½•ï¼ŒçŠ¶æ€è®¾ä¸ºNEW",
            ),
            # 2. å¼€å§‹æ‰§è¡Œ
            StatusUpdatePoint(
                location="ExecutionService._execute_workflow_sync() - Line 160",
                trigger="Background execution starts",
                old_status="NEW",
                new_status="RUNNING",
                critical=True,
                has_error_handling=True,
                description="åå°æ‰§è¡Œå¼€å§‹å‰æ›´æ–°çŠ¶æ€ä¸ºRUNNING",
            ),
            # 3. æ‰§è¡ŒæˆåŠŸå®Œæˆ
            StatusUpdatePoint(
                location="ExecutionService._execute_workflow_background() - Line 776-777",
                trigger="Workflow completes successfully",
                old_status="RUNNING",
                new_status="SUCCESS",
                critical=True,
                has_error_handling=True,
                description="å·¥ä½œæµæ­£å¸¸å®Œæˆï¼ŒçŠ¶æ€æ›´æ–°ä¸ºSUCCESS",
            ),
            # 4. æ‰§è¡Œå¤±è´¥
            StatusUpdatePoint(
                location="ExecutionService._execute_workflow_background() - Line 778-779",
                trigger="Workflow execution fails",
                old_status="RUNNING",
                new_status="ERROR",
                critical=True,
                has_error_handling=True,
                description="å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼ŒçŠ¶æ€æ›´æ–°ä¸ºERROR",
            ),
            # 5. æš‚åœçŠ¶æ€
            StatusUpdatePoint(
                location="ExecutionService._execute_workflow_background() - Line 782",
                trigger="Workflow pauses for human input",
                old_status="RUNNING",
                new_status="PAUSED",
                critical=True,
                has_error_handling=True,
                description="å·¥ä½œæµæš‚åœç­‰å¾…äººå·¥è¾“å…¥",
            ),
            # 6. å¼‚å¸¸å¤„ç†
            StatusUpdatePoint(
                location="ExecutionService._execute_workflow_background() - Line 815",
                trigger="Background execution exception",
                old_status="RUNNING",
                new_status="ERROR",
                critical=True,
                has_error_handling=True,
                description="åå°æ‰§è¡Œå¼‚å¸¸ï¼ŒçŠ¶æ€è®¾ä¸ºERROR",
            ),
            # 7. æ‰‹åŠ¨å–æ¶ˆ
            StatusUpdatePoint(
                location="ExecutionService.cancel_execution() - Line 269",
                trigger="User cancels execution",
                old_status="RUNNING|PAUSED",
                new_status="CANCELED",
                critical=True,
                has_error_handling=True,
                description="ç”¨æˆ·æ‰‹åŠ¨å–æ¶ˆæ‰§è¡Œ",
            ),
            # 8. æ¢å¤æ‰§è¡Œ
            StatusUpdatePoint(
                location="ExecutionService.resume_workflow() - Line 330",
                trigger="Resume from pause",
                old_status="PAUSED",
                new_status="RUNNING",
                critical=True,
                has_error_handling=False,  # éœ€è¦æ”¹è¿›
                description="ä»æš‚åœçŠ¶æ€æ¢å¤æ‰§è¡Œ",
            ),
        ]

    def audit_status_tracking(self) -> Dict[str, any]:
        """å®¡è®¡çŠ¶æ€è·Ÿè¸ªæœºåˆ¶"""
        print("ğŸ” å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€è·Ÿè¸ªå®¡è®¡")
        print("=" * 80)

        audit_results = {
            "total_status_points": len(self.status_points),
            "critical_points": len([p for p in self.status_points if p.critical]),
            "points_with_error_handling": len(
                [p for p in self.status_points if p.has_error_handling]
            ),
            "identified_gaps": [],
            "recommendations": [],
        }

        # 1. åˆ†æå…³é”®çŠ¶æ€æ›´æ–°ç‚¹
        print("\nğŸ“‹ å…³é”®çŠ¶æ€æ›´æ–°ç‚¹åˆ†æ:")
        for i, point in enumerate(self.status_points, 1):
            status = "âœ…" if point.has_error_handling else "âš ï¸"
            critical = "ğŸ”¥" if point.critical else "ğŸ“"
            print(f"  {i}. {status}{critical} {point.old_status} â†’ {point.new_status}")
            print(f"     ä½ç½®: {point.location}")
            print(f"     è§¦å‘: {point.trigger}")
            print(f"     æè¿°: {point.description}")

            if not point.has_error_handling:
                audit_results["identified_gaps"].append(f"ç¼ºå°‘é”™è¯¯å¤„ç†: {point.location}")
            print()

        # 2. è¯†åˆ«æ½œåœ¨é—®é¢˜
        print("\nğŸš¨ è¯†åˆ«çš„æ½œåœ¨é—®é¢˜:")
        gaps = [
            "æ•°æ®åº“äº‹åŠ¡å¤±è´¥æ—¶çŠ¶æ€å¯èƒ½ä¸ä¸€è‡´",
            "ç½‘ç»œä¸­æ–­æ—¶çŠ¶æ€æ›´æ–°å¯èƒ½ä¸¢å¤±",
            "é•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµçŠ¶æ€å¯èƒ½è¿‡æ—¶",
            "å¹¶å‘æ‰§è¡Œæ—¶çŠ¶æ€ç«äº‰æ¡ä»¶",
            "ç³»ç»Ÿé‡å¯åè¿è¡Œä¸­çš„æ‰§è¡ŒçŠ¶æ€æœªæ¢å¤",
        ]

        for i, gap in enumerate(gaps, 1):
            print(f"  {i}. âš ï¸ {gap}")
            audit_results["identified_gaps"].append(gap)

        # 3. æ”¹è¿›å»ºè®®
        print("\nğŸ’¡ çŠ¶æ€è·Ÿè¸ªæ”¹è¿›å»ºè®®:")
        recommendations = [
            "æ·»åŠ çŠ¶æ€æ›´æ–°é‡è¯•æœºåˆ¶",
            "å®ç°çŠ¶æ€å˜æ›´äº‹ä»¶é€šçŸ¥",
            "æ·»åŠ çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥",
            "å®ç°æ‰§è¡Œè¶…æ—¶æ£€æµ‹",
            "æ·»åŠ çŠ¶æ€å†å²è®°å½•",
            "å®ç°æ•…éšœæ¢å¤æœºåˆ¶",
        ]

        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. ğŸ”§ {rec}")
            audit_results["recommendations"].append(rec)

        return audit_results

    def generate_status_monitoring_queries(self):
        """ç”ŸæˆçŠ¶æ€ç›‘æ§æŸ¥è¯¢"""
        print("\nğŸ“Š çŠ¶æ€ç›‘æ§SQLæŸ¥è¯¢:")
        print("-" * 50)

        queries = {
            "æ´»è·ƒæ‰§è¡Œç»Ÿè®¡": """
                SELECT status, COUNT(*) as count
                FROM workflow_executions
                WHERE created_at > NOW() - INTERVAL '1 hour'
                GROUP BY status
                ORDER BY count DESC;
            """,
            "é•¿æ—¶é—´è¿è¡Œæ£€æµ‹": """
                SELECT execution_id, workflow_id, status,
                       EXTRACT(EPOCH FROM NOW() - to_timestamp(start_time)) / 3600 as hours_running
                FROM workflow_executions
                WHERE status = 'RUNNING'
                  AND start_time < EXTRACT(EPOCH FROM NOW() - INTERVAL '2 hours')
                ORDER BY hours_running DESC;
            """,
            "çŠ¶æ€å¼‚å¸¸æ£€æµ‹": """
                SELECT execution_id, status, start_time, end_time,
                       CASE
                           WHEN status = 'RUNNING' AND end_time IS NOT NULL THEN 'çŠ¶æ€ä¸ä¸€è‡´'
                           WHEN status IN ('SUCCESS', 'ERROR') AND end_time IS NULL THEN 'ç»“æŸæ—¶é—´ç¼ºå¤±'
                           ELSE 'æ­£å¸¸'
                       END as issue
                FROM workflow_executions
                WHERE created_at > NOW() - INTERVAL '24 hours'
                HAVING issue != 'æ­£å¸¸';
            """,
            "æ‰§è¡Œå¤±è´¥åˆ†æ": """
                SELECT DATE(to_timestamp(start_time)) as date,
                       COUNT(CASE WHEN status = 'ERROR' THEN 1 END) as failed_count,
                       COUNT(*) as total_count,
                       ROUND(COUNT(CASE WHEN status = 'ERROR' THEN 1 END)::numeric / COUNT(*) * 100, 2) as failure_rate
                FROM workflow_executions
                WHERE start_time > EXTRACT(EPOCH FROM NOW() - INTERVAL '7 days')
                GROUP BY DATE(to_timestamp(start_time))
                ORDER BY date DESC;
            """,
        }

        for name, query in queries.items():
            print(f"\n-- {name}")
            print(query.strip())


class ExecutionStatusEnhancer:
    """æ‰§è¡ŒçŠ¶æ€å¢å¼ºå™¨"""

    def __init__(self):
        self.enhancements = []

    def design_robust_status_updates(self):
        """è®¾è®¡å¥å£®çš„çŠ¶æ€æ›´æ–°æœºåˆ¶"""
        print("\nğŸ›  è®¾è®¡å¥å£®çš„çŠ¶æ€æ›´æ–°æœºåˆ¶")
        print("=" * 80)

        print("\n1. ğŸ”„ çŠ¶æ€æ›´æ–°é‡è¯•æœºåˆ¶:")
        retry_mechanism = """
        async def update_execution_status_with_retry(
            self, execution_id: str, new_status: str,
            error_message: str = None, max_retries: int = 3
        ):
            for attempt in range(max_retries):
                try:
                    db_execution = self.db.query(ExecutionModel).filter(
                        ExecutionModel.execution_id == execution_id
                    ).first()

                    if not db_execution:
                        logger.error(f"Execution not found: {execution_id}")
                        return False

                    old_status = db_execution.status
                    db_execution.status = new_status
                    db_execution.updated_at = datetime.now()

                    if error_message:
                        db_execution.error_message = error_message

                    if new_status in ['SUCCESS', 'ERROR', 'CANCELED']:
                        db_execution.end_time = int(datetime.now().timestamp())

                    self.db.commit()

                    # è®°å½•çŠ¶æ€å˜æ›´
                    logger.info(f"Status updated: {execution_id} {old_status} â†’ {new_status}")

                    # å‘é€çŠ¶æ€å˜æ›´é€šçŸ¥
                    await self._notify_status_change(execution_id, old_status, new_status)

                    return True

                except Exception as e:
                    logger.warning(f"Status update attempt {attempt + 1} failed: {e}")
                    self.db.rollback()
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

            logger.error(f"Failed to update status after {max_retries} attempts")
            return False
        """
        print(retry_mechanism)

        print("\n2. ğŸ“¢ çŠ¶æ€å˜æ›´é€šçŸ¥æœºåˆ¶:")
        notification_mechanism = """
        async def _notify_status_change(self, execution_id: str, old_status: str, new_status: str):
            # WebSocketé€šçŸ¥
            await self.websocket_manager.broadcast_status_update(
                execution_id, old_status, new_status
            )

            # ä¸šåŠ¡æ—¥å¿—è®°å½•
            await self.unified_log_service.add_business_log(
                execution_id=execution_id,
                event_type="status_change",
                technical_message=f"Execution status changed from {old_status} to {new_status}",
                user_friendly_message=f"ğŸ“Š æ‰§è¡ŒçŠ¶æ€æ›´æ–°: {old_status} â†’ {new_status}",
                display_priority=7,
                is_milestone=new_status in ['RUNNING', 'SUCCESS', 'ERROR']
            )
        """
        print(notification_mechanism)

        print("\n3. ğŸ• æ‰§è¡Œè¶…æ—¶æ£€æµ‹:")
        timeout_detection = """
        async def detect_stalled_executions(self):
            # æ£€æµ‹è¶…æ—¶æ‰§è¡Œ
            timeout_threshold = 2 * 3600  # 2å°æ—¶
            current_time = int(datetime.now().timestamp())

            stalled_executions = self.db.query(ExecutionModel).filter(
                ExecutionModel.status == ExecutionStatus.RUNNING.value,
                ExecutionModel.start_time < current_time - timeout_threshold
            ).all()

            for execution in stalled_executions:
                logger.warning(f"Stalled execution detected: {execution.execution_id}")

                # æ ‡è®°ä¸ºè¶…æ—¶
                await self.update_execution_status_with_retry(
                    execution.execution_id,
                    ExecutionStatus.ERROR.value,
                    "Execution timeout - no activity for 2 hours"
                )
        """
        print(timeout_detection)

        print("\n4. ğŸ”§ çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥:")
        consistency_check = """
        async def check_status_consistency(self):
            # æ£€æŸ¥çŠ¶æ€ä¸ä¸€è‡´çš„è®°å½•
            inconsistent_records = self.db.execute(text('''
                SELECT execution_id, status, start_time, end_time
                FROM workflow_executions
                WHERE (status = 'RUNNING' AND end_time IS NOT NULL)
                   OR (status IN ('SUCCESS', 'ERROR') AND end_time IS NULL)
                   OR (start_time > end_time AND end_time IS NOT NULL)
            ''')).fetchall()

            for record in inconsistent_records:
                logger.warning(f"Status inconsistency: {record.execution_id}")

                # è‡ªåŠ¨ä¿®å¤é€»è¾‘
                if record.status == 'RUNNING' and record.end_time:
                    # è¿è¡Œä¸­ä½†æœ‰ç»“æŸæ—¶é—´ï¼Œå¯èƒ½æ˜¯æœªæ­£ç¡®æ›´æ–°
                    await self._investigate_and_fix_status(record.execution_id)
        """
        print(consistency_check)


def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„çŠ¶æ€å®¡è®¡å’Œå¢å¼ºå»ºè®®"""
    print("ğŸš€ å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€è·Ÿè¸ª - å…¨é¢å®¡è®¡ä¸å¢å¼º")
    print("=" * 100)

    # 1. æ‰§è¡Œå®¡è®¡
    auditor = ExecutionStatusAudit()
    audit_results = auditor.audit_status_tracking()

    # 2. ç”Ÿæˆç›‘æ§æŸ¥è¯¢
    auditor.generate_status_monitoring_queries()

    # 3. è®¾è®¡å¢å¼ºæœºåˆ¶
    enhancer = ExecutionStatusEnhancer()
    enhancer.design_robust_status_updates()

    # 4. æ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 100)
    print("ğŸ“‹ å®¡è®¡æ€»ç»“æŠ¥å‘Š")
    print("=" * 100)

    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»çŠ¶æ€æ›´æ–°ç‚¹: {audit_results['total_status_points']}")
    print(f"   å…³é”®æ›´æ–°ç‚¹: {audit_results['critical_points']}")
    print(f"   æœ‰é”™è¯¯å¤„ç†: {audit_results['points_with_error_handling']}")
    print(f"   å‘ç°é—®é¢˜: {len(audit_results['identified_gaps'])}")

    print(f"\nğŸ¯ å…³é”®è¡ŒåŠ¨é¡¹:")
    print("   1. âœ… ç°æœ‰çŠ¶æ€æ›´æ–°ç‚¹åŸºæœ¬å®Œæ•´")
    print("   2. ğŸ”§ éœ€è¦æ·»åŠ é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†")
    print("   3. ğŸ“¢ å®ç°çŠ¶æ€å˜æ›´é€šçŸ¥ç³»ç»Ÿ")
    print("   4. ğŸ• æ·»åŠ è¶…æ—¶æ£€æµ‹å’Œè‡ªåŠ¨æ¢å¤")
    print("   5. ğŸ” éƒ¨ç½²çŠ¶æ€ç›‘æ§æŸ¥è¯¢")
    print("   6. ğŸ§ª å¢åŠ çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥")

    print(f"\nâš¡ å®æ–½ä¼˜å…ˆçº§:")
    print("   ğŸ”¥ é«˜: çŠ¶æ€æ›´æ–°é‡è¯•æœºåˆ¶")
    print("   ğŸ”¥ é«˜: è¶…æ—¶æ£€æµ‹å’Œè‡ªåŠ¨æ ‡è®°")
    print("   ğŸ“‹ ä¸­: çŠ¶æ€å˜æ›´é€šçŸ¥ç³»ç»Ÿ")
    print("   ğŸ“‹ ä¸­: ä¸€è‡´æ€§æ£€æŸ¥å®šæ—¶ä»»åŠ¡")
    print("   ğŸ“ ä½: çŠ¶æ€å†å²è®°å½•åŠŸèƒ½")

    print(f"\nğŸš€ ç³»ç»Ÿç°çŠ¶è¯„ä¼°:")
    print("   âœ… åŸºç¡€çŠ¶æ€è·Ÿè¸ªæœºåˆ¶å·²å®ç°")
    print("   âœ… å…³é”®çŠ¶æ€è½¬æ¢ç‚¹å·²è¦†ç›–")
    print("   âš ï¸ ç¼ºå°‘æ•…éšœæ¢å¤æœºåˆ¶")
    print("   âš ï¸ éœ€è¦å¢å¼ºé”™è¯¯å¤„ç†")
    print("   ğŸ“ˆ å»ºè®®å®æ–½ç›‘æ§å’Œå‘Šè­¦")


if __name__ == "__main__":
    main()

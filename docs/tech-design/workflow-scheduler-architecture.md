# Workflow Scheduler æŠ€æœ¯æ¶æ„è®¾è®¡

## 1. æ¦‚è¿°ä¸ä¸šåŠ¡ç›®æ ‡

**workflow_scheduler** æ˜¯ Workflow ç³»ç»Ÿçš„è§¦å‘å™¨ç®¡ç†å’Œè°ƒåº¦æ ¸å¿ƒï¼Œä¸“æ³¨äºç®¡ç†workflowçš„è§¦å‘æ¡ä»¶ç›‘æ§ï¼Œå½“è§¦å‘æ¡ä»¶æ»¡è¶³æ—¶è°ƒç”¨workflow_engineæ‰§è¡Œä»»åŠ¡ã€‚

### æ ¸å¿ƒèŒè´£

1. **è§¦å‘å™¨ç®¡ç†**ï¼šç®¡ç† Cronã€Manualã€Webhookã€Emailã€GitHub ç­‰å¤šç§è§¦å‘å™¨é…ç½®
2. **è°ƒåº¦ç›‘æ§**ï¼šæŒç»­ç›‘æ§è§¦å‘æ¡ä»¶ï¼Œç¡®ä¿åŠæ—¶å“åº”
3. **éƒ¨ç½²ç®¡ç†**ï¼šç®¡ç†workflowçš„éƒ¨ç½²çŠ¶æ€å’Œè§¦å‘å™¨é…ç½®
4. **è°ƒåº¦åè°ƒ**ï¼šå½“è§¦å‘æ¡ä»¶æ»¡è¶³æ—¶ï¼Œé€šè¿‡HTTPè°ƒç”¨workflow_engineæ‰§è¡Œ

### èŒè´£è¾¹ç•Œ

**workflow_scheduler è´Ÿè´£**ï¼š
- è§¦å‘å™¨é…ç½®å’Œç›‘æ§
- è°ƒåº¦æ—¶æœºåˆ¤æ–­
- éƒ¨ç½²çŠ¶æ€ç®¡ç†
- åˆ†å¸ƒå¼é”é˜²é‡

**workflow_engine è´Ÿè´£**ï¼š
- å®é™…workflowæ‰§è¡Œ
- æ‰§è¡ŒçŠ¶æ€è·Ÿè¸ª
- æ‰§è¡Œå†å²è®°å½•
- èŠ‚ç‚¹æ‰§è¡Œç®¡ç†

## 2. ç³»ç»Ÿæ¶æ„

```mermaid
graph TD
    subgraph "Client Layer"
        UI["Frontend (Web/App)"]
        API_CLIENTS["External API Clients"]
        WEBHOOK_CLIENTS["Webhook Clients"]
    end

    subgraph "API Gateway Layer"
        API_GATEWAY["API Gateway (FastAPI)"]
    end

    subgraph "Internal HTTP Services"
        WF_SCHEDULER["workflow_scheduler (FastAPI)"]
        WF_AGENT["workflow_agent (FastAPI)"]
        WF_ENGINE["workflow_engine (FastAPI)"]
    end

    subgraph "workflow_scheduler Service"
        DEPLOY_SERVICE["DeploymentService"]
        TRIGGER_MANAGER["TriggerManager"]

        CRON_TRIGGER["CronTrigger (APScheduler)"]
        MANUAL_TRIGGER["ManualTrigger"]
        WEBHOOK_TRIGGER["WebhookTrigger"]
        EMAIL_TRIGGER["EmailTrigger (IMAP)"]
        GITHUB_TRIGGER["GitHubTrigger (App Integration)"]
        DISTRIBUTED_LOCK["DistributedLockManager"]
    end

    subgraph "External Systems"
        POSTGRES[("PostgreSQL Database")]
        REDIS[("Redis (Locking & Cache)")]
        EMAIL_SERVER[("Email Server (IMAP)")]
        GITHUB_API[("GitHub API & Webhooks")]
    end

    %% Client connections
    UI --> API_GATEWAY
    API_CLIENTS --> API_GATEWAY
    WEBHOOK_CLIENTS --> API_GATEWAY

    %% API Gateway to internal services
    API_GATEWAY --> WF_SCHEDULER
    API_GATEWAY --> WF_AGENT

    %% Internal service connections
    WF_SCHEDULER --> DEPLOY_SERVICE
    DEPLOY_SERVICE --> TRIGGER_MANAGER

    TRIGGER_MANAGER --> CRON_TRIGGER
    TRIGGER_MANAGER --> MANUAL_TRIGGER
    TRIGGER_MANAGER --> WEBHOOK_TRIGGER
    TRIGGER_MANAGER --> EMAIL_TRIGGER
    TRIGGER_MANAGER --> GITHUB_TRIGGER

    %% All triggers call workflow_engine
    CRON_TRIGGER --> WF_ENGINE
    MANUAL_TRIGGER --> WF_ENGINE
    WEBHOOK_TRIGGER --> WF_ENGINE
    EMAIL_TRIGGER --> WF_ENGINE
    GITHUB_TRIGGER --> WF_ENGINE

    %% Data and external connections
    WF_SCHEDULER --> DISTRIBUTED_LOCK
    WF_SCHEDULER --> POSTGRES
    DISTRIBUTED_LOCK --> REDIS
    EMAIL_TRIGGER --> EMAIL_SERVER
    GITHUB_TRIGGER --> GITHUB_API
```

## 3. æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 3.1. DeploymentService

**èŒè´£**ï¼šç®¡ç† Workflow çš„éƒ¨ç½²ç”Ÿå‘½å‘¨æœŸ

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- éªŒè¯ Workflow å®šä¹‰çš„æœ‰æ•ˆæ€§ï¼ˆåŸºæœ¬ç»“æ„éªŒè¯ï¼‰
- åˆ›å»º/æ›´æ–°/åˆ é™¤éƒ¨ç½²è®°å½•
- é…ç½®è§¦å‘å™¨ï¼ˆCron è¡¨è¾¾å¼ã€Webhook è·¯å¾„ã€Email è¿‡æ»¤å™¨ï¼‰
- ä¸ TriggerManager åè°ƒï¼Œæ³¨å†Œ/æ³¨é”€è§¦å‘å™¨

**APIæ¥å£**ï¼š
```python
class DeploymentService:
    async def deploy_workflow(self, workflow_id: str, workflow_spec: dict) -> DeploymentResult
    async def undeploy_workflow(self, workflow_id: str) -> bool
    async def update_deployment(self, workflow_id: str, workflow_spec: dict) -> DeploymentResult
    async def get_deployment_status(self, workflow_id: str) -> DeploymentStatus
```

### 3.2. TriggerManager

**èŒè´£**ï¼šç»Ÿä¸€ç®¡ç†æ‰€æœ‰ç±»å‹çš„è§¦å‘å™¨

**æ”¯æŒçš„è§¦å‘å™¨ç±»å‹**ï¼š
- **Cronè§¦å‘å™¨**ï¼šåŸºäºcronè¡¨è¾¾å¼çš„å®šæ—¶æ‰§è¡Œ
- **Manualè§¦å‘å™¨**ï¼šç”¨æˆ·æ‰‹åŠ¨è§¦å‘ï¼Œæ”¯æŒç¡®è®¤æœºåˆ¶
- **Webhookè§¦å‘å™¨**ï¼šHTTPç«¯ç‚¹è§¦å‘ï¼Œæ¯ä¸ªworkflowç‹¬ç«‹è·¯å¾„
- **Emailè§¦å‘å™¨**ï¼šé‚®ä»¶ç›‘æ§è§¦å‘ï¼Œæ”¯æŒè¿‡æ»¤å™¨å’Œé™„ä»¶å¤„ç†
- **GitHubè§¦å‘å™¨**ï¼šGitHubä»“åº“äº‹ä»¶è§¦å‘ï¼Œæ”¯æŒAppé›†æˆå’Œä»£ç è®¿é—®

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ç®¡ç†è§¦å‘å™¨ç”Ÿå‘½å‘¨æœŸï¼ˆå¯åŠ¨/åœæ­¢/é‡å¯ï¼‰
- è§£æè§¦å‘äº‹ä»¶ï¼Œæå–ç›¸å…³æ•°æ®
- éªŒè¯è§¦å‘æƒé™å’Œå‚æ•°
- ç›´æ¥è°ƒç”¨ workflow_engine HTTP æ¥å£æ‰§è¡Œworkflow

**APIæ¥å£**ï¼š
```python
class TriggerManager:
    async def register_triggers(self, workflow_id: str, trigger_specs: List[TriggerSpec]) -> bool
    async def unregister_triggers(self, workflow_id: str) -> bool
    async def get_trigger_status(self, workflow_id: str) -> Dict[str, TriggerStatus]
    async def trigger_manual(self, workflow_id: str, user_id: str, confirmation: bool = False) -> ExecutionResult
    async def process_webhook(self, workflow_id: str, request_data: dict) -> ExecutionResult
```

## 4. è§¦å‘å™¨è¯¦ç»†è®¾è®¡

### 4.1. Cronè§¦å‘å™¨ (CronTrigger)

**æŠ€æœ¯å®ç°**ï¼š
- åŸºäº Python APScheduler å®ç°
- æ”¯æŒæ ‡å‡†cronè¡¨è¾¾å¼å’Œæ—¶åŒºé…ç½®
- å“ˆå¸Œåˆ†æ•£æœºåˆ¶é¿å…ä»»åŠ¡åŒæ—¶æ‰§è¡Œ
- åˆ†å¸ƒå¼é”é˜²æ­¢é‡å¤æ‰§è¡Œ

**é…ç½®ç¤ºä¾‹**ï¼š
```json
{
  "node_type": "TRIGGER_NODE",
  "subtype": "TRIGGER_CRON",
  "parameters": {
    "cron_expression": "0 9 * * MON-FRI",
    "timezone": "America/New_York",
    "enabled": true
  }
}
```

**å®ç°æ ¸å¿ƒ**ï¼š
```python
class CronTrigger(BaseTrigger):
    async def start(self):
        if not self.enabled:
            return

        self.scheduler.add_job(
            func=self._execute_with_jitter,
            trigger=CronTrigger(self.cron_expression),
            timezone=self.timezone,
            id=f"cron_{self.workflow_id}",
            replace_existing=True
        )

    async def _execute_with_jitter(self):
        jitter = self._calculate_jitter(self.workflow_id)
        await asyncio.sleep(jitter)

        async with self.lock_manager.acquire(f"workflow_{self.workflow_id}"):
            await self._trigger_workflow()
```

### 4.2. Manualè§¦å‘å™¨ (ManualTrigger)

**æŠ€æœ¯å®ç°**ï¼š
- é€šè¿‡ API Gateway æä¾› REST ç«¯ç‚¹
- æ”¯æŒç”¨æˆ·èº«ä»½éªŒè¯
- å¯é€‰çš„ç¡®è®¤æœºåˆ¶é˜²è¯¯è§¦å‘
- å®æ—¶å“åº”ç”¨æˆ·æ“ä½œ

**APIç«¯ç‚¹**ï¼š
```
POST /api/v1/workflows/{workflow_id}/trigger/manual
Authorization: Bearer <jwt_token>
{
  "confirmation": true
}
```

**å®ç°æ ¸å¿ƒ**ï¼š
```python
class ManualTrigger(BaseTrigger):
    async def trigger_manual(self, user_id: str, confirmation: bool = False):
        if self.require_confirmation and not confirmation:
            return {"status": "confirmation_required", "message": "Please confirm execution"}

        trigger_data = {
            "trigger_time": datetime.now().isoformat(),
            "execution_id": f"exec_{uuid.uuid4()}",
            "user_id": user_id
        }

        return await self._trigger_workflow(trigger_data)
```

### 4.3. Webhookè§¦å‘å™¨ (WebhookTrigger)

**æŠ€æœ¯å®ç°**ï¼š
- æ¯ä¸ªworkflowåˆ†é…å”¯ä¸€çš„webhookè·¯å¾„
- API Gatewayç»Ÿä¸€æ¥æ”¶å¹¶è·¯ç”±webhookè¯·æ±‚
- æ”¯æŒå¤šç§HTTPæ–¹æ³• (GET/POST/PUT/PATCH/DELETE)
- å¯é…ç½®èº«ä»½éªŒè¯è¦æ±‚

**è·¯å¾„æ ¼å¼**ï¼š
```
https://api.example.com/webhook/{workflow_id}
https://api.example.com/webhook/custom-path  # è‡ªå®šä¹‰è·¯å¾„
```

**å®ç°æ ¸å¿ƒ**ï¼š
```python
class WebhookTrigger(BaseTrigger):
    def get_webhook_url(self) -> str:
        return f"{API_GATEWAY_BASE_URL}{self.webhook_path}"

    async def process_webhook(self, request_data: dict):
        trigger_data = {
            "headers": request_data["headers"],
            "body": request_data["body"],
            "query_params": request_data["query_params"],
            "method": request_data["method"],
            "path": request_data["path"]
        }

        return await self._trigger_workflow(trigger_data)
```

### 4.4. Emailè§¦å‘å™¨ (EmailTrigger)

**æŠ€æœ¯å®ç°**ï¼š
- åŸºäº IMAP åè®®ç›‘æ§é‚®ç®±
- å¼‚æ­¥é‚®ä»¶æ£€æŸ¥ä»»åŠ¡ (å¯é…ç½®é—´éš”)
- æ”¯æŒé‚®ä»¶è¿‡æ»¤å™¨ (å‘ä»¶äººã€ä¸»é¢˜ã€å†…å®¹)
- å¯é€‰çš„é™„ä»¶å¤„ç†å’Œè‡ªåŠ¨æ ‡è®°å·²è¯»

**é…ç½®ç¤ºä¾‹**ï¼š
```json
{
  "node_type": "TRIGGER_NODE",
  "subtype": "TRIGGER_EMAIL",
  "parameters": {
    "email_filter": "from:github-noreply@github.com",
    "folder": "INBOX",
    "mark_as_read": true,
    "attachment_processing": "include"
  }
}
```

**å®ç°æ ¸å¿ƒ**ï¼š
```python
class EmailTrigger(BaseTrigger):
    async def _monitor_emails(self):
        while True:
            try:
                async with IMAPClient() as client:
                    await client.connect()
                    await client.select_folder(self.folder)

                    new_emails = await client.search('UNSEEN')

                    for email_id in new_emails:
                        email_data = await self._process_email(client, email_id)

                        if self._matches_filter(email_data):
                            await self._trigger_workflow(email_data)

                            if self.mark_as_read:
                                await client.add_flags(email_id, ['\\Seen'])

            except Exception as e:
                logger.error(f"Email monitoring error: {e}")

            await asyncio.sleep(self.check_interval)
```

### 4.5. GitHubè§¦å‘å™¨ (GitHubTrigger)

**æŠ€æœ¯å®ç°**ï¼š
- åŸºäº GitHub App é›†æˆï¼Œé€šè¿‡webhookæ¥æ”¶äº‹ä»¶
- æ”¯æŒç§æœ‰ä»“åº“è®¿é—®å’Œå®Œæ•´çš„ä»£ç æƒé™
- é«˜çº§è¿‡æ»¤å™¨ï¼šåˆ†æ”¯ã€è·¯å¾„ã€ä½œè€…ã€æ ‡ç­¾ç­‰
- è‡ªåŠ¨è·å–ä»“åº“ä¸Šä¸‹æ–‡ï¼ˆPR diffã€æ–‡ä»¶å†…å®¹ç­‰ï¼‰

**é…ç½®ç¤ºä¾‹**ï¼š
```json
{
  "node_type": "TRIGGER_NODE",
  "subtype": "TRIGGER_GITHUB",
  "parameters": {
    "github_app_installation_id": "12345678",
    "repository": "microsoft/vscode",
    "events": ["push", "pull_request"],
    "branches": ["main", "develop"],
    "paths": ["src/**", "*.md"],
    "action_filter": ["opened", "synchronize"],
    "author_filter": "^(?!dependabot)",
    "label_filter": ["bug", "enhancement"],
    "ignore_bots": true,
    "draft_pr_handling": "ignore"
  }
}
```

**GitHub Appé›†æˆ**ï¼š
```python
class GitHubTrigger(BaseTrigger):
    def __init__(self, workflow_id: str, config: GitHubTriggerSpec):
        self.installation_id = config.github_app_installation_id
        self.repository = config.repository
        self.events = config.events
        self.filters = {
            "branches": config.branches,
            "paths": config.paths,
            "actions": config.action_filter,
            "author": config.author_filter,
            "labels": config.label_filter
        }

    async def process_github_event(self, event_type: str, payload: dict):
        # 1. éªŒè¯äº‹ä»¶ç±»å‹å’Œä»“åº“åŒ¹é…
        if not self._matches_event_filter(event_type, payload):
            return

        # 2. åº”ç”¨é«˜çº§è¿‡æ»¤å™¨
        if not self._matches_advanced_filters(event_type, payload):
            return

        # 3. å¢å¼ºäº‹ä»¶æ•°æ® - è·å–ä»“åº“ä¸Šä¸‹æ–‡
        enhanced_data = await self._enhance_event_data(event_type, payload)

        # 4. è§¦å‘workflowæ‰§è¡Œ
        return await self._trigger_workflow(enhanced_data)

    async def _enhance_event_data(self, event_type: str, payload: dict) -> dict:
        """ä½¿ç”¨GitHub Appæƒé™è·å–é¢å¤–çš„ä»“åº“æ•°æ®"""
        github_client = GitHubAppClient(
            app_id=GITHUB_APP_ID,
            private_key=GITHUB_APP_PRIVATE_KEY
        )

        enhanced_data = {
            "event": event_type,
            "action": payload.get("action"),
            "repository": payload["repository"],
            "sender": payload["sender"],
            "payload": payload,
            "timestamp": datetime.now().isoformat()
        }

        # æ ¹æ®äº‹ä»¶ç±»å‹å¢å¼ºæ•°æ®
        if event_type == "pull_request":
            pr_context = await github_client.get_pr_context(
                self.installation_id,
                self.repository,
                payload["number"]
            )
            enhanced_data["pr_context"] = pr_context

        elif event_type == "push":
            commit_contexts = []
            for commit in payload["commits"]:
                commit_context = await github_client.get_commit_context(
                    self.installation_id,
                    self.repository,
                    commit["id"]
                )
                commit_contexts.append(commit_context)
            enhanced_data["commit_contexts"] = commit_contexts

        return enhanced_data
```

**é«˜çº§è¿‡æ»¤ç³»ç»Ÿ**ï¼š
```python
def _matches_advanced_filters(self, event_type: str, payload: dict) -> bool:
    # åˆ†æ”¯è¿‡æ»¤
    if self.filters["branches"] and event_type in ["push", "pull_request"]:
        if event_type == "push":
            branch = payload["ref"].replace("refs/heads/", "")
        else:
            branch = payload["pull_request"]["base"]["ref"]

        if branch not in self.filters["branches"]:
            return False

    # è·¯å¾„è¿‡æ»¤ (å¯¹pushå’ŒPRäº‹ä»¶)
    if self.filters["paths"]:
        changed_files = self._get_changed_files(event_type, payload)
        if not any(
            any(fnmatch.fnmatch(file, pattern) for pattern in self.filters["paths"])
            for file in changed_files
        ):
            return False

    # ä½œè€…è¿‡æ»¤
    if self.filters["author"]:
        author = self._get_event_author(event_type, payload)
        if not re.match(self.filters["author"], author):
            return False

    # æ ‡ç­¾è¿‡æ»¤ (ä»…å¯¹issueså’ŒPR)
    if self.filters["labels"] and event_type in ["issues", "pull_request"]:
        event_labels = [label["name"] for label in payload.get("labels", [])]
        if not any(label in event_labels for label in self.filters["labels"]):
            return False

    return True
```

**GitHub Appæƒé™å’Œå®‰å…¨**ï¼š
- ä½¿ç”¨çŸ­æœŸè®¿é—®ä»¤ç‰Œï¼ˆ1å°æ—¶æœ‰æ•ˆæœŸï¼‰
- æ”¯æŒç»†ç²’åº¦ä»“åº“æƒé™æ§åˆ¶
- Webhookç­¾åéªŒè¯ç¡®ä¿æ•°æ®å®Œæ•´æ€§
- æ”¯æŒç§æœ‰ä»“åº“è®¿é—®

## 5. æ‰§è¡Œæµç¨‹

### 5.1. Workflow éƒ¨ç½²æµç¨‹

```mermaid
sequenceDiagram
    participant Client
    participant Gateway as API Gateway
    participant Deploy as DeploymentService
    participant TriggerMgr as TriggerManager
    participant DB as PostgreSQL

    Client->>Gateway: POST /workflows/{id}/deploy
    Gateway->>Deploy: deploy_workflow(workflow_spec)

    Deploy->>Deploy: validate_workflow_definition()
    Deploy->>DB: UPDATE workflows SET deployment_status='DEPLOYED'

    Deploy->>TriggerMgr: register_triggers(workflow_id, trigger_specs)

    loop For each trigger
        TriggerMgr->>TriggerMgr: create_trigger_instance()
        TriggerMgr->>TriggerMgr: start_trigger()
    end

    TriggerMgr-->>Deploy: All triggers registered
    Deploy-->>Gateway: Deployment successful
    Gateway-->>Client: 200 OK (deployment_id)
```

### 5.2. Cron è§¦å‘æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant Scheduler as APScheduler
    participant Cron as CronTrigger
    participant Lock as DistributedLockManager
    participant Engine as workflow_engine

    Note over Scheduler: Cron æ—¶é—´åˆ°è¾¾

    Scheduler->>Cron: trigger_execution()
    Cron->>Cron: calculate_jitter(workflow_id)
    Cron->>Cron: sleep(jitter_seconds)

    Cron->>Lock: acquire_lock(workflow_id)
    alt Lock acquired
        Cron->>Engine: POST /v1/workflows/{id}/execute
        Engine-->>Cron: 202 Accepted (execution_id)
        Cron->>Lock: release_lock(workflow_id)
    else Lock failed
        Note over Cron: Skip execution (already running)
    end
```

### 5.3. Manual è§¦å‘æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant User
    participant Gateway as API Gateway
    participant Manual as ManualTrigger
    participant Engine as workflow_engine

    User->>Gateway: POST /workflows/{id}/trigger/manual
    Gateway->>Gateway: authenticate_user()
    Gateway->>Manual: trigger_manual(workflow_id, user_id)

    alt require_confirmation = true
        Manual-->>Gateway: confirmation_required
        Gateway-->>User: 403 Confirmation Required
        User->>Gateway: POST /workflows/{id}/trigger/manual (confirmation=true)
        Gateway->>Manual: trigger_manual(workflow_id, user_id, confirmation=true)
    end

    Manual->>Engine: POST /v1/workflows/{id}/execute
    Engine-->>Manual: 202 Accepted (execution_id)
    Manual-->>Gateway: execution_started
    Gateway-->>User: 200 OK (execution_id)
```

### 5.4. Webhook è§¦å‘æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant Client as External System
    participant Gateway as API Gateway
    participant Webhook as WebhookTrigger
    participant Engine as workflow_engine

    Client->>Gateway: POST /webhook/{workflow_id}
    Gateway->>Gateway: parse_request_data()
    Gateway->>Webhook: process_webhook(workflow_id, request_data)

    Webhook->>Webhook: validate_authentication()
    Webhook->>Webhook: extract_trigger_data()

    Webhook->>Engine: POST /v1/workflows/{id}/execute
    Engine-->>Webhook: 202 Accepted (execution_id)

    Webhook-->>Gateway: 200 OK
    Gateway-->>Client: Webhook received
```

### 5.5. Email è§¦å‘æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant Email as Email Server
    participant Monitor as EmailTrigger
    participant Engine as workflow_engine

    loop Email Monitoring
        Monitor->>Email: IMAP check for new emails
        Email-->>Monitor: new_emails[]

        loop For each new email
            Monitor->>Monitor: extract_email_data()
            Monitor->>Monitor: apply_email_filter()

            alt Email matches filter
                Monitor->>Engine: POST /v1/workflows/{id}/execute
                Engine-->>Monitor: 202 Accepted (execution_id)

                opt mark_as_read = true
                    Monitor->>Email: IMAP mark as read
                end
            end
        end

        Monitor->>Monitor: sleep(check_interval)
    end
```

### 5.6. GitHub è§¦å‘æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant GitHub as GitHub (Webhook)
    participant Gateway as API Gateway
    participant GitHubTrigger as GitHubTrigger
    participant GitHubClient as GitHubAppClient
    participant Engine as workflow_engine

    GitHub->>Gateway: POST /webhooks/github (event payload)
    Gateway->>Gateway: verify_github_signature()
    Gateway->>GitHubTrigger: process_github_event(event_type, payload)

    GitHubTrigger->>GitHubTrigger: matches_event_filter()
    GitHubTrigger->>GitHubTrigger: matches_advanced_filters()

    alt Event matches filters
        GitHubTrigger->>GitHubClient: get_installation_token(installation_id)
        GitHubClient-->>GitHubTrigger: access_token (1h validity)

        alt Event type: pull_request
            GitHubTrigger->>GitHubClient: get_pr_context(repo, pr_number)
            GitHubClient->>GitHub: GET /repos/{repo}/pulls/{number}
            GitHubClient->>GitHub: GET /repos/{repo}/pulls/{number}/files
            GitHubClient-->>GitHubTrigger: pr_context (diff, files, comments)
        else Event type: push
            GitHubTrigger->>GitHubClient: get_commit_context(repo, commit_sha)
            GitHubClient->>GitHub: GET /repos/{repo}/commits/{sha}
            GitHubClient-->>GitHubTrigger: commit_context (diff, files)
        end

        GitHubTrigger->>Engine: POST /v1/workflows/{id}/execute (enhanced_data)
        Engine-->>GitHubTrigger: 202 Accepted (execution_id)
    end

    GitHubTrigger-->>Gateway: 200 OK
    Gateway-->>GitHub: Webhook processed
```

## 6. GitHub App é›†æˆæ¶æ„

### 6.1. GitHub App é…ç½®

**Appæƒé™è¦æ±‚**ï¼š
- `contents: read` - è®¿é—®ä»“åº“æ–‡ä»¶å’Œdiff
- `metadata: read` - åŸºæœ¬ä»“åº“ä¿¡æ¯
- `pull_requests: read` - PRæ•°æ®å’Œè¯„è®º
- `issues: read` - Issueæ•°æ®å’Œè¯„è®º
- `actions: read` - Workflowè¿è¡Œä¿¡æ¯
- `deployments: read` - éƒ¨ç½²çŠ¶æ€

**Webhookäº‹ä»¶**ï¼š
```yaml
æ”¯æŒçš„äº‹ä»¶ç±»å‹:
  - push, pull_request, pull_request_review
  - issues, issue_comment, release
  - deployment, deployment_status
  - workflow_run, check_run, check_suite
  - create, delete, fork, star, watch
```

### 6.2. æ•°æ®åº“é›†æˆ

**GitHubå®‰è£…è®°å½•**ï¼š
```sql
CREATE TABLE github_installations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id),
    installation_id BIGINT UNIQUE NOT NULL,
    account_id BIGINT NOT NULL,
    account_login TEXT NOT NULL,
    account_type TEXT NOT NULL, -- 'User' or 'Organization'
    repositories JSONB, -- Array of accessible repo info
    permissions JSONB,
    access_token_expires_at TIMESTAMP,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE github_webhook_events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    delivery_id TEXT UNIQUE NOT NULL,
    event_type TEXT NOT NULL,
    installation_id BIGINT,
    repository_id BIGINT,
    payload JSONB,
    processed_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### 6.3. API Gatewayé›†æˆ

**Webhookç«¯ç‚¹**ï¼š
```python
@app.post("/webhooks/github")
async def github_webhook_handler(
    request: Request,
    x_github_event: str = Header(...),
    x_github_delivery: str = Header(...),
    x_hub_signature_256: str = Header(...)
):
    # 1. éªŒè¯webhookç­¾å
    payload = await request.body()
    if not verify_github_signature(payload, x_hub_signature_256):
        raise HTTPException(401, "Invalid signature")

    # 2. è§£æäº‹ä»¶æ•°æ®
    event_data = json.loads(payload)

    # 3. è·¯ç”±åˆ°workflow_scheduler
    await workflow_scheduler.process_github_event(
        event_type=x_github_event,
        delivery_id=x_github_delivery,
        payload=event_data
    )

    return {"status": "processed"}
```

## 7. éƒ¨ç½²æ¶æ„

### 7.1. æœåŠ¡é…ç½®

**workflow_scheduler** ä½œä¸ºç‹¬ç«‹çš„ FastAPI æœåŠ¡ï¼š

- **ç«¯å£**: 8003
- **åè®®**: HTTP/REST API
- **ä¾èµ–**: APScheduler, Redis, PostgreSQL, IMAPå®¢æˆ·ç«¯
- **å¥åº·æ£€æŸ¥**: `curl -f http://localhost:8003/health`

### 7.2. ç¯å¢ƒå˜é‡é…ç½®

```bash
# æ ¸å¿ƒæœåŠ¡é…ç½®
PORT="8003"
HOST="0.0.0.0"
DEBUG="false"

# å¤–éƒ¨æœåŠ¡åœ°å€
WORKFLOW_ENGINE_URL="http://workflow-engine:8002"
API_GATEWAY_URL="http://api-gateway:8000"

# æ•°æ®åº“é…ç½®
DATABASE_URL="postgresql://user:pass@postgres/workflow_scheduler"
REDIS_URL="redis://redis:6379/1"

# é‚®ä»¶ç›‘æ§é…ç½®
IMAP_SERVER="imap.gmail.com"
EMAIL_USER="workflow@example.com"
EMAIL_PASSWORD="app_password"
EMAIL_CHECK_INTERVAL="60"

# GitHub Appé›†æˆé…ç½®
GITHUB_APP_ID="123456"
GITHUB_APP_PRIVATE_KEY="-----BEGIN RSA PRIVATE KEY-----\n...\n-----END RSA PRIVATE KEY-----"
GITHUB_WEBHOOK_SECRET="secure_webhook_secret_here"
GITHUB_API_BASE_URL="https://api.github.com"

# APScheduleré…ç½®
SCHEDULER_TIMEZONE="UTC"
SCHEDULER_MAX_WORKERS="10"
```

### 7.3. åˆ†å¸ƒå¼éƒ¨ç½²

- å¤šä¸ª workflow_scheduler å®ä¾‹è´Ÿè½½å‡è¡¡
- é€šè¿‡ Redis å®ç°åˆ†å¸ƒå¼é”å’ŒçŠ¶æ€å…±äº«
- PostgreSQL ä½œä¸ºå…±äº«æ•°æ®å­˜å‚¨
- workflow_engine é€šè¿‡ AWS ECS ç‹¬ç«‹éƒ¨ç½²å’Œä¼¸ç¼©
- **ç®€åŒ–æ¶æ„**ï¼šæ— éœ€å¤æ‚çš„æ‰§è¡ŒçŠ¶æ€åŒæ­¥ï¼Œåªéœ€ç®¡ç†è§¦å‘å™¨çŠ¶æ€

## 7. å®‰å…¨è€ƒè™‘

### 7.1. èº«ä»½éªŒè¯

- **Manualè§¦å‘å™¨**: JWT tokenéªŒè¯
- **Webhookè§¦å‘å™¨**: å¯é€‰çš„APIå¯†é’¥æˆ–ç­¾åéªŒè¯
- **Emailè§¦å‘å™¨**: å®‰å…¨çš„IMAPè¿æ¥å’Œå‡­æ®ç®¡ç†
- **å†…éƒ¨æœåŠ¡**: HTTP APIä¹‹é—´çš„æœåŠ¡é—´è®¤è¯

### 7.2. æƒé™æ§åˆ¶

- åŸºäºç”¨æˆ·è§’è‰²çš„workflowè§¦å‘æƒé™
- Webhookç«¯ç‚¹çš„è®¿é—®æ§åˆ¶
- é‚®ç®±ç›‘æ§çš„æƒé™éš”ç¦»
- å®¡è®¡æ—¥å¿—è®°å½•æ‰€æœ‰è§¦å‘äº‹ä»¶

### 7.3. æ•°æ®å®‰å…¨

- æ•æ„Ÿé…ç½®åŠ å¯†å­˜å‚¨
- é‚®ä»¶å†…å®¹çš„å®‰å…¨å¤„ç†
- ç½‘ç»œä¼ è¾“TLSåŠ å¯†
- åˆ†å¸ƒå¼é”çš„å®‰å…¨å®ç°

## 8. ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### 8.1. å…³é”®æŒ‡æ ‡

- éƒ¨ç½²çš„ Workflow æ•°é‡å’ŒçŠ¶æ€åˆ†å¸ƒ
- å„ç±»è§¦å‘å™¨çš„è°ƒåº¦æˆåŠŸç‡å’Œå¤±è´¥ç‡
- è°ƒåº¦å»¶è¿Ÿå’Œå“ˆå¸Œåˆ†æ•£æ•ˆæœ
- ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µï¼ˆCPUã€å†…å­˜ã€æ•°æ®åº“è¿æ¥ï¼‰
- é‚®ä»¶ç›‘æ§å»¶è¿Ÿå’Œå¤„ç†é‡

### 8.2. æ—¥å¿—ç»“æ„

```json
{
  "timestamp": "2025-01-28T10:30:00Z",
  "service": "workflow_scheduler",
  "trigger_type": "cron",
  "workflow_id": "wf_123",
  "execution_id": "exec_456",
  "event": "trigger_fired",
  "duration_ms": 1250,
  "status": "success"
}
```

### 8.3. å‘Šè­¦ç­–ç•¥

- è§¦å‘å™¨è°ƒåº¦å¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼
- è°ƒåº¦å»¶è¿Ÿå¼‚å¸¸å»¶é•¿
- é‚®ä»¶ç›‘æ§è¿æ¥å¤±è´¥
- ç³»ç»Ÿèµ„æºä¸è¶³
- ä¾èµ–æœåŠ¡ä¸å¯ç”¨ï¼ˆworkflow_engineã€æ•°æ®åº“ï¼‰

## 9. å®ç°æŠ€æœ¯æ ˆ

### 9.1. æ ¸å¿ƒæŠ€æœ¯

- **Webæ¡†æ¶**: FastAPI (Python 3.11+)
- **è°ƒåº¦å™¨**: APScheduler
- **æ•°æ®åº“**: PostgreSQL + SQLAlchemy
- **ç¼“å­˜/é”**: Redis
- **é‚®ä»¶**: aioimaplib (å¼‚æ­¥IMAPå®¢æˆ·ç«¯)
- **HTTPå®¢æˆ·ç«¯**: httpx (å¼‚æ­¥HTTP)

### 9.2. é¡¹ç›®ç»“æ„

```
workflow_scheduler/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ api/                       # REST APIç«¯ç‚¹
â”‚   â”‚   â”œâ”€â”€ deployment.py         # éƒ¨ç½²ç®¡ç†API
â”‚   â”‚   â””â”€â”€ triggers.py           # è§¦å‘å™¨ç®¡ç†API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ deployment_service.py # éƒ¨ç½²æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ trigger_manager.py    # è§¦å‘å™¨ç®¡ç†å™¨
â”‚   â”‚   â””â”€â”€ github_client.py     # GitHub Appå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ triggers/
â”‚   â”‚   â”œâ”€â”€ base.py               # åŸºç¡€è§¦å‘å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ cron_trigger.py       # Cronè§¦å‘å™¨
â”‚   â”‚   â”œâ”€â”€ manual_trigger.py     # æ‰‹åŠ¨è§¦å‘å™¨
â”‚   â”‚   â”œâ”€â”€ webhook_trigger.py    # Webhookè§¦å‘å™¨
â”‚   â”‚   â”œâ”€â”€ email_trigger.py      # é‚®ä»¶è§¦å‘å™¨
â”‚   â”‚   â””â”€â”€ github_trigger.py     # GitHubè§¦å‘å™¨
â”‚   â”œâ”€â”€ models/                   # æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ core/                     # æ ¸å¿ƒé…ç½®
â”œâ”€â”€ tests/                        # å•å…ƒæµ‹è¯•
â”œâ”€â”€ requirements.txt              # Pythonä¾èµ–
â””â”€â”€ Dockerfile                    # å®¹å™¨åŒ–é…ç½®
```

### 9.3. å¼€å‘å‘½ä»¤

```bash
# å®‰è£…ä¾èµ–
uv sync

# è¿è¡ŒæœåŠ¡
python -m workflow_scheduler.app.main

# è¿è¡Œæµ‹è¯•
pytest tests/

# æ„å»ºDockeré•œåƒ
docker build -t workflow-scheduler --platform linux/amd64 .
```

## 10. è§¦å‘å™¨åæŸ¥å’ŒåŒ¹é…æœºåˆ¶

### 10.1. é—®é¢˜åˆ†æ

**æ ¸å¿ƒæŒ‘æˆ˜**ï¼šå½“å¤–éƒ¨äº‹ä»¶å‘ç”Ÿæ—¶ï¼ˆå¦‚GitHub webhookã€é‚®ä»¶åˆ°è¾¾ã€å®šæ—¶ä»»åŠ¡è§¦å‘ï¼‰ï¼Œç³»ç»Ÿéœ€è¦å¿«é€Ÿæ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„workflowè§¦å‘å™¨ã€‚

**ç°æœ‰é—®é¢˜**ï¼š
- Workflowå®šä¹‰ä¸­è§¦å‘å™¨é…ç½®åˆ†æ•£ï¼Œéš¾ä»¥å»ºç«‹åå‘ç´¢å¼•
- äº‹ä»¶è¿‡æ»¤é€»è¾‘å¤æ‚ï¼ˆåˆ†æ”¯ã€è·¯å¾„ã€ä½œè€…ç­‰ï¼‰ï¼Œæ— æ³•é¢„è®¡ç®—
- éœ€è¦éå†æ‰€æœ‰éƒ¨ç½²çš„workflowæ‰èƒ½æ‰¾åˆ°åŒ¹é…é¡¹ï¼Œæ€§èƒ½ä½ä¸‹

### 10.2. è§¦å‘å™¨ç´¢å¼•è®¾è®¡

**æ•°æ®åº“ç´¢å¼•è¡¨**ï¼š
```sql
-- è§¦å‘å™¨å¿«é€ŸæŸ¥æ‰¾ç´¢å¼•è¡¨
CREATE TABLE trigger_index (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    workflow_id UUID NOT NULL,
    trigger_type TEXT NOT NULL, -- 'cron', 'webhook', 'email', 'github', 'manual'
    trigger_config JSONB NOT NULL, -- è§¦å‘å™¨å®Œæ•´é…ç½®

    -- å¿«é€ŸåŒ¹é…å­—æ®µ
    cron_expression TEXT, -- cronè¡¨è¾¾å¼ (ä»…cronç±»å‹)
    webhook_path TEXT, -- webhookè·¯å¾„ (ä»…webhookç±»å‹)
    email_filter TEXT, -- é‚®ä»¶è¿‡æ»¤å™¨ (ä»…emailç±»å‹)

    -- GitHubè§¦å‘å™¨ç´¢å¼•å­—æ®µ
    github_repository TEXT, -- ä»“åº“å 'owner/repo' (ä»…githubç±»å‹)
    github_events TEXT[], -- äº‹ä»¶ç±»å‹æ•°ç»„ (ä»…githubç±»å‹)
    github_installation_id BIGINT, -- GitHub Appå®‰è£…ID (ä»…githubç±»å‹)

    -- å…ƒæ•°æ®
    deployment_status TEXT DEFAULT 'active', -- 'active', 'paused', 'stopped'
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_trigger_type ON trigger_index(trigger_type);
CREATE INDEX idx_github_repo_events ON trigger_index(github_repository, github_events)
    WHERE trigger_type = 'github';
CREATE INDEX idx_webhook_path ON trigger_index(webhook_path)
    WHERE trigger_type = 'webhook';
CREATE INDEX idx_deployment_status ON trigger_index(deployment_status);
```

### 10.3. å¿«é€ŸåŒ¹é…ç®—æ³•

**äº‹ä»¶è·¯ç”±å™¨ (EventRouter)**ï¼š
```python
class EventRouter:
    def __init__(self, db_session):
        self.db = db_session

    async def find_matching_workflows(self, event_type: str, event_data: dict) -> List[TriggerMatch]:
        """æ ¹æ®äº‹ä»¶ç±»å‹å’Œæ•°æ®å¿«é€Ÿæ‰¾åˆ°åŒ¹é…çš„è§¦å‘å™¨"""

        if event_type == "github":
            return await self._find_github_matches(event_data)
        elif event_type == "webhook":
            return await self._find_webhook_matches(event_data)
        elif event_type == "email":
            return await self._find_email_matches(event_data)
        elif event_type == "cron":
            return await self._find_cron_matches(event_data)

        return []

    async def _find_github_matches(self, event_data: dict) -> List[TriggerMatch]:
        """GitHubäº‹ä»¶å¿«é€ŸåŒ¹é…"""
        repository = event_data["repository"]["full_name"]
        event_type = event_data["event"]

        # 1. åŸºç¡€ç´¢å¼•æŸ¥è¯¢ - å¿«é€Ÿç­›é€‰
        base_query = """
        SELECT workflow_id, trigger_config
        FROM trigger_index
        WHERE trigger_type = 'github'
          AND deployment_status = 'active'
          AND github_repository = %s
          AND %s = ANY(github_events)
        """

        candidates = await self.db.fetch_all(base_query, repository, event_type)

        # 2. é«˜çº§è¿‡æ»¤ - è¯¦ç»†åŒ¹é…
        matches = []
        for candidate in candidates:
            trigger_config = candidate["trigger_config"]

            if self._matches_github_filters(event_data, trigger_config):
                matches.append(TriggerMatch(
                    workflow_id=candidate["workflow_id"],
                    trigger_config=trigger_config,
                    match_score=self._calculate_match_score(event_data, trigger_config)
                ))

        return matches

    def _matches_github_filters(self, event_data: dict, config: dict) -> bool:
        """åº”ç”¨GitHubé«˜çº§è¿‡æ»¤å™¨"""
        # åˆ†æ”¯è¿‡æ»¤
        if config.get("branches"):
            if event_data["event"] == "push":
                branch = event_data["payload"]["ref"].replace("refs/heads/", "")
            elif event_data["event"] == "pull_request":
                branch = event_data["payload"]["pull_request"]["base"]["ref"]
            else:
                branch = None

            if branch and branch not in config["branches"]:
                return False

        # è·¯å¾„è¿‡æ»¤
        if config.get("paths"):
            changed_files = self._extract_changed_files(event_data)
            if not self._matches_path_patterns(changed_files, config["paths"]):
                return False

        # ä½œè€…è¿‡æ»¤
        if config.get("author_filter"):
            author = self._extract_author(event_data)
            if not re.match(config["author_filter"], author):
                return False

        # åŠ¨ä½œè¿‡æ»¤
        if config.get("action_filter"):
            action = event_data.get("action")
            if action and action not in config["action_filter"]:
                return False

        return True

    async def _find_webhook_matches(self, event_data: dict) -> List[TriggerMatch]:
        """Webhookè·¯å¾„ç›´æ¥åŒ¹é…"""
        webhook_path = event_data["path"]

        query = """
        SELECT workflow_id, trigger_config
        FROM trigger_index
        WHERE trigger_type = 'webhook'
          AND deployment_status = 'active'
          AND webhook_path = %s
        """

        results = await self.db.fetch_all(query, webhook_path)

        return [
            TriggerMatch(
                workflow_id=result["workflow_id"],
                trigger_config=result["trigger_config"],
                match_score=1.0  # ç²¾ç¡®åŒ¹é…
            )
            for result in results
        ]
```

### 10.4. è§¦å‘å™¨æ³¨å†Œç®¡ç†

**TriggerIndexManager**ï¼š
```python
class TriggerIndexManager:
    def __init__(self, db_session):
        self.db = db_session

    async def register_workflow_triggers(self, workflow_id: str, workflow_spec: dict):
        """æ³¨å†Œworkflowçš„æ‰€æœ‰è§¦å‘å™¨åˆ°ç´¢å¼•è¡¨"""

        # æ¸…é™¤æ—§çš„ç´¢å¼•è®°å½•
        await self.db.execute(
            "DELETE FROM trigger_index WHERE workflow_id = %s",
            workflow_id
        )

        # è§£æworkflowä¸­çš„è§¦å‘å™¨èŠ‚ç‚¹
        trigger_nodes = self._extract_trigger_nodes(workflow_spec)

        for trigger_node in trigger_nodes:
            await self._index_trigger(workflow_id, trigger_node)

    async def _index_trigger(self, workflow_id: str, trigger_node: dict):
        """å°†å•ä¸ªè§¦å‘å™¨æ·»åŠ åˆ°ç´¢å¼•"""
        trigger_type = trigger_node["subtype"].replace("TRIGGER_", "").lower()
        trigger_config = trigger_node["parameters"]

        index_data = {
            "workflow_id": workflow_id,
            "trigger_type": trigger_type,
            "trigger_config": trigger_config,
            "deployment_status": "active"
        }

        # æ ¹æ®è§¦å‘å™¨ç±»å‹å¡«å……ç´¢å¼•å­—æ®µ
        if trigger_type == "github":
            index_data.update({
                "github_repository": trigger_config["repository"],
                "github_events": trigger_config["events"],
                "github_installation_id": trigger_config["github_app_installation_id"]
            })
        elif trigger_type == "webhook":
            index_data.update({
                "webhook_path": trigger_config.get("webhook_path", f"/webhook/{workflow_id}")
            })
        elif trigger_type == "email":
            index_data.update({
                "email_filter": trigger_config.get("email_filter", "")
            })
        elif trigger_type == "cron":
            index_data.update({
                "cron_expression": trigger_config["cron_expression"]
            })

        await self.db.execute(
            """
            INSERT INTO trigger_index (
                workflow_id, trigger_type, trigger_config,
                github_repository, github_events, github_installation_id,
                webhook_path, email_filter, cron_expression, deployment_status
            ) VALUES (
                %(workflow_id)s, %(trigger_type)s, %(trigger_config)s,
                %(github_repository)s, %(github_events)s, %(github_installation_id)s,
                %(webhook_path)s, %(email_filter)s, %(cron_expression)s, %(deployment_status)s
            )
            """,
            index_data
        )

    def _extract_trigger_nodes(self, workflow_spec: dict) -> List[dict]:
        """ä»workflowå®šä¹‰ä¸­æå–æ‰€æœ‰è§¦å‘å™¨èŠ‚ç‚¹"""
        trigger_nodes = []

        for node in workflow_spec.get("nodes", []):
            if node.get("node_type") == "TRIGGER_NODE":
                trigger_nodes.append(node)

        return trigger_nodes
```

## 11. å†…æµ‹æ¨¡å¼ - é‚®ä»¶é€šçŸ¥ç³»ç»Ÿ

### 11.1. å†…æµ‹é…ç½®

**ç¯å¢ƒå˜é‡é…ç½®**ï¼š
```bash
# å†…æµ‹æ¨¡å¼é…ç½®
TESTING_MODE="true"
TESTING_EMAIL_RECIPIENT="z1771485029@gmail.com"
SKIP_WORKFLOW_EXECUTION="true"

# é‚®ä»¶å®¢æˆ·ç«¯é…ç½® (ä½¿ç”¨shared/email_client)
EMAIL_CLIENT_TYPE="migadu"  # æˆ– "smtp"
```

### 11.2. å†…æµ‹è§¦å‘å™¨å®ç°

**æµ‹è¯•æ¨¡å¼åŸºç¡€ç±»**ï¼š
```python
class BaseTriggerTesting(BaseTrigger):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.testing_mode = os.getenv("TESTING_MODE", "false").lower() == "true"
        self.testing_email = os.getenv("TESTING_EMAIL_RECIPIENT")

        if self.testing_mode:
            from shared.email_client import get_email_client
            self.email_client = get_email_client()

    async def _trigger_workflow(self, trigger_data: dict):
        """é‡å†™è§¦å‘æ–¹æ³• - å†…æµ‹æ¨¡å¼å‘é€é‚®ä»¶é€šçŸ¥"""

        if self.testing_mode:
            await self._send_testing_notification(trigger_data)
            return {"status": "testing_notification_sent", "email": self.testing_email}
        else:
            # ç”Ÿäº§æ¨¡å¼ - è°ƒç”¨workflow_engine
            return await super()._trigger_workflow(trigger_data)

    async def _send_testing_notification(self, trigger_data: dict):
        """å‘é€å†…æµ‹é‚®ä»¶é€šçŸ¥"""

        # æ„é€ é‚®ä»¶å†…å®¹
        subject = f"ğŸš€ Workflow Trigger Alert - {self.trigger_type.upper()}"

        # é‚®ä»¶æ­£æ–‡
        email_body = f"""
        <h2>Workflow Scheduler å†…æµ‹é€šçŸ¥</h2>

        <p><strong>è§¦å‘è¯¦æƒ…ï¼š</strong></p>
        <ul>
            <li><strong>Workflow ID:</strong> {self.workflow_id}</li>
            <li><strong>è§¦å‘å™¨ç±»å‹:</strong> {self.trigger_type}</li>
            <li><strong>è§¦å‘æ—¶é—´:</strong> {datetime.now().isoformat()}</li>
        </ul>

        <p><strong>è§¦å‘æ•°æ®:</strong></p>
        <pre style="background: #f5f5f5; padding: 10px; border-radius: 5px;">
{json.dumps(trigger_data, indent=2, ensure_ascii=False)}
        </pre>

        <p><strong>è§¦å‘å™¨é…ç½®:</strong></p>
        <pre style="background: #f5f5f5; padding: 10px; border-radius: 5px;">
{json.dumps(self.config.__dict__ if hasattr(self.config, '__dict__') else str(self.config), indent=2, ensure_ascii=False)}
        </pre>

        <hr>
        <p><em>è¿™æ˜¯å†…æµ‹æ¨¡å¼é€šçŸ¥ï¼Œå®é™…workflowå¹¶æœªæ‰§è¡Œã€‚</em></p>
        <p><em>ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}</em></p>
        """

        try:
            await self.email_client.send_email(
                to_email=self.testing_email,
                subject=subject,
                html_body=email_body,
                from_name="Workflow Scheduler Testing"
            )

            logger.info(f"Testing notification sent to {self.testing_email} for workflow {self.workflow_id}")

        except Exception as e:
            logger.error(f"Failed to send testing notification: {e}")
```

### 11.3. å„è§¦å‘å™¨çš„å†…æµ‹å®ç°

**GitHubè§¦å‘å™¨å†…æµ‹**ï¼š
```python
class GitHubTrigger(BaseTriggerTesting):
    async def _send_testing_notification(self, trigger_data: dict):
        """GitHubè§¦å‘å™¨ä¸“ç”¨é‚®ä»¶é€šçŸ¥"""
        event_type = trigger_data.get("event")
        repository = trigger_data.get("repository", {}).get("full_name", "unknown")
        action = trigger_data.get("action")

        subject = f"ğŸ™ GitHub {event_type.title()} Trigger - {repository}"

        # GitHubç‰¹å®šçš„é‚®ä»¶å†…å®¹
        github_info = f"""
        <h3>GitHub Event Details</h3>
        <ul>
            <li><strong>Repository:</strong> {repository}</li>
            <li><strong>Event:</strong> {event_type}</li>
            <li><strong>Action:</strong> {action or 'N/A'}</li>
            <li><strong>Sender:</strong> {trigger_data.get('sender', {}).get('login', 'unknown')}</li>
        </ul>
        """

        if event_type == "pull_request":
            pr_info = trigger_data.get("payload", {})
            github_info += f"""
            <h4>Pull Request Info</h4>
            <ul>
                <li><strong>PR #:</strong> {pr_info.get('number', 'unknown')}</li>
                <li><strong>Title:</strong> {pr_info.get('title', 'unknown')}</li>
                <li><strong>Base Branch:</strong> {pr_info.get('base', {}).get('ref', 'unknown')}</li>
            </ul>
            """

        # è°ƒç”¨åŸºç±»æ–¹æ³•ï¼Œä¼ å…¥å¢å¼ºçš„å†…å®¹
        base_body = await super()._send_testing_notification(trigger_data)
        enhanced_body = base_body.replace(
            "<h2>Workflow Scheduler å†…æµ‹é€šçŸ¥</h2>",
            f"<h2>Workflow Scheduler å†…æµ‹é€šçŸ¥</h2>{github_info}"
        )

        await self.email_client.send_email(
            to_email=self.testing_email,
            subject=subject,
            html_body=enhanced_body,
            from_name="GitHub Workflow Scheduler"
        )
```

### 11.4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

**ç´¢å¼•æŸ¥è¯¢ä¼˜åŒ–**ï¼š
- ä½¿ç”¨æ•°æ®åº“è¿æ¥æ± å‡å°‘è¿æ¥å¼€é”€
- é¢„è®¡ç®—å¸¸ç”¨è¿‡æ»¤å™¨ç»„åˆ
- ä½¿ç”¨Redisç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢ç»“æœ
- æ‰¹é‡å¤„ç†å¤šä¸ªäº‹ä»¶

**åŒ¹é…ç®—æ³•ä¼˜åŒ–**ï¼š
```python
class OptimizedEventRouter(EventRouter):
    def __init__(self, db_session, redis_client):
        super().__init__(db_session)
        self.redis = redis_client
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜

    async def find_matching_workflows(self, event_type: str, event_data: dict) -> List[TriggerMatch]:
        # æ„é€ ç¼“å­˜é”®
        cache_key = self._build_cache_key(event_type, event_data)

        # å°è¯•ä»ç¼“å­˜è·å–
        cached_result = await self.redis.get(cache_key)
        if cached_result:
            return json.loads(cached_result)

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒæŸ¥è¯¢
        matches = await super().find_matching_workflows(event_type, event_data)

        # ç¼“å­˜ç»“æœ
        await self.redis.setex(
            cache_key,
            self.cache_ttl,
            json.dumps([m.to_dict() for m in matches])
        )

        return matches
```

è¿™ä¸ªè®¾è®¡è§£å†³äº†è§¦å‘å™¨åæŸ¥çš„æ ¸å¿ƒé—®é¢˜ï¼Œå¹¶æä¾›äº†å®Œæ•´çš„å†…æµ‹é‚®ä»¶é€šçŸ¥æ–¹æ¡ˆã€‚

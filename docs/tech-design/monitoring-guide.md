# ğŸ“š AI Teams åˆ†å¸ƒå¼ç›‘æ§ç³»ç»Ÿå®Œæ•´ä½¿ç”¨æ‰‹å†Œ

## ğŸŒŸ æ ¸å¿ƒæ¦‚å¿µä»‹ç»

### **1. OpenTelemetry (OTel)**
**æ˜¯ä»€ä¹ˆï¼Ÿ** 
- å¼€æºçš„å¯è§‚æµ‹æ€§æ¡†æ¶ï¼Œæä¾›ç»Ÿä¸€çš„ API å’Œ SDK
- ç”¨äºæ”¶é›†ã€å¤„ç†å’Œå¯¼å‡ºè¿½è¸ª(Traces)ã€æŒ‡æ ‡(Metrics)å’Œæ—¥å¿—(Logs)æ•°æ®
- å‚å•†ä¸­ç«‹ï¼Œæ”¯æŒå¯¼å‡ºåˆ°ä»»ä½•ç›‘æ§åç«¯

**åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š**
- è‡ªåŠ¨æ”¶é›†æ‰€æœ‰ HTTP è¯·æ±‚çš„è¿½è¸ªæ•°æ®
- è®°å½•æœåŠ¡é—´è°ƒç”¨é“¾è·¯
- æ”¶é›†æ€§èƒ½æŒ‡æ ‡

### **2. Jaeger**
**æ˜¯ä»€ä¹ˆï¼Ÿ**
- å¼€æºçš„åˆ†å¸ƒå¼è¿½è¸ªç³»ç»Ÿï¼Œç”± Uber å¼€å‘
- ç”¨äºç›‘æ§å’Œæ•…éšœæ’é™¤å¾®æœåŠ¡æ¶æ„
- æä¾›å¯è§†åŒ–çš„è¯·æ±‚é“¾è·¯å›¾

**åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š**
- æœ¬åœ°è°ƒè¯•å·¥å…·
- æŸ¥çœ‹è¯·æ±‚åœ¨å„ä¸ªæœåŠ¡é—´çš„æµè½¬è¿‡ç¨‹
- åˆ†ææ€§èƒ½ç“¶é¢ˆ

### **3. Prometheus**
**æ˜¯ä»€ä¹ˆï¼Ÿ**
- å¼€æºçš„ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
- åŸºäºæ—¶é—´åºåˆ—æ•°æ®åº“
- ä½¿ç”¨æ‹‰å–(Pull)æ¨¡å¼æ”¶é›†æŒ‡æ ‡

**åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š**
- æœ¬åœ°çŸ­æœŸæŒ‡æ ‡å­˜å‚¨
- æ”¶é›†æœåŠ¡çš„æ€§èƒ½æŒ‡æ ‡
- æä¾›æŸ¥è¯¢æ¥å£

### **4. Grafana Cloud**
**æ˜¯ä»€ä¹ˆï¼Ÿ**
- Grafana Labs æä¾›çš„æ‰˜ç®¡ç›‘æ§æœåŠ¡
- åŒ…å«å¤šä¸ªç»„ä»¶ï¼šMimirï¼ˆæŒ‡æ ‡ï¼‰ã€Lokiï¼ˆæ—¥å¿—ï¼‰ã€Tempoï¼ˆè¿½è¸ªï¼‰

**Mimirï¼š**
- é•¿æœŸæŒ‡æ ‡å­˜å‚¨
- å…¼å®¹ Prometheus æŸ¥è¯¢è¯­è¨€(PromQL)
- é«˜å¯ç”¨å’Œå¯æ‰©å±•

**Lokiï¼š**
- æ—¥å¿—èšåˆç³»ç»Ÿ
- ç±»ä¼¼ Prometheusï¼Œä½†ç”¨äºæ—¥å¿—
- æ”¯æŒæ ‡ç­¾æŸ¥è¯¢å’Œå…¨æ–‡æœç´¢

---

## ğŸ—ï¸ ç›‘æ§ç³»ç»Ÿæ¶æ„ä¸æ•°æ®æµ

### **æ•´ä½“æ¶æ„å›¾**

```mermaid
graph TB
    subgraph "åº”ç”¨æœåŠ¡"
        A1[API Gateway<br/>:8000]
        A2[Workflow Agent<br/>:8001]
        A3[Workflow Engine<br/>:8002]
    end
    
    subgraph "OpenTelemetry SDK"
        SDK1[OTel SDK<br/>in API Gateway]
        SDK2[OTel SDK<br/>in Workflow Agent]
        SDK3[OTel SDK<br/>in Workflow Engine]
    end
    
    subgraph "æ•°æ®æ”¶é›†å±‚"
        OC[OpenTelemetry Collector<br/>:4317 gRPC<br/>:4318 HTTP]
        PROM[Prometheus<br/>:9090]
    end
    
    subgraph "æœ¬åœ°å­˜å‚¨ä¸å¯è§†åŒ–"
        JAE[Jaeger<br/>:16686 UI<br/>:14250 gRPC]
    end
    
    subgraph "Grafana Cloud"
        GCM[Grafana Cloud Mimir<br/>é•¿æœŸæŒ‡æ ‡å­˜å‚¨]
        GCL[Grafana Cloud Loki<br/>æ—¥å¿—èšåˆ]
        GCT[Grafana Cloud Tempo<br/>åˆ†å¸ƒå¼è¿½è¸ª]
    end
    
    %% åº”ç”¨åˆ°SDK
    A1 --> SDK1
    A2 --> SDK2
    A3 --> SDK3
    
    %% SDKåˆ°Collector
    SDK1 -->|OTLP gRPC<br/>Traces & Metrics| OC
    SDK2 -->|OTLP gRPC<br/>Traces & Metrics| OC
    SDK3 -->|OTLP gRPC<br/>Traces & Metrics| OC
    
    %% SDKåˆ°Prometheus
    SDK1 -->|/metrics<br/>Pull| PROM
    SDK2 -->|/metrics<br/>Pull| PROM
    SDK3 -->|/metrics<br/>Pull| PROM
    
    %% Collectoråˆ†å‘
    OC -->|Traces| JAE
    OC -->|Metrics| GCM
    OC -->|Logs| GCL
    OC -->|Traces| GCT
    
    %% Prometheusè¿œç¨‹å†™å…¥
    PROM -->|Remote Write| GCM
    
    %% æ—¥å¿—ç›´æ¥è¾“å‡º
    A1 -.->|Structured Logs<br/>CloudWatch| GCL
    A2 -.->|Structured Logs<br/>CloudWatch| GCL
    A3 -.->|Structured Logs<br/>CloudWatch| GCL
```

### **ç»„ä»¶åä½œåŸç†**

#### **1. æ•°æ®ç”Ÿæˆå±‚ - åº”ç”¨æœåŠ¡**

æ¯ä¸ªæœåŠ¡é€šè¿‡ `shared.telemetry` æ¨¡å—åˆå§‹åŒ– OpenTelemetry SDKï¼š

```python
# åœ¨ apps/backend/api-gateway/app/main.py
from shared.telemetry import setup_telemetry, TrackingMiddleware, MetricsMiddleware

# åˆå§‹åŒ–é¥æµ‹ç³»ç»Ÿ
setup_telemetry(
    app=app,
    service_name="api-gateway",
    service_version="1.0.0",
    otlp_endpoint="http://localhost:4317",  # OTel Collector åœ°å€
    prometheus_port=8000
)
```

**æ•°æ®ç±»å‹ç”Ÿæˆï¼š**
- **Tracesï¼ˆè¿½è¸ªï¼‰**: è‡ªåŠ¨è®°å½•æ¯ä¸ª HTTP è¯·æ±‚çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
- **Metricsï¼ˆæŒ‡æ ‡ï¼‰**: è®°å½•è¯·æ±‚æ•°ã€å»¶è¿Ÿã€é”™è¯¯ç‡ç­‰
- **Logsï¼ˆæ—¥å¿—ï¼‰**: ç»“æ„åŒ– JSON æ—¥å¿—ï¼ŒåŒ…å« trace_id å…³è”

#### **2. æ•°æ®æ”¶é›†å±‚ - OpenTelemetry SDK**

SDK åœ¨æ¯ä¸ªæœåŠ¡å†…éƒ¨è¿è¡Œï¼Œè´Ÿè´£ï¼š

```python
# shared/telemetry/complete_stack.py
def _setup_tracing(resource: Resource, otlp_endpoint: str):
    # åˆ›å»º TracerProvider
    tracer_provider = TracerProvider(resource=resource)
    trace.set_tracer_provider(tracer_provider)
    
    # é…ç½® OTLP å¯¼å‡ºå™¨ - å‘é€åˆ° Collector
    otlp_exporter = OTLPSpanExporter(endpoint=otlp_endpoint, insecure=True)
    span_processor = BatchSpanProcessor(otlp_exporter)
    tracer_provider.add_span_processor(span_processor)
```

**å…³é”®åŠŸèƒ½ï¼š**
- **è‡ªåŠ¨è£…é…**: FastAPIã€HTTP å®¢æˆ·ç«¯ã€æ•°æ®åº“è°ƒç”¨è‡ªåŠ¨è¿½è¸ª
- **ä¸Šä¸‹æ–‡ä¼ æ’­**: è·¨æœåŠ¡ä¼ é€’ trace_id å®ç°åˆ†å¸ƒå¼è¿½è¸ª
- **æ‰¹é‡å¯¼å‡º**: é«˜æ•ˆå‘é€æ•°æ®åˆ° Collector

#### **3. æ•°æ®è·¯ç”±å±‚ - OpenTelemetry Collector**

Collector æ˜¯ä¸­å¿ƒåŒ–çš„æ•°æ®å¤„ç†å™¨ï¼š

```yaml
# monitoring/otel-collector-config.yml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317  # æ¥æ”¶æ¥è‡ª SDK çš„æ•°æ®
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 1s
    send_batch_size: 1024
  
  attributes:
    actions:
      - key: environment
        value: ${ENVIRONMENT}
        action: insert

exporters:
  # æœ¬åœ° Jaeger
  jaeger:
    endpoint: jaeger:14250
    tls: { insecure: true }
  
  # Grafana Cloud
  otlphttp/grafana-cloud-traces:
    endpoint: ${GRAFANA_CLOUD_TEMPO_URL}
    headers:
      authorization: Basic ${GRAFANA_CLOUD_API_KEY}
```

**æ•°æ®æµå‘ï¼š**
1. **æ¥æ”¶**: ä»æ‰€æœ‰æœåŠ¡æ¥æ”¶ OTLP æ ¼å¼æ•°æ®
2. **å¤„ç†**: æ‰¹é‡å¤„ç†ã€æ·»åŠ æ ‡ç­¾ã€æ•°æ®è½¬æ¢
3. **å¯¼å‡º**: åŒæ—¶å‘é€åˆ°å¤šä¸ªåç«¯ï¼ˆJaegerã€Grafana Cloudï¼‰

#### **4. å­˜å‚¨ä¸å¯è§†åŒ–å±‚**

##### **Jaegerï¼ˆæœ¬åœ°è¿½è¸ªï¼‰**
- **ç”¨é€”**: å¼€å‘è°ƒè¯•ï¼ŒæŸ¥çœ‹è¯·æ±‚é“¾è·¯
- **æ•°æ®æº**: ä» Collector æ¥æ”¶ traces
- **è®¿é—®**: http://localhost:16686

##### **Prometheusï¼ˆæœ¬åœ°æŒ‡æ ‡ï¼‰**
- **ç”¨é€”**: çŸ­æœŸæŒ‡æ ‡å­˜å‚¨å’ŒæŸ¥è¯¢
- **æ•°æ®æº**: ä¸»åŠ¨æ‹‰å–å„æœåŠ¡çš„ /metrics ç«¯ç‚¹
- **é…ç½®**:
```yaml
# monitoring/prometheus.yml
scrape_configs:
  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: '/metrics'
```

##### **Grafana Cloudï¼ˆç”Ÿäº§ç›‘æ§ï¼‰**
- **Mimir**: é•¿æœŸæŒ‡æ ‡å­˜å‚¨ï¼Œæ¥æ”¶ Prometheus è¿œç¨‹å†™å…¥
- **Loki**: æ—¥å¿—èšåˆï¼Œé€šè¿‡ CloudWatch æˆ–ç›´æ¥æ¨é€
- **Tempo**: åˆ†å¸ƒå¼è¿½è¸ªå­˜å‚¨ï¼Œä» Collector æ¥æ”¶

### **å…·ä½“ä»£ç å®ç°**

#### **1. è¿½è¸ªç”Ÿæˆä¸ä¼ æ’­**

```python
# shared/telemetry/middleware.py
class TrackingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        # è·å–å½“å‰ OpenTelemetry span
        span = trace.get_current_span()
        
        if span.is_recording():
            # æå– trace_id ä½œä¸º tracking_id
            span_context = span.get_span_context()
            tracking_id = format(span_context.trace_id, '032x')
            
            # å­˜å‚¨åˆ°è¯·æ±‚çŠ¶æ€ï¼Œä¾›ä¸šåŠ¡ä»£ç ä½¿ç”¨
            request.state.tracking_id = tracking_id
            
            # æ·»åŠ  span å±æ€§
            span.set_attribute("tracking.id", tracking_id)
            span.set_attribute("http.method", request.method)
            span.set_attribute("http.url", str(request.url))
```

**è·¨æœåŠ¡ä¼ æ’­ï¼š**
```python
# åœ¨ API Gateway è°ƒç”¨å…¶ä»–æœåŠ¡æ—¶
async def call_workflow_agent(data: dict):
    # OpenTelemetry è‡ªåŠ¨æ³¨å…¥è¿½è¸ªå¤´éƒ¨
    async with httpx.AsyncClient() as client:
        # TracePropagator è‡ªåŠ¨æ·»åŠ  traceparent å¤´éƒ¨
        response = await client.post(
            "http://workflow-agent:8001/generate",
            json=data
        )
    return response.json()
```

#### **2. æŒ‡æ ‡æ”¶é›†ä¸å¯¼å‡º**

```python
# shared/telemetry/metrics.py
class MetricsCollector:
    def __init__(self, service_name: str):
        self.meter = metrics.get_meter(service_name)
        
        # åˆ›å»ºæŒ‡æ ‡
        self.request_count = self.meter.create_counter(
            name="http_requests_total",
            description="Total HTTP requests",
            unit="1"
        )
        
        self.request_duration = self.meter.create_histogram(
            name="http_request_duration_seconds",
            description="HTTP request duration",
            unit="s"
        )
```

**æŒ‡æ ‡è®°å½•ï¼š**
```python
# shared/telemetry/middleware.py
class MetricsMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start_time = time.time()
        
        try:
            response = await call_next(request)
            duration = time.time() - start_time
            
            # è®°å½•æŒ‡æ ‡
            self.metrics.request_count.add(1, {
                'service_name': self.service_name,
                'endpoint': request.url.path,
                'method': request.method,
                'status_code': str(response.status_code)
            })
            
            self.metrics.request_duration.record(duration, {
                'service_name': self.service_name,
                'endpoint': request.url.path
            })
```

#### **3. æ—¥å¿—å…³è”**

```python
# shared/telemetry/formatter.py
class CloudWatchTracingFormatter(logging.Formatter):
    def format(self, record):
        # è·å–å½“å‰ trace context
        span = trace.get_current_span()
        if span.is_recording():
            span_context = span.get_span_context()
            trace_id = format(span_context.trace_id, '032x')
            span_id = format(span_context.span_id, '016x')
        else:
            trace_id = "no-trace"
            span_id = "no-span"
        
        # æ„å»ºç»“æ„åŒ–æ—¥å¿—
        log_record = {
            "@timestamp": self.formatTime(record, self.datefmt),
            "@level": record.levelname,
            "@message": record.getMessage(),
            "@logger": record.name,
            "@thread": record.thread,
            "service": self.service_name,
            "trace_id": trace_id,
            "span_id": span_id,
            "file": f"{record.filename}:{record.lineno}"
        }
        
        return json.dumps(log_record)
```

### **æ•°æ®æŸ¥è¯¢ç¤ºä¾‹**

#### **1. åœ¨ Jaeger ä¸­è¿½è¸ªè¯·æ±‚**
```
1. è®¿é—® http://localhost:16686
2. é€‰æ‹©æœåŠ¡: api-gateway
3. æŸ¥æ‰¾æ“ä½œ: POST /api/app/workflows
4. æŸ¥çœ‹å®Œæ•´è°ƒç”¨é“¾:
   - api-gateway (100ms)
   - â†’ workflow-agent (500ms)
   - â†’ workflow-engine (200ms)
```

#### **2. åœ¨ Prometheus æŸ¥è¯¢æŒ‡æ ‡**
```promql
# æœåŠ¡è¯·æ±‚é€Ÿç‡
rate(http_requests_total{service_name="api-gateway"}[5m])

# P95 å»¶è¿Ÿ
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

#### **3. åœ¨ Grafana Cloud å…³è”æ•°æ®**
```
1. ä½¿ç”¨ trace_id å…³è”æ‰€æœ‰æ•°æ®:
   - Tempo: æŸ¥çœ‹åˆ†å¸ƒå¼è¿½è¸ª
   - Loki: æŸ¥çœ‹ç›¸å…³æ—¥å¿—
   - Mimir: æŸ¥çœ‹æ—¶é—´æ®µå†…çš„æŒ‡æ ‡

2. åˆ›å»ºç»Ÿä¸€ä»ªè¡¨æ¿å±•ç¤º:
   - è¿½è¸ªæ•°æ®é¢æ¿
   - æ—¥å¿—æµé¢æ¿
   - æŒ‡æ ‡å›¾è¡¨
```

### **å…³é”®é›†æˆç‚¹**

1. **æœåŠ¡åˆå§‹åŒ–**: `setup_telemetry()` ä¸€æ¬¡æ€§é…ç½®æ‰€æœ‰ç»„ä»¶
2. **ä¸­é—´ä»¶æ³¨å†Œ**: è‡ªåŠ¨æ”¶é›†æ•°æ®ï¼Œæ— éœ€ä¿®æ”¹ä¸šåŠ¡ä»£ç 
3. **ä¸Šä¸‹æ–‡ä¼ æ’­**: OpenTelemetry è‡ªåŠ¨å¤„ç†è·¨æœåŠ¡è¿½è¸ª
4. **ç»Ÿä¸€ trace_id**: æ‰€æœ‰é¥æµ‹æ•°æ®é€šè¿‡ trace_id å…³è”

è¿™ä¸ªæ¶æ„ç¡®ä¿äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§ï¼Œä»è¯·æ±‚è¿›å…¥ç³»ç»Ÿåˆ°å“åº”è¿”å›ï¼Œæ¯ä¸€æ­¥éƒ½è¢«è®°å½•å’Œå…³è”ã€‚

---

## ğŸ”§ å¦‚ä½•åœ¨ä»£ç ä¸­ä½¿ç”¨

### **1. åˆå§‹åŒ–é¥æµ‹ç³»ç»Ÿ**

åœ¨æ¯ä¸ªæœåŠ¡çš„ `main.py` ä¸­ï¼š

```python
# apps/backend/api-gateway/app/main.py
from shared.telemetry import setup_telemetry, TrackingMiddleware, MetricsMiddleware

# åˆå§‹åŒ–é¥æµ‹ç³»ç»Ÿ
setup_telemetry(app, service_name="api-gateway", service_version="1.0.0")

# æ·»åŠ ä¸­é—´ä»¶
app.add_middleware(TrackingMiddleware)  # è‡ªåŠ¨è¿½è¸ªè¯·æ±‚
app.add_middleware(MetricsMiddleware, service_name="api-gateway")  # æ”¶é›†æŒ‡æ ‡
```

### **2. ä½¿ç”¨è¿½è¸ªåŠŸèƒ½**

#### **è‡ªåŠ¨è¿½è¸ªï¼ˆå·²é›†æˆï¼‰**
```python
# æ‰€æœ‰ HTTP è¯·æ±‚è‡ªåŠ¨è¢«è¿½è¸ªï¼Œæ— éœ€é¢å¤–ä»£ç 
@app.get("/api/app/sessions")
async def get_sessions():
    # è¿™ä¸ªç«¯ç‚¹çš„æ¯æ¬¡è°ƒç”¨éƒ½ä¼šè¢«è‡ªåŠ¨è¿½è¸ª
    return {"sessions": [...]}
```

#### **æ‰‹åŠ¨æ·»åŠ è¿½è¸ª Span**
```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

async def process_workflow(workflow_id: str):
    # åˆ›å»ºä¸€ä¸ªæ–°çš„ span
    with tracer.start_as_current_span("process_workflow") as span:
        # æ·»åŠ å±æ€§
        span.set_attribute("workflow.id", workflow_id)
        span.set_attribute("workflow.type", "ai_generation")
        
        # ä¸šåŠ¡é€»è¾‘
        result = await generate_workflow(workflow_id)
        
        # è®°å½•äº‹ä»¶
        span.add_event("workflow_generated", {
            "nodes_count": len(result.nodes)
        })
        
        return result
```

### **3. è®°å½•ä¸šåŠ¡æŒ‡æ ‡**

```python
from shared.telemetry.metrics import get_metrics_collector

metrics = get_metrics_collector()

# è®¡æ•°å™¨ - ç»Ÿè®¡å·¥ä½œæµæ‰§è¡Œæ¬¡æ•°
metrics.workflow_executions.add(1, {
    "workflow_type": "data_processing",
    "status": "success"
})

# ç›´æ–¹å›¾ - è®°å½•æ‰§è¡Œæ—¶é—´
import time
start_time = time.time()
# ... æ‰§è¡Œå·¥ä½œæµ ...
duration = time.time() - start_time
metrics.workflow_duration.record(duration, {
    "workflow_type": "data_processing"
})

# é‡è¡¨ - è®°å½•å½“å‰å€¼
metrics.active_sessions.set(42, {
    "service": "api-gateway"
})
```

### **4. ç»“æ„åŒ–æ—¥å¿—**

```python
import logging

logger = logging.getLogger(__name__)

# æ—¥å¿—ä¼šè‡ªåŠ¨åŒ…å« tracking_id
logger.info("Processing workflow", extra={
    "workflow_id": "wf-123",
    "user_id": "user-456",
    "operation": "generate"
})

# é”™è¯¯æ—¥å¿—ä¼šåˆ›å»º Span Event
try:
    result = await risky_operation()
except Exception as e:
    logger.error(f"Operation failed: {str(e)}", extra={
        "error_type": type(e).__name__,
        "workflow_id": "wf-123"
    })
```

### **5. è·¨æœåŠ¡è¿½è¸ªä¼ æ’­**

```python
# åœ¨ API Gateway è°ƒç”¨ Workflow Agent
import httpx

async def call_workflow_agent(data: dict):
    # TrackingMiddleware è‡ªåŠ¨æ³¨å…¥è¿½è¸ªå¤´éƒ¨
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://workflow-agent:8001/generate",
            json=data,
            headers={
                # tracking_id è‡ªåŠ¨ä»å½“å‰è¯·æ±‚ä¼ æ’­
                "X-Tracking-ID": request.state.tracking_id
            }
        )
    return response.json()
```

---

## ğŸ“Š åœ¨å“ªé‡ŒæŸ¥çœ‹ç›‘æ§æ•°æ®

### **1. æœ¬åœ° Jaeger UI (è¿½è¸ª)**

**è®¿é—®åœ°å€ï¼š** `http://localhost:16686`

**æŸ¥çœ‹å†…å®¹ï¼š**
- è¯·æ±‚é“¾è·¯å›¾
- æœåŠ¡é—´è°ƒç”¨å…³ç³»
- æ¯ä¸ªæ“ä½œçš„è€—æ—¶
- é”™è¯¯å’Œå¼‚å¸¸

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
1. æ‰“å¼€ Jaeger UI
2. é€‰æ‹©æœåŠ¡ï¼ˆå¦‚ "api-gateway"ï¼‰
3. è¾“å…¥ tracking_id æˆ–æ—¶é—´èŒƒå›´
4. æŸ¥çœ‹è¯·æ±‚çš„å®Œæ•´é“¾è·¯

**Jaeger UI åŠŸèƒ½è¯´æ˜ï¼š**
- **Service**: é€‰æ‹©è¦æŸ¥çœ‹çš„æœåŠ¡
- **Operation**: é€‰æ‹©ç‰¹å®šçš„æ“ä½œï¼ˆå¦‚ GET /api/app/sessionsï¼‰
- **Tags**: ä½¿ç”¨æ ‡ç­¾è¿‡æ»¤ï¼ˆå¦‚ error=true, user.id=123ï¼‰
- **Lookback**: æ—¶é—´èŒƒå›´
- **Trace Timeline**: å±•ç¤ºè¯·æ±‚åœ¨å„æœåŠ¡é—´çš„æ—¶åºå…³ç³»
- **Span Details**: æŸ¥çœ‹æ¯ä¸ªæ“ä½œçš„è¯¦ç»†ä¿¡æ¯

### **2. æœ¬åœ° Prometheus (æŒ‡æ ‡)**

**è®¿é—®åœ°å€ï¼š** `http://localhost:9090`

**æŸ¥è¯¢ç¤ºä¾‹ï¼š**
```promql
# è¯·æ±‚é€Ÿç‡
rate(http_requests_total[5m])

# å¹³å‡å“åº”æ—¶é—´
histogram_quantile(0.95, http_request_duration_seconds_bucket)

# é”™è¯¯ç‡
rate(http_requests_total{status=~"5.."}[5m])

# æœåŠ¡å¯ç”¨æ€§
(1 - (sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])))) * 100
```

### **3. Grafana Cloud Dashboard**

**è®¿é—®æ­¥éª¤ï¼š**
1. ç™»å½• [Grafana Cloud](https://grafana.com)
2. è¿›å…¥ä½ çš„å®ä¾‹
3. è®¿é—®é¢„é…ç½®çš„ä»ªè¡¨æ¿

**ä»ªè¡¨æ¿ç¤ºä¾‹ï¼š**

#### **æœåŠ¡æ¦‚è§ˆä»ªè¡¨æ¿**
```json
{
  "dashboard": {
    "title": "AI Teams æœåŠ¡æ¦‚è§ˆ",
    "panels": [
      {
        "title": "è¯·æ±‚é€Ÿç‡",
        "targets": [{
          "expr": "sum(rate(http_requests_total[5m])) by (service)"
        }]
      },
      {
        "title": "é”™è¯¯ç‡",
        "targets": [{
          "expr": "sum(rate(http_requests_total{status=~'5..'}[5m])) by (service)"
        }]
      },
      {
        "title": "P95 å»¶è¿Ÿ",
        "targets": [{
          "expr": "histogram_quantile(0.95, http_request_duration_seconds_bucket)"
        }]
      }
    ]
  }
}
```

### **4. CloudWatch Logs Insights (AWS)**

**æŸ¥è¯¢ç¤ºä¾‹ï¼š**

```sql
-- æŸ¥æ‰¾ç‰¹å®š tracking_id çš„æ‰€æœ‰æ—¥å¿—
fields @timestamp, service, @message
| filter tracking_id = "abc123def456"
| sort @timestamp desc

-- æŸ¥æ‰¾æ‰€æœ‰é”™è¯¯
fields @timestamp, service, error.message, tracking_id
| filter @level = "ERROR"
| sort @timestamp desc
| limit 100

-- åˆ†æè¯·æ±‚æ€§èƒ½
fields request.path, request.duration
| filter request.duration > 1.0
| stats avg(request.duration) by request.path

-- æŸ¥æ‰¾æ…¢æŸ¥è¯¢
fields @timestamp, @message, tracking_id, request.duration
| filter request.duration > 2.0
| sort request.duration desc

-- ç”¨æˆ·è¡Œä¸ºåˆ†æ
fields user.id, request.path, @timestamp
| filter ispresent(user.id)
| stats count() by user.id, request.path
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### **1. å¯åŠ¨æœ¬åœ°ç›‘æ§æ ˆ**

```bash
# 1. å¯åŠ¨ç›‘æ§æœåŠ¡
cd monitoring
docker-compose -f docker-compose.monitoring.yml up -d

# 2. å¯åŠ¨åº”ç”¨æœåŠ¡
cd ../apps/backend
docker-compose up -d

# 3. éªŒè¯æœåŠ¡
curl http://localhost:16686  # Jaeger UI
curl http://localhost:9090   # Prometheus
curl http://localhost:3100   # Loki (å¦‚æœå¯ç”¨)

# 4. æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker logs otel-collector
docker logs jaeger
docker logs prometheus
```

### **2. é…ç½® Grafana Cloudï¼ˆå¯é€‰ï¼‰**

```bash
# 1. åˆ›å»º Grafana Cloud å…è´¹è´¦å·
# https://grafana.com/auth/sign-up/create-user

# 2. è·å– API å¯†é’¥å’Œç§Ÿæˆ· ID
# åœ¨ Grafana Cloud æ§åˆ¶å° -> API Keys

# 3. é…ç½®ç¯å¢ƒå˜é‡
export GRAFANA_CLOUD_API_KEY="your-api-key"
export GRAFANA_CLOUD_TENANT_ID="your-tenant-id"
export GRAFANA_CLOUD_PROMETHEUS_URL="https://prometheus-prod-xx.grafana.net/api/prom/push"
export GRAFANA_CLOUD_LOKI_URL="https://logs-prod-xx.grafana.net/loki/api/v1/push"

# 4. é‡å¯ OTel Collector
docker-compose -f docker-compose.monitoring.yml restart otel-collector
```

### **3. ç”Ÿæˆæµ‹è¯•æ•°æ®**

```python
# test_monitoring.py
import httpx
import asyncio
import random

async def generate_test_traffic():
    """ç”Ÿæˆæµ‹è¯•æµé‡ä»¥æŸ¥çœ‹ç›‘æ§æ•°æ®"""
    async with httpx.AsyncClient() as client:
        for i in range(100):
            # åˆ›å»ºä¼šè¯
            response = await client.post(
                "http://localhost:8000/api/app/sessions",
                json={"name": f"Test Session {i}"}
            )
            
            # éšæœºäº§ç”Ÿä¸€äº›é”™è¯¯
            if random.random() < 0.1:
                await client.get("http://localhost:8000/api/app/nonexistent")
            
            # æ¨¡æ‹Ÿä¸åŒçš„å“åº”æ—¶é—´
            await asyncio.sleep(random.uniform(0.1, 0.5))

asyncio.run(generate_test_traffic())
```

---

## ğŸ“ˆ å¸¸ç”¨ç›‘æ§æŸ¥è¯¢

### **1. Jaeger æŸ¥è¯¢**

```yaml
# æŸ¥æ‰¾æ…¢è¯·æ±‚
Service: api-gateway
Operation: POST /api/app/chat/stream
Min Duration: 1s

# æŸ¥æ‰¾é”™è¯¯
Service: workflow-agent
Tags: error=true

# æŸ¥æ‰¾ç‰¹å®šç”¨æˆ·
Tags: user.id=user-123

# è·¨æœåŠ¡è¿½è¸ª
Service: api-gateway AND workflow-agent
```

### **2. Prometheus/Grafana æŸ¥è¯¢**

```promql
# æœåŠ¡å¯ç”¨æ€§ (SLA)
(1 - (sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])))) * 100

# æ¯ç§’è¯·æ±‚æ•° (RPS)
sum(rate(http_requests_total[1m])) by (service)

# æ´»è·ƒç”¨æˆ·æ•°
sum(active_sessions) by (service)

# å·¥ä½œæµæ‰§è¡ŒæˆåŠŸç‡
sum(rate(workflow_executions_total{status="success"}[5m])) / sum(rate(workflow_executions_total[5m]))

# P50/P95/P99 å»¶è¿Ÿ
histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))

# AI Token ä½¿ç”¨è¶‹åŠ¿
sum(rate(ai_tokens_used_total[5m])) by (model, service)

# å†…å­˜ä½¿ç”¨
process_resident_memory_bytes / 1024 / 1024  # MB
```

### **3. Loki æ—¥å¿—æŸ¥è¯¢**

```logql
# æŸ¥æ‰¾æ‰€æœ‰é”™è¯¯æ—¥å¿—
{service="api-gateway"} |= "ERROR"

# ç‰¹å®š tracking_id
{service=~"api-gateway|workflow-agent"} |= "tracking_id=\"abc123\""

# JSON è§£æå’Œè¿‡æ»¤
{service="workflow-agent"} 
  | json 
  | workflow_id="wf-123" 
  | line_format "{{.timestamp}} {{.message}}"

# ç»Ÿè®¡é”™è¯¯ç±»å‹
{service="api-gateway"} 
  | json 
  | __error__="" 
  | level="ERROR" 
  | pattern `<_> error_type="<error_type>"` 
  | count by (error_type)

# æŸ¥æ‰¾æ…¢è¯·æ±‚æ—¥å¿—
{service="api-gateway"} 
  | json 
  | request_duration > 1.0
```

---

## ğŸ¯ å®é™…ä½¿ç”¨åœºæ™¯

### **åœºæ™¯ 1ï¼šè°ƒè¯•æ…¢è¯·æ±‚**

1. **ç”¨æˆ·æŠ¥å‘Š**: "åˆ›å»ºå·¥ä½œæµå¾ˆæ…¢"
2. **Jaeger è¿½è¸ª**:
   ```
   Service: api-gateway
   Operation: POST /api/app/workflows
   Min Duration: 3s
   ```
3. **æ‰¾åˆ° tracking_id**: `abc123def456`
4. **æŸ¥çœ‹è¯·æ±‚é“¾è·¯**:
   - API Gateway (100ms) 
   - â†’ Workflow Agent (2900ms) âš ï¸
   - â†’ Workflow Engine (50ms)
5. **æ·±å…¥ Workflow Agent**:
   - LLM è°ƒç”¨: 2500ms âš ï¸
   - æ•°æ®åº“æŸ¥è¯¢: 300ms
6. **æŸ¥çœ‹ç›¸å…³æ—¥å¿—**:
   ```logql
   {service="workflow-agent"} |= "tracking_id=\"abc123def456\""
   ```
7. **å‘ç°é—®é¢˜**: LLM æ¨¡å‹å“åº”æ…¢ï¼Œè€ƒè™‘ä¼˜åŒ– prompt æˆ–ä½¿ç”¨ç¼“å­˜

### **åœºæ™¯ 2ï¼šç›‘æ§æœåŠ¡å¥åº·**

1. **è®¾ç½® Grafana å‘Šè­¦**:
   ```yaml
   alert: HighErrorRate
   expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.01
   for: 5m
   labels:
     severity: warning
   annotations:
     summary: "æœåŠ¡ {{ $labels.service }} é”™è¯¯ç‡è¿‡é«˜"
   ```

2. **æ”¶åˆ°å‘Šè­¦é€šçŸ¥**
3. **æŸ¥çœ‹é”™è¯¯è¯¦æƒ…**:
   ```promql
   sum(rate(http_requests_total{status=~"5.."}[5m])) by (service, status, path)
   ```
4. **æŸ¥æ‰¾é”™è¯¯æ—¥å¿—**:
   ```sql
   fields @timestamp, tracking_id, error.message
   | filter @level = "ERROR" and service = "api-gateway"
   | sort @timestamp desc
   | limit 50
   ```
5. **ä½¿ç”¨ tracking_id åœ¨ Jaeger ä¸­æŸ¥çœ‹å¤±è´¥è¯·æ±‚çš„å®Œæ•´é“¾è·¯**

### **åœºæ™¯ 3ï¼šå®¹é‡è§„åˆ’**

1. **æŸ¥çœ‹å†å²è¶‹åŠ¿**:
   ```promql
   # 30å¤©è¯·æ±‚é‡è¶‹åŠ¿
   increase(http_requests_total[30d])
   
   # å³°å€¼ QPS
   max_over_time(rate(http_requests_total[1m])[30d:1h])
   ```

2. **èµ„æºä½¿ç”¨åˆ†æ**:
   ```promql
   # CPU ä½¿ç”¨ç‡
   rate(process_cpu_seconds_total[5m]) * 100
   
   # å†…å­˜ä½¿ç”¨
   process_resident_memory_bytes / 1024 / 1024 / 1024  # GB
   ```

3. **é¢„æµ‹æœªæ¥å¢é•¿**:
   - å½“å‰: 100 QPS, 2GB å†…å­˜
   - å¢é•¿ç‡: 20% / æœˆ
   - 6ä¸ªæœˆå: 250 QPS, 5GB å†…å­˜
   - å»ºè®®: æå‰æ‰©å®¹è‡³ 4 ä¸ªå®ä¾‹

### **åœºæ™¯ 4ï¼šåˆ†æç”¨æˆ·è¡Œä¸º**

```sql
-- CloudWatch Logs Insights
fields user.id, request.path, @timestamp
| filter ispresent(user.id)
| stats count() by user.id, bin(5m)
| sort count() desc

-- ç”¨æˆ·è·¯å¾„åˆ†æ
fields user.id, request.path, @timestamp
| filter user.id = "user-123"
| sort @timestamp asc
```

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥æŒ‡å—

### **é—®é¢˜ï¼šçœ‹ä¸åˆ°è¿½è¸ªæ•°æ®**

```bash
# 1. æ£€æŸ¥ OTel Collector çŠ¶æ€
docker logs otel-collector

# 2. éªŒè¯æœåŠ¡é…ç½®
curl http://localhost:4318/v1/traces  # åº”è¿”å› 405

# 3. æ£€æŸ¥ç¯å¢ƒå˜é‡
docker exec api-gateway env | grep OTEL

# 4. éªŒè¯è¿½è¸ªå¤´ä¼ æ’­
curl -H "traceparent: 00-12345678901234567890123456789012-1234567890123456-01" \
     http://localhost:8000/api/public/health -v
```

### **é—®é¢˜ï¼šæŒ‡æ ‡ä¸æ›´æ–°**

```bash
# 1. æ£€æŸ¥ Prometheus æŠ“å–
curl http://localhost:9090/targets

# 2. éªŒè¯æŒ‡æ ‡ç«¯ç‚¹
curl http://localhost:8000/metrics

# 3. æŸ¥çœ‹å¯¼å‡ºå™¨æ—¥å¿—
docker logs otel-collector | grep prometheus

# 4. æ‰‹åŠ¨æŸ¥è¯¢æŒ‡æ ‡
curl -G http://localhost:9090/api/v1/query \
     --data-urlencode 'query=up{job="api-gateway"}'
```

### **é—®é¢˜ï¼šæ—¥å¿—æœªæ”¶é›†**

```python
# éªŒè¯æ—¥å¿—æ ¼å¼åŒ–å™¨
import logging
logger = logging.getLogger(__name__)
logger.info("Test log", extra={"test": "value"})

# æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸º JSON æ ¼å¼
# åº”è¯¥çœ‹åˆ°: {"@timestamp":"2024-03-15T10:00:00Z","@level":"INFO",...}
```

### **é—®é¢˜ï¼šé«˜å»¶è¿Ÿ**

1. **ä½¿ç”¨ Jaeger æ‰¾åˆ°æ…¢æ“ä½œ**
2. **æŸ¥çœ‹ç«ç„°å›¾** (Jaeger UI -> Trace -> Flamegraph)
3. **åˆ†ææ•°æ®åº“æŸ¥è¯¢**:
   ```python
   with tracer.start_as_current_span("database_query") as span:
       span.set_attribute("db.statement", query)
       result = await db.execute(query)
   ```

---

## ğŸ“š è¿›é˜¶ä½¿ç”¨

### **è‡ªå®šä¹‰ä»ªè¡¨æ¿**

åˆ›å»º `dashboards/workflow-monitoring.json`:

```json
{
  "dashboard": {
    "title": "å·¥ä½œæµæ‰§è¡Œç›‘æ§",
    "panels": [
      {
        "title": "å·¥ä½œæµæ‰§è¡Œè¶‹åŠ¿",
        "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
        "targets": [{
          "expr": "sum(rate(workflow_executions_total[5m])) by (workflow_type)",
          "legendFormat": "{{workflow_type}}"
        }]
      },
      {
        "title": "AI Token ä½¿ç”¨",
        "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
        "targets": [{
          "expr": "sum(rate(ai_tokens_used_total[5m])) by (model)",
          "legendFormat": "{{model}}"
        }]
      },
      {
        "title": "å·¥ä½œæµæˆåŠŸç‡",
        "gridPos": {"x": 0, "y": 8, "w": 8, "h": 6},
        "targets": [{
          "expr": "sum(rate(workflow_executions_total{status=\"success\"}[5m])) / sum(rate(workflow_executions_total[5m])) * 100"
        }]
      },
      {
        "title": "å¹³å‡æ‰§è¡Œæ—¶é—´",
        "gridPos": {"x": 8, "y": 8, "w": 8, "h": 6},
        "targets": [{
          "expr": "histogram_quantile(0.95, sum(rate(workflow_duration_seconds_bucket[5m])) by (le))"
        }]
      },
      {
        "title": "æ´»è·ƒå·¥ä½œæµ",
        "gridPos": {"x": 16, "y": 8, "w": 8, "h": 6},
        "targets": [{
          "expr": "sum(active_workflows) by (status)"
        }]
      }
    ]
  }
}
```

### **è®¾ç½® SLO (æœåŠ¡çº§åˆ«ç›®æ ‡)**

```yaml
# slo.yaml
apiVersion: sloth.slok.dev/v1
kind: PrometheusServiceLevel
metadata:
  name: api-gateway-slo
spec:
  service: "api-gateway"
  labels:
    team: "platform"
  slos:
    - name: "requests-availability"
      objective: 99.9  # 99.9% å¯ç”¨æ€§
      sli:
        events:
          error_query: sum(rate(http_requests_total{service="api-gateway",status=~"5.."}[5m]))
          total_query: sum(rate(http_requests_total{service="api-gateway"}[5m]))
      alerting:
        name: APIGatewayAvailability
        page_alert:
          labels:
            severity: critical
    
    - name: "requests-latency"
      objective: 95  # 95% è¯·æ±‚ < 1s
      sli:
        events:
          error_query: |
            sum(rate(http_request_duration_seconds_bucket{service="api-gateway",le="1.0"}[5m]))
          total_query: |
            sum(rate(http_request_duration_seconds_count{service="api-gateway"}[5m]))
```

### **è‡ªå®šä¹‰è¿½è¸ª Span**

```python
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode

tracer = trace.get_tracer(__name__)

async def complex_operation():
    with tracer.start_as_current_span("complex_operation") as span:
        # æ·»åŠ  span å±æ€§
        span.set_attribute("operation.type", "data_processing")
        span.set_attribute("operation.complexity", "high")
        
        try:
            # æ­¥éª¤ 1: æ•°æ®éªŒè¯
            with tracer.start_as_current_span("validate_data") as child_span:
                child_span.set_attribute("data.size", len(data))
                await validate_data(data)
            
            # æ­¥éª¤ 2: AI å¤„ç†
            with tracer.start_as_current_span("ai_processing") as child_span:
                child_span.set_attribute("model.name", "gpt-4")
                result = await process_with_ai(data)
                child_span.set_attribute("tokens.used", result.token_count)
            
            # æ­¥éª¤ 3: å­˜å‚¨ç»“æœ
            with tracer.start_as_current_span("store_result") as child_span:
                child_span.set_attribute("storage.type", "postgresql")
                await store_result(result)
            
            # æˆåŠŸ
            span.set_status(Status(StatusCode.OK))
            span.add_event("operation_completed", {
                "result.size": len(result),
                "duration": time.time() - start_time
            })
            
        except Exception as e:
            # è®°å½•é”™è¯¯
            span.record_exception(e)
            span.set_status(Status(StatusCode.ERROR, str(e)))
            raise
```

### **æ‰¹é‡æ“ä½œç›‘æ§**

```python
from opentelemetry import trace, baggage
from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator

tracer = trace.get_tracer(__name__)
propagator = TraceContextTextMapPropagator()

async def batch_process_workflows(workflow_ids: List[str]):
    with tracer.start_as_current_span("batch_process") as span:
        span.set_attribute("batch.size", len(workflow_ids))
        
        # è®¾ç½® baggage ç”¨äºè·¨æœåŠ¡ä¼ æ’­
        baggage.set_baggage("batch.id", str(uuid.uuid4()))
        baggage.set_baggage("batch.total", str(len(workflow_ids)))
        
        results = []
        for i, workflow_id in enumerate(workflow_ids):
            with tracer.start_as_current_span(f"process_workflow_{i}") as child_span:
                child_span.set_attribute("workflow.id", workflow_id)
                child_span.set_attribute("batch.index", i)
                
                try:
                    result = await process_single_workflow(workflow_id)
                    results.append(result)
                    child_span.add_event("workflow_processed")
                except Exception as e:
                    child_span.record_exception(e)
                    child_span.set_status(Status(StatusCode.ERROR))
        
        span.set_attribute("batch.success_count", len(results))
        return results
```

---

## ğŸ”’ å®‰å…¨å’Œæœ€ä½³å®è·µ

### **1. æ•æ„Ÿæ•°æ®å¤„ç†**

```python
# ä¸è¦åœ¨è¿½è¸ªä¸­åŒ…å«æ•æ„Ÿä¿¡æ¯
span.set_attribute("user.id", user_id)  # âœ…
span.set_attribute("user.email", email)  # âŒ é¿å… PII

# æ—¥å¿—è„±æ•
logger.info("User login", extra={
    "user_id": user_id,  # âœ…
    "ip": mask_ip(request.client.host),  # âœ… è„±æ•
    # "password": password  # âŒ ç»ä¸è®°å½•
})
```

### **2. é‡‡æ ·ç­–ç•¥**

```python
# apps/backend/shared/telemetry/complete_stack.py
from opentelemetry.sdk.trace.sampling import TraceIdRatioBased

# ç”Ÿäº§ç¯å¢ƒé‡‡æ · 10%
sampler = TraceIdRatioBased(0.1)

# æˆ–ä½¿ç”¨è‡ªå®šä¹‰é‡‡æ ·å™¨
class CustomSampler:
    def should_sample(self, context, trace_id, name, kind, attributes, links):
        # é”™è¯¯æ€»æ˜¯é‡‡æ ·
        if attributes.get("error"):
            return SamplingResult(Decision.RECORD_AND_SAMPLE)
        
        # VIP ç”¨æˆ·æ€»æ˜¯é‡‡æ ·
        if attributes.get("user.vip"):
            return SamplingResult(Decision.RECORD_AND_SAMPLE)
        
        # å…¶ä»–è¯·æ±‚ 1% é‡‡æ ·
        return TraceIdRatioBased(0.01).should_sample(...)
```

### **3. æ€§èƒ½ä¼˜åŒ–**

```python
# æ‰¹é‡å¯¼å‡º
batch_span_processor = BatchSpanProcessor(
    span_exporter,
    max_queue_size=2048,
    max_export_batch_size=512,
    schedule_delay_millis=5000,
)

# å¼‚æ­¥æ—¥å¿—
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncLogger:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    def log(self, level, message, **kwargs):
        self.executor.submit(logger.log, level, message, **kwargs)
```

---

## ğŸ“– å‚è€ƒèµ„æº

### **å®˜æ–¹æ–‡æ¡£**
- [OpenTelemetry Python](https://opentelemetry.io/docs/instrumentation/python/)
- [Jaeger Documentation](https://www.jaegertracing.io/docs/)
- [Prometheus Docs](https://prometheus.io/docs/)
- [Grafana Cloud Docs](https://grafana.com/docs/grafana-cloud/)

### **æŸ¥è¯¢è¯­è¨€**
- [PromQL Tutorial](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [LogQL Documentation](https://grafana.com/docs/loki/latest/logql/)

### **æœ€ä½³å®è·µ**
- [Distributed Tracing Best Practices](https://www.jaegertracing.io/docs/1.21/best-practices/)
- [Monitoring Microservices](https://sre.google/sre-book/monitoring-distributed-systems/)

è¿™ä»½æ‰‹å†Œæ¶µç›–äº†ä»åŸºç¡€æ¦‚å¿µåˆ°å®é™…æ“ä½œçš„å®Œæ•´å†…å®¹ã€‚é€šè¿‡è¿™ä¸ªç›‘æ§ç³»ç»Ÿï¼Œä½ å¯ä»¥å…¨é¢äº†è§£ AI Teams ç³»ç»Ÿçš„è¿è¡ŒçŠ¶å†µï¼Œå¿«é€Ÿå®šä½é—®é¢˜ï¼Œå¹¶æŒç»­ä¼˜åŒ–æ€§èƒ½ï¼ ğŸš€